# 6ã€Pytorch ä¸­é˜¶ API

## 6.1ã€Dataset å’Œ DataLoader

Pytorch ä½¿ç”¨ Dataset å’Œ DataLoader è¿™ä¸¤ä¸ªå·¥å…·ç±»æ¥æž„å»ºæ•°æ®ç®¡é“ã€‚å®ƒä»¬çš„ä½œç”¨æ˜¯å°†æ•°æ®æ•´ç†æˆé€‚åˆè®­ç»ƒæ¨¡åž‹çš„æ ¼å¼ï¼Œä¸€ä¸ª batch ä¸€ä¸ª batch çš„å–å‡ºç»™æ¨¡åž‹

### 6.1.1ã€Dataset å’Œ DataLoader åŽŸç†

#### èŽ·å–ä¸€ä¸ª batch çš„æ­¥éª¤

å‡å®šæ•°æ®é›†çš„ç‰¹å¾å’Œæ ‡ç­¾åˆ†åˆ«è¡¨ç¤ºä¸ºå¼ é‡`X`å’Œ`Y`ï¼Œæ•°æ®é›†å¯ä»¥è¡¨+ç¤ºä¸º `(X,Y)`, å‡å®š batch å¤§å°ä¸º `m`

1. é¦–å…ˆç¡®å®šæ•°æ®é›†é•¿åº¦ï¼š `n`
2. ä»Ž `0` åˆ° `n-1` çš„èŒƒå›´ä¸­æŠ½æ ·å‡º `m` ä¸ªæ•°ï¼ˆbatch å¤§å°ï¼‰  
   å‡å®š `m=4`, æ‹¿åˆ°çš„ç»“æžœæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œç±»ä¼¼ï¼š`indices = [1,4,8,9]`
3. ä»Žæ•°æ®é›†ä¸­åŽ»å–è¿™`m`ä¸ªæ•°å¯¹åº”ä¸‹æ ‡çš„å…ƒç´   
   æ‹¿åˆ°çš„ç»“æžœæ˜¯ä¸€ä¸ªå…ƒç»„åˆ—è¡¨ï¼Œç±»ä¼¼ï¼š`samples = [(X[1],Y[1]),(X[4],Y[4]),(X[8],Y[8]),(X[9],Y[9])]`
4. å°†ç»“æžœæ•´ç†æˆä¸¤ä¸ªå¼ é‡ä½œä¸ºè¾“å‡º  
   ç±»ä¼¼ `batch = (features,labels)`  
   å…¶ä¸­ `features = torch.stack([X[1],X[4],X[8],X[9]])`ï¼Œ`labels = torch.stack([Y[1],Y[4],Y[8],Y[9]])`

#### Dataset å’Œ DataLoader çš„åŠŸèƒ½åˆ†å·¥

`Dataset` æ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼Œç”¨äºŽè¡¨ç¤ºæ•°æ®é›†

- ä¸Šè¿°æ­¥éª¤ 1 ç¡®å®šæ•°æ®é›†çš„é•¿åº¦æ˜¯ç”± Dataset çš„ **`__len__` ** æ–¹æ³•å®žçŽ°
- æ­¥éª¤ 2 ä»Ž`0`åˆ° `n-1` çš„èŒƒå›´ä¸­æŠ½æ ·å‡º `m` ä¸ªæ•°çš„æ–¹æ³•æ˜¯ç”± DataLoader çš„ `sampler`å’Œ `batch_sampler`å‚æ•°æŒ‡å®š
  - `sampler` å‚æ•°æŒ‡å®šå•ä¸ªå…ƒç´ æŠ½æ ·æ–¹æ³•ï¼Œä¸€èˆ¬æ— éœ€ç”¨æˆ·è®¾ç½®ï¼Œç¨‹åºé»˜è®¤åœ¨ DataLoader çš„å‚æ•° `shuffle=True` æ—¶é‡‡ç”¨éšæœºæŠ½æ ·ï¼Œ`shuffle=False` æ—¶é‡‡ç”¨é¡ºåºæŠ½æ ·
  - `batch_sampler` å‚æ•°å°†å¤šä¸ªæŠ½æ ·çš„å…ƒç´ æ•´ç†æˆä¸€ä¸ªåˆ—è¡¨ï¼Œä¸€èˆ¬æ— éœ€ç”¨æˆ·è®¾ç½®ï¼Œé»˜è®¤æ–¹æ³•åœ¨ DataLoader çš„å‚æ•° `drop_last=True` æ—¶ä¼šä¸¢å¼ƒæ•°æ®é›†æœ€åŽä¸€ä¸ªé•¿åº¦ä¸èƒ½è¢« batch å¤§å°æ•´é™¤çš„æ‰¹æ¬¡ï¼Œåœ¨ `drop_last=False` æ—¶ä¿ç•™æœ€åŽä¸€ä¸ªæ‰¹æ¬¡
- æ­¥éª¤ 3 æ ¹æ®ä¸‹æ ‡å–æ•°æ®é›†ä¸­çš„å…ƒç´  æ˜¯ç”± Dataset çš„ **`__getitem__` **æ–¹æ³•å®žçŽ°
- æ­¥éª¤ 4 çš„é€»è¾‘ç”±DataLoaderçš„å‚æ•°`collate_fn`æŒ‡å®šã€‚ä¸€èˆ¬æƒ…å†µä¸‹ä¹Ÿæ— éœ€ç”¨æˆ·è®¾ç½®ã€‚

Dataset å’Œ DataLoader çš„ä¸€èˆ¬ä½¿ç”¨æ–¹å¼å¦‚ä¸‹

- TensorDataset(data, labels)
- DataLoader(ds,batch_size=4,drop_last,shuffle...)

```py
import torch 
from torch.utils.data import TensorDataset,Dataset,DataLoader
from torch.utils.data import RandomSampler,BatchSampler 

# TensorDataset(data, labels)
ds = TensorDataset(torch.randn(1000,3),torch.randint(low=0,high=2,size=(1000,)).float())
dl = DataLoader(ds,batch_size=4,drop_last = False)

# èŽ·å–æ•°æ®åŠ è½½å™¨ä¸­çš„ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ï¼ˆfeatureså’Œlabelsï¼‰
features,labels = next(iter(dl))
print("features = ",features )
print("labels = ",labels )  
```

DataLoader å†…éƒ¨è°ƒç”¨æ–¹å¼æ­¥éª¤æ‹†è§£å¦‚ä¸‹ï¼š

```py
# step1: ç¡®å®šæ•°æ®é›†é•¿åº¦ (Dataset çš„ __len__ æ–¹æ³•å®žçŽ°)
ds = TensorDataset(torch.randn(1000,3),torch.randint(low=0,high=2,size=(1000,)).float())
print("n = ", len(ds)) # len(ds)ç­‰ä»·äºŽ ds.__len__()

# step2: ç¡®å®šæŠ½æ · indices (DataLoader ä¸­çš„ Sampler å’Œ BatchSampler å®žçŽ°)
sampler = RandomSampler(data_source = ds) # åˆ›å»ºéšæœºé‡‡æ ·å™¨
batch_sampler = BatchSampler(sampler = sampler, batch_size = 4, drop_last = False) # åˆ›å»ºæ‰¹æ¬¡é‡‡æ ·å™¨
# å–å‡ºç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„ç´¢å¼• indices
for idxs in batch_sampler:
    indices = idxs
    break 
print("indices = ",indices)

# step3: å–å‡ºä¸€æ‰¹æ ·æœ¬ batch (Dataset çš„ __getitem__ æ–¹æ³•å®žçŽ°)
batch = [ds[i] for i in  indices]  #  ds[i] ç­‰ä»·äºŽ ds.__getitem__(i)
print("batch = ", batch)

# step4: æ•´ç†æˆ features å’Œ labels (DataLoader çš„ collate_fn æ–¹æ³•å®žçŽ°)
def collate_fn(batch):
    features = torch.stack([sample[0] for sample in batch])
    labels = torch.stack([sample[1] for sample in batch])
    return features,labels 

features,labels = collate_fn(batch)
print("features = ",features)
print("labels = ",labels)

```

### 6.1.2ã€Dataset ä½¿ç”¨

Dataset åˆ›å»ºæ•°æ®é›†çš„æ–¹æ³•ï¼š

- ä½¿ç”¨ torch.utils.data.**TensorDataset** æ ¹æ® Tensor åˆ›å»ºæ•°æ®é›†ï¼ˆnumpy çš„ arrayï¼ŒPandas çš„ DataFrame éœ€è¦å…ˆè½¬æ¢æˆ Tensorï¼‰

  ```py
  from torch.utils.data import TensorDataset
  train_ds = TensorDataset(features,labels)
  ```

- ä½¿ç”¨ torchvision.datasets.ImageFolder æ ¹æ®å›¾ç‰‡ç›®å½•åˆ›å»ºå›¾ç‰‡æ•°æ®é›†

- ç»§æ‰¿ torch.utils.data.Dataset åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†

å¸¸ç”¨æ‰‹æ³•ï¼š

- torch.utils.data.random_split å°†ä¸€ä¸ªæ•°æ®é›†åˆ†å‰²æˆå¤šä»½ï¼Œå¸¸ç”¨äºŽåˆ†å‰²è®­ç»ƒé›†ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†
- è°ƒç”¨ Dataset çš„åŠ æ³•è¿ç®—ç¬¦(`+`)å°†å¤šä¸ªæ•°æ®é›†åˆå¹¶æˆä¸€ä¸ªæ•°æ®é›†

#### æ ¹æ® Tensor åˆ›å»ºæ•°æ®é›†

```py
import numpy as np 
import torch 
from torch.utils.data import TensorDataset,Dataset,DataLoader,random_split 

# æ ¹æ® Tensor åˆ›å»ºæ•°æ®é›†
from sklearn import datasets 
iris = datasets.load_iris()
ds_iris = TensorDataset(torch.tensor(iris.data),torch.tensor(iris.target))

# åˆ†å‰²æˆè®­ç»ƒé›†å’Œé¢„æµ‹é›†
n_train = int(len(ds_iris)*0.8)
n_val = len(ds_iris) - n_train
ds_train,ds_val = random_split(ds_iris,[n_train,n_val])

# ä½¿ç”¨ DataLoader åŠ è½½æ•°æ®é›†
dl_train,dl_val = DataLoader(ds_train,batch_size = 8),DataLoader(ds_val,batch_size = 8)
for features,labels in dl_train:
    print(features,labels)
    break

# æ¼”ç¤ºåŠ æ³•è¿ç®—ç¬¦ï¼ˆ`+`ï¼‰çš„åˆå¹¶ä½œç”¨
ds_data = ds_train + ds_val

print('len(ds_train) = ',len(ds_train)) # 120
print('len(ds_valid) = ',len(ds_val)) # 30
print('len(ds_train+ds_valid) = ',len(ds_data)) # 150
print(type(ds_data))
```

#### æ ¹æ®å›¾ç‰‡ç›®å½•åˆ›å»ºå›¾ç‰‡æ•°æ®é›†

```py
import numpy as np 
import torch 
from torch.utils.data import DataLoader
from torchvision import transforms,datasets 

# å¸¸ç”¨çš„å›¾ç‰‡å¢žå¼ºæ“ä½œ
from PIL import Image
img = Image.open('./data/cat.jpeg')
# éšæœºæ•°å€¼ç¿»è½¬
transforms.RandomVerticalFlip()(img)
# éšæœºæ—‹è½¬
transforms.RandomRotation(45)(img)
# å®šä¹‰å›¾ç‰‡å¢žå¼ºæ“ä½œï¼Œç”¨äºŽå°†å¤šä¸ªå›¾åƒå˜æ¢ï¼ˆtransformsï¼‰ç»„åˆæˆä¸€ä¸ªå•ä¸€çš„å˜æ¢
transform_train = transforms.Compose([
   transforms.RandomHorizontalFlip(), # éšæœºæ°´å¹³ç¿»è½¬
   transforms.RandomVerticalFlip(), # éšæœºåž‚ç›´ç¿»è½¬
   transforms.RandomRotation(45),  # éšæœºåœ¨45åº¦è§’åº¦å†…æ—‹è½¬
   transforms.ToTensor() # è½¬æ¢æˆå¼ é‡
  ]
)
transform_valid = transforms.Compose([
    transforms.ToTensor()
  ]
)

# æ ¹æ®å›¾ç‰‡ç›®å½•åˆ›å»ºæ•°æ®é›†
def transform_label(x):
    return torch.tensor([x]).float()

ds_train = datasets.ImageFolder("./eat_pytorch_datasets/cifar2/train/",transform = transform_train,target_transform= transform_label)
ds_val = datasets.ImageFolder("./eat_pytorch_datasets/cifar2/test/",transform = transform_valid,target_transform= transform_label)


print(ds_train.class_to_idx) # {'0_airplane': 0, '1_automobile': 1}

# ä½¿ç”¨ DataLoader åŠ è½½æ•°æ®é›†
dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)
dl_val = DataLoader(ds_val,batch_size = 50,shuffle = True)
for features,labels in dl_train:
    print(features.shape) # torch.Size([50, 3, 32, 32])
    print(labels.shape) # torch.Size([50, 1])
    break
```

#### åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†

é€šè¿‡ç»§æ‰¿ torch.utils.data.Dataset åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†çš„æ–¹å¼æ¥å¯¹ cifar2 æž„å»ºæ•°æ®ç®¡é“

```py
from pathlib import Path 
from PIL import Image 

class Cifar2Dataset(Dataset):
    def __init__(self,imgs_dir,img_transform):
        self.files = list(Path(imgs_dir).rglob("*.jpg"))
        self.transform = img_transform
        
    def __len__(self,):
        return len(self.files)
    
    def __getitem__(self,i):
        file_i = str(self.files[i])
        img = Image.open(file_i)
        tensor = self.transform(img)
        label = torch.tensor([1.0]) if  "1_automobile" in file_i else torch.tensor([0.0])
        return tensor,label 
    
    
train_dir = "./eat_pytorch_datasets/cifar2/train/"
test_dir = "./eat_pytorch_datasets/cifar2/test/"

# å®šä¹‰å›¾ç‰‡å¢žå¼º
transform_train = transforms.Compose([
   transforms.RandomHorizontalFlip(), # éšæœºæ°´å¹³ç¿»è½¬
   transforms.RandomVerticalFlip(), # éšæœºåž‚ç›´ç¿»è½¬
   transforms.RandomRotation(45),  # éšæœºåœ¨45åº¦è§’åº¦å†…æ—‹è½¬
   transforms.ToTensor() # è½¬æ¢æˆå¼ é‡
  ]
)

transform_val = transforms.Compose([
    transforms.ToTensor()
  ]
)

ds_train = Cifar2Dataset(train_dir,transform_train)
ds_val = Cifar2Dataset(test_dir,transform_val)

dl_train = DataLoader(ds_train,batch_size = 50,shuffle = True)
dl_val = DataLoader(ds_val,batch_size = 50,shuffle = True)

for features,labels in dl_train:
    print(features.shape) # torch.Size([50, 3, 32, 32])
    print(labels.shape) # torch.Size([50, 1])
    break
```

### 6.1.3ã€ä½¿ç”¨ DataLoader åŠ è½½æ•°æ®é›†

DataLoader èƒ½å¤ŸæŽ§åˆ¶ batch çš„å¤§å°ï¼Œbatch ä¸­å…ƒç´ çš„é‡‡æ ·æ–¹æ³•ï¼Œä»¥åŠå°† batch ç»“æžœæ•´ç†æˆæ¨¡åž‹æ‰€éœ€è¾“å…¥å½¢å¼çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿä½¿ç”¨å¤šè¿›ç¨‹è¯»å–æ•°æ®

DataLoader çš„å‡½æ•°ç­¾åå¦‚ä¸‹

```py
DataLoader(
    dataset, # ä¼ å…¥ Dataset
    batch_size=1, # å– Dataset æ—¶ï¼Œä¸€æ¬¡å–å¤šå¤§
    shuffle=False,
    sampler=None,
    batch_sampler=None,
    num_workers=0,
    collate_fn=None,
    pin_memory=False,
    drop_last=False,
    timeout=0,
    worker_init_fn=None,
    multiprocessing_context=None,
)
```

ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä»…ä»…ä¼šé…ç½® dataset, batch_size, shuffle, num_workers,pin_memory, drop_last è¿™å…­ä¸ªå‚æ•°ï¼Œ

æœ‰æ—¶å€™å¯¹äºŽä¸€äº›å¤æ‚ç»“æž„çš„æ•°æ®é›†ï¼Œè¿˜éœ€è¦è‡ªå®šä¹‰ collate_fn å‡½æ•°ï¼Œå…¶ä»–å‚æ•°ä¸€èˆ¬ä½¿ç”¨é»˜è®¤å€¼å³å¯ã€‚

DataLoader é™¤äº†å¯ä»¥åŠ è½½æˆ‘ä»¬å‰é¢è®²çš„ torch.utils.data.Dataset å¤–ï¼Œè¿˜èƒ½å¤ŸåŠ è½½å¦å¤–ä¸€ç§æ•°æ®é›† torch.utils.data.IterableDatasetã€‚

å’Œ Dataset æ•°æ®é›†ç›¸å½“äºŽä¸€ç§åˆ—è¡¨ç»“æž„ä¸åŒï¼ŒIterableDataset ç›¸å½“äºŽä¸€ç§è¿­ä»£å™¨ç»“æž„ã€‚ å®ƒæ›´åŠ å¤æ‚ï¼Œä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨ã€‚

- dataset : æ•°æ®é›†
- batch_size: æ‰¹æ¬¡å¤§å°
- shuffle: æ˜¯å¦ä¹±åº
- sampler: æ ·æœ¬é‡‡æ ·å‡½æ•°ï¼Œä¸€èˆ¬æ— éœ€è®¾ç½®ã€‚
- batch_sampler: æ‰¹æ¬¡é‡‡æ ·å‡½æ•°ï¼Œä¸€èˆ¬æ— éœ€è®¾ç½®ã€‚
- num_workers: ä½¿ç”¨å¤šè¿›ç¨‹è¯»å–æ•°æ®ï¼Œè®¾ç½®çš„è¿›ç¨‹æ•°ã€‚
- collate_fn: æ•´ç†ä¸€ä¸ªæ‰¹æ¬¡æ•°æ®çš„å‡½æ•°ã€‚
- pin_memory: æ˜¯å¦è®¾ç½®ä¸ºé”ä¸šå†…å­˜ã€‚é»˜è®¤ä¸ºFalseï¼Œé”ä¸šå†…å­˜ä¸ä¼šä½¿ç”¨è™šæ‹Ÿå†…å­˜(ç¡¬ç›˜)ï¼Œä»Žé”ä¸šå†…å­˜æ‹·è´åˆ°GPUä¸Šé€Ÿåº¦ä¼šæ›´å¿«ã€‚
- drop_last: æ˜¯å¦ä¸¢å¼ƒæœ€åŽä¸€ä¸ªæ ·æœ¬æ•°é‡ä¸è¶³batch_sizeæ‰¹æ¬¡æ•°æ®ã€‚
- timeout: åŠ è½½ä¸€ä¸ªæ•°æ®æ‰¹æ¬¡çš„æœ€é•¿ç­‰å¾…æ—¶é—´ï¼Œä¸€èˆ¬æ— éœ€è®¾ç½®ã€‚
- worker_init_fn: æ¯ä¸ªworkerä¸­datasetçš„åˆå§‹åŒ–å‡½æ•°ï¼Œå¸¸ç”¨äºŽ IterableDatasetã€‚ä¸€èˆ¬ä¸ä½¿ç”¨

```py
# æž„å»ºè¾“å…¥æ•°æ®ç®¡é“
ds = TensorDataset(torch.arange(1,50))
dl = DataLoader(ds,
                batch_size = 10,
                shuffle= True,
                num_workers=2,
                drop_last = True)
# è¿­ä»£æ•°æ®
for batch, in dl:
    print(batch)
    
'''
tensor([45, 49, 27,  7, 32, 48, 19, 38, 35, 30])
tensor([44, 37, 21, 39, 29, 13,  8, 31, 33,  5])
tensor([34, 28,  2, 23, 15, 42, 43, 40, 22,  6])
tensor([36,  3, 46,  9, 26, 16, 12, 17, 18,  1])
'''
```

## 6.2ã€æ¨¡åž‹å±‚ torch.nn

æ·±åº¦å­¦ä¹ æ¨¡åž‹ç”±å„ç§æ¨¡åž‹å±‚ç»„åˆ

**torch.nn** ä¸­å†…ç½®äº†éžå¸¸ä¸°å¯Œçš„å„ç§æ¨¡åž‹å±‚ã€‚å®ƒä»¬éƒ½å±žäºŽ nn.Module çš„å­ç±»ï¼Œå…·å¤‡å‚æ•°ç®¡ç†åŠŸèƒ½

ä¹Ÿå¯ä»¥é€šè¿‡ç»§æ‰¿ nn.Module åŸºç±»æž„å»ºè‡ªå®šä¹‰çš„æ¨¡åž‹å±‚

pytorch ä¸åŒºåˆ†æ¨¡åž‹å’Œæ¨¡åž‹å±‚ï¼Œéƒ½æ˜¯é€šè¿‡ç»§æ‰¿ nn.Module è¿›è¡Œæž„å»º

åªè¦ç»§æ‰¿ nn.Module åŸºç±»å¹¶å®žçŽ° forward æ–¹æ³•å³å¯è‡ªå®šä¹‰æ¨¡åž‹å±‚

> torch.nn.function ä¸­æœ‰å¾ˆå¤šåŠŸèƒ½ï¼Œä¸Ž nn.Module ä¸€æ ·ã€‚  
> ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå¦‚æžœæ¨¡åž‹æœ‰å¯å­¦ä¹ çš„å‚æ•°ï¼ˆwï¼Œbï¼‰ï¼Œæœ€å¥½ç”¨ nn.Moduleï¼Œå…¶ä»–æƒ…å†µï¼ˆæ¿€æ´»å‡½æ•°ï¼Œloss functionï¼‰ nn.function ç›¸å¯¹æ›´ç®€å•äº›

### 6.2.1ã€åŸºç¡€å±‚

- nn.Linearï¼šå…¨è¿žæŽ¥å±‚ã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥å±‚ç‰¹å¾æ•° Ã— è¾“å‡ºå±‚ç‰¹å¾æ•°(weight)ï¼‹ è¾“å‡ºå±‚ç‰¹å¾æ•°(bias)
- nn.Embeddingï¼šåµŒå…¥å±‚ã€‚ä¸€ç§æ¯” Onehot æ›´åŠ æœ‰æ•ˆçš„å¯¹ç¦»æ•£ç‰¹å¾è¿›è¡Œç¼–ç çš„æ–¹æ³•ã€‚ä¸€èˆ¬ç”¨äºŽå°†è¾“å…¥ä¸­çš„å•è¯æ˜ å°„ä¸ºç¨ å¯†å‘é‡ã€‚åµŒå…¥å±‚çš„å‚æ•°éœ€è¦å­¦ä¹ ã€‚
- nn.Flattenï¼šåŽ‹å¹³å±‚ï¼Œç”¨äºŽå°†å¤šç»´å¼ é‡æ ·æœ¬åŽ‹æˆä¸€ç»´å¼ é‡æ ·æœ¬ã€‚
- nn.BatchNorm1dï¼šä¸€ç»´æ‰¹æ ‡å‡†åŒ–å±‚ã€‚é€šè¿‡çº¿æ€§å˜æ¢å°†è¾“å…¥æ‰¹æ¬¡ç¼©æ”¾å¹³ç§»åˆ°ç¨³å®šçš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚å¯ä»¥å¢žå¼ºæ¨¡åž‹å¯¹è¾“å…¥ä¸åŒåˆ†å¸ƒçš„é€‚åº”æ€§ï¼ŒåŠ å¿«æ¨¡åž‹è®­ç»ƒé€Ÿåº¦ï¼Œæœ‰è½»å¾®æ­£åˆ™åŒ–æ•ˆæžœã€‚ä¸€èˆ¬åœ¨æ¿€æ´»å‡½æ•°ä¹‹å‰ä½¿ç”¨ã€‚å¯ä»¥ç”¨ afine å‚æ•°è®¾ç½®è¯¥å±‚æ˜¯å¦å«æœ‰å¯ä»¥è®­ç»ƒçš„å‚æ•°ã€‚
- nn.BatchNorm2dï¼šäºŒç»´æ‰¹æ ‡å‡†åŒ–å±‚ã€‚ å¸¸ç”¨äºŽ CV é¢†åŸŸã€‚
- nn.BatchNorm3dï¼šä¸‰ç»´æ‰¹æ ‡å‡†åŒ–å±‚ã€‚
- nn.Dropoutï¼šä¸€ç»´éšæœºä¸¢å¼ƒå±‚ã€‚ä¸€ç§æ­£åˆ™åŒ–æ‰‹æ®µã€‚
- nn.Dropout2dï¼šäºŒç»´éšæœºä¸¢å¼ƒå±‚ã€‚
- nn.Dropout3dï¼šä¸‰ç»´éšæœºä¸¢å¼ƒå±‚ã€‚
- nn.Thresholdï¼šé™å¹…å±‚ã€‚å½“è¾“å…¥å¤§äºŽæˆ–å°äºŽé˜ˆå€¼èŒƒå›´æ—¶ï¼Œæˆªæ–­ä¹‹ã€‚
- nn.ConstantPad2dï¼š äºŒç»´å¸¸æ•°å¡«å……å±‚ã€‚å¯¹äºŒç»´å¼ é‡æ ·æœ¬å¡«å……å¸¸æ•°æ‰©å±•é•¿åº¦ã€‚

- nn.ReplicationPad1dï¼š ä¸€ç»´å¤åˆ¶å¡«å……å±‚ã€‚å¯¹ä¸€ç»´å¼ é‡æ ·æœ¬é€šè¿‡å¤åˆ¶è¾¹ç¼˜å€¼å¡«å……æ‰©å±•é•¿åº¦ã€‚
- nn.ZeroPad2dï¼šäºŒç»´é›¶å€¼å¡«å……å±‚ã€‚å¯¹äºŒç»´å¼ é‡æ ·æœ¬åœ¨è¾¹ç¼˜å¡«å……0å€¼.
- nn.GroupNormï¼šç»„å½’ä¸€åŒ–ã€‚ä¸€ç§æ›¿ä»£æ‰¹å½’ä¸€åŒ–çš„æ–¹æ³•ï¼Œå°†é€šé“åˆ†æˆè‹¥å¹²ç»„è¿›è¡Œå½’ä¸€ã€‚ä¸å— batch å¤§å°é™åˆ¶ã€‚
- nn.LayerNormï¼šå±‚å½’ä¸€åŒ–ã€‚å¸¸ç”¨äºŽ NLP é¢†åŸŸï¼Œä¸å—åºåˆ—é•¿åº¦ä¸ä¸€è‡´å½±å“ã€‚
- nn.InstanceNorm2d: æ ·æœ¬å½’ä¸€åŒ–ã€‚ä¸€èˆ¬åœ¨å›¾åƒé£Žæ ¼è¿ç§»ä»»åŠ¡ä¸­æ•ˆæžœè¾ƒå¥½ã€‚

å„ç§å½’ä¸€åŒ–å±‚ï¼š

- ç»“æž„åŒ–æ•°æ® BatchNorm1D å½’ä¸€åŒ–
- å›¾ç‰‡æ•°æ®çš„å„ç§å½’ä¸€åŒ–ï¼ˆä¸€èˆ¬å¸¸ç”¨BatchNorm2Dï¼‰
- æ–‡æœ¬æ•°æ®çš„ LayerNorm å½’ä¸€åŒ–
- å¯è‡ªé€‚åº”å­¦ä¹ çš„å½’ä¸€åŒ– SwitchableNorm

å‚è€ƒè®ºæ–‡ï¼šhttps://arxiv.org/pdf/1806.10779.pdf

å¯¹ BatchNorm éœ€è¦æ³¨æ„çš„å‡ ç‚¹ï¼š

- åŽŸå§‹è®ºæ–‡è®¤ä¸ºå°† BatchNorm æ”¾åœ¨æ¿€æ´»å‡½æ•°å‰æ•ˆæžœè¾ƒå¥½ï¼ŒåŽé¢çš„ç ”ç©¶ä¸€èˆ¬è®¤ä¸ºå°† BatchNorm æ”¾åœ¨æ¿€æ´»å‡½æ•°ä¹‹åŽæ›´å¥½
- BatchNormåœ¨è®­ç»ƒè¿‡ç¨‹å’ŒæŽ¨ç†è¿‡ç¨‹çš„é€»è¾‘ä¸ä¸€æ ·ï¼Œè®­ç»ƒè¿‡ç¨‹ BatchNorm çš„å‡å€¼å’Œæ–¹å·®å’Œæ ¹æ® mini-batch ä¸­çš„æ•°æ®ä¼°è®¡çš„ï¼Œè€ŒæŽ¨ç†è¿‡ç¨‹ä¸­ BatchNorm çš„å‡å€¼å’Œæ–¹å·®æ˜¯ç”¨çš„è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…¨ä½“æ ·æœ¬ä¼°è®¡çš„ã€‚å› æ­¤é¢„æµ‹è¿‡ç¨‹æ˜¯ç¨³å®šçš„ï¼Œç›¸åŒçš„æ ·æœ¬ä¸ä¼šå› ä¸ºæ‰€åœ¨æ‰¹æ¬¡çš„å·®å¼‚å¾—åˆ°ä¸åŒçš„ç»“æžœï¼Œä½†è®­ç»ƒè¿‡ç¨‹ä¸­åˆ™ä¼šå—åˆ°æ‰¹æ¬¡ä¸­å…¶ä»–æ ·æœ¬çš„å½±å“æ‰€ä»¥æœ‰æ­£åˆ™åŒ–æ•ˆæžœ
- å¦‚æžœå—åˆ° GPU å†…å­˜é™åˆ¶ï¼Œä¸å¾—ä¸ä½¿ç”¨å¾ˆå°çš„ batch_sizeï¼Œè®­ç»ƒé˜¶æ®µæ—¶ä½¿ç”¨çš„ mini-batch ä¸Šçš„å‡å€¼å’Œæ–¹å·®çš„ä¼°è®¡å’Œé¢„æµ‹é˜¶æ®µæ—¶ä½¿ç”¨çš„å…¨ä½“æ ·æœ¬ä¸Šçš„å‡å€¼å’Œæ–¹å·®çš„ä¼°è®¡å·®å¼‚å¯èƒ½ä¼šè¾ƒå¤§ï¼Œæ•ˆæžœä¼šå˜å·®ã€‚è¿™æ—¶å€™ï¼Œå¯ä»¥å°è¯• LayerNorm æˆ–è€… GroupNorm ç­‰å½’ä¸€åŒ–æ–¹æ³•

BatchNorm ä½¿ç”¨ï¼š

```py
import torch 
from torch import nn 
batch_size, channel, height, width = 32, 16, 128, 128
tensor = torch.arange(0,32*16*128*128).view(32,16,128,128).float() 
# åˆ›å»ºäº† 2D æ‰¹é‡å½’ä¸€åŒ–å±‚
bn = nn.BatchNorm2d(num_features=channel,affine=False)
bn_out = bn(tensor)
channel_mean = torch.mean(bn_out[:,0,:,:]) # æå–å¼ é‡ä¸­ç¬¬ä¸€ä¸ªé€šé“çš„æ‰€æœ‰åƒç´ ï¼Œè®¡ç®—è¯¥é€šé“åƒç´ çš„å‡å€¼å’Œæ ‡å‡†å·®
channel_std = torch.std(bn_out[:,0,:,:]) 
print("channel mean:",channel_mean.item()) # 1.043081283569336e-07
print("channel std:",channel_std.item()) # 1.0000009536743164
```

### 6.2.2ã€å·ç§¯ç½‘ç»œç›¸å…³å±‚

- nn.Conv1dï¼šæ™®é€šä¸€ç»´å·ç§¯ï¼Œå¸¸ç”¨äºŽæ–‡æœ¬ã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥é€šé“æ•° Ã— å·ç§¯æ ¸å°ºå¯¸(å¦‚3)Ã—å·ç§¯æ ¸ä¸ªæ•° + å·ç§¯æ ¸å°ºå¯¸(å¦‚3ï¼‰
- nn.Conv2dï¼šæ™®é€šäºŒç»´å·ç§¯ï¼Œå¸¸ç”¨äºŽå›¾åƒã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥é€šé“æ•°Ã—å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3)Ã—å·ç§¯æ ¸ä¸ªæ•° + å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3)ã€‚) é€šè¿‡è°ƒæ•´ dilation å‚æ•°å¤§äºŽ 1ï¼Œå¯ä»¥å˜æˆç©ºæ´žå·ç§¯ï¼Œå¢žåŠ æ„Ÿå—é‡Žã€‚ é€šè¿‡è°ƒæ•´ groups å‚æ•°ä¸ä¸º1ï¼Œå¯ä»¥å˜æˆåˆ†ç»„å·ç§¯ã€‚åˆ†ç»„å·ç§¯ä¸­æ¯ä¸ªå·ç§¯æ ¸ä»…å¯¹å…¶å¯¹åº”çš„ä¸€ä¸ªåˆ†ç»„è¿›è¡Œæ“ä½œã€‚ å½“ groups å‚æ•°æ•°é‡ç­‰äºŽè¾“å…¥é€šé“æ•°æ—¶ï¼Œç›¸å½“äºŽ tensorflow ä¸­çš„äºŒç»´æ·±åº¦å·ç§¯å±‚tf.keras.layers.DepthwiseConv2Dã€‚ åˆ©ç”¨åˆ†ç»„å·ç§¯å’Œ1ä¹˜1å·ç§¯çš„ç»„åˆæ“ä½œï¼Œå¯ä»¥æž„é€ ç›¸å½“äºŽ Keras ä¸­çš„äºŒç»´æ·±åº¦å¯åˆ†ç¦»å·ç§¯å±‚tf.keras.layers.SeparableConv2Dã€‚
- nn.Conv3dï¼šæ™®é€šä¸‰ç»´å·ç§¯ï¼Œå¸¸ç”¨äºŽè§†é¢‘ã€‚å‚æ•°ä¸ªæ•° = è¾“å…¥é€šé“æ•°Ã—å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3ä¹˜3)Ã—å·ç§¯æ ¸ä¸ªæ•° + å·ç§¯æ ¸å°ºå¯¸(å¦‚3ä¹˜3ä¹˜3) ã€‚
- nn.MaxPool1d: ä¸€ç»´æœ€å¤§æ± åŒ–ã€‚
- nn.MaxPool2dï¼šäºŒç»´æœ€å¤§æ± åŒ–ã€‚ä¸€ç§ä¸‹é‡‡æ ·æ–¹å¼ã€‚æ²¡æœ‰éœ€è¦è®­ç»ƒçš„å‚æ•°ã€‚
- nn.MaxPool3dï¼šä¸‰ç»´æœ€å¤§æ± åŒ–ã€‚
- nn.AdaptiveMaxPool2dï¼šäºŒç»´è‡ªé€‚åº”æœ€å¤§æ± åŒ–ã€‚æ— è®ºè¾“å…¥å›¾åƒçš„å°ºå¯¸å¦‚ä½•å˜åŒ–ï¼Œè¾“å‡ºçš„å›¾åƒå°ºå¯¸æ˜¯å›ºå®šçš„ã€‚ è¯¥å‡½æ•°çš„å®žçŽ°åŽŸç†ï¼Œå¤§æ¦‚æ˜¯é€šè¿‡è¾“å…¥å›¾åƒçš„å°ºå¯¸å’Œè¦å¾—åˆ°çš„è¾“å‡ºå›¾åƒçš„å°ºå¯¸æ¥åå‘æŽ¨ç®—æ± åŒ–ç®—å­çš„padding,strideç­‰å‚æ•°ã€‚
- nn.FractionalMaxPool2dï¼šäºŒç»´åˆ†æ•°æœ€å¤§æ± åŒ–ã€‚æ™®é€šæœ€å¤§æ± åŒ–é€šå¸¸è¾“å…¥å°ºå¯¸æ˜¯è¾“å‡ºçš„æ•´æ•°å€ã€‚è€Œåˆ†æ•°æœ€å¤§æ± åŒ–åˆ™å¯ä»¥ä¸å¿…æ˜¯æ•´æ•°ã€‚åˆ†æ•°æœ€å¤§æ± åŒ–ä½¿ç”¨äº†ä¸€äº›éšæœºé‡‡æ ·ç­–ç•¥ï¼Œæœ‰ä¸€å®šçš„æ­£åˆ™æ•ˆæžœï¼Œå¯ä»¥ç”¨å®ƒæ¥ä»£æ›¿æ™®é€šæœ€å¤§æ± åŒ–å’Œ Dropout å±‚ã€‚
- nn.AvgPool2dï¼šäºŒç»´å¹³å‡æ± åŒ–ã€‚
- nn.AdaptiveAvgPool2dï¼šäºŒç»´è‡ªé€‚åº”å¹³å‡æ± åŒ–ã€‚æ— è®ºè¾“å…¥çš„ç»´åº¦å¦‚ä½•å˜åŒ–ï¼Œè¾“å‡ºçš„ç»´åº¦æ˜¯å›ºå®šçš„ã€‚
- nn.ConvTranspose2dï¼šäºŒç»´å·ç§¯è½¬ç½®å±‚ï¼Œä¿—ç§°åå·ç§¯å±‚ã€‚å¹¶éžå·ç§¯çš„é€†æ“ä½œï¼Œä½†åœ¨å·ç§¯æ ¸ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œå½“å…¶è¾“å…¥å°ºå¯¸æ˜¯å·ç§¯æ“ä½œè¾“å‡ºå°ºå¯¸çš„æƒ…å†µä¸‹ï¼Œå·ç§¯è½¬ç½®çš„è¾“å‡ºå°ºå¯¸æ°å¥½æ˜¯å·ç§¯æ“ä½œçš„è¾“å…¥å°ºå¯¸ã€‚åœ¨è¯­ä¹‰åˆ†å‰²ä¸­å¯ç”¨äºŽä¸Šé‡‡æ ·ã€‚
- nn.Upsampleï¼šä¸Šé‡‡æ ·å±‚ï¼Œæ“ä½œæ•ˆæžœå’Œæ± åŒ–ç›¸åã€‚å¯ä»¥é€šè¿‡modeå‚æ•°æŽ§åˆ¶ä¸Šé‡‡æ ·ç­–ç•¥ä¸º"nearest"æœ€é‚»è¿‘ç­–ç•¥æˆ–"linear"çº¿æ€§æ’å€¼ç­–ç•¥ã€‚
- nn.Unfoldï¼šæ»‘åŠ¨çª—å£æå–å±‚ã€‚å…¶å‚æ•°å’Œå·ç§¯æ“ä½œnn.Conv2dç›¸åŒã€‚å®žé™…ä¸Šï¼Œå·ç§¯æ“ä½œå¯ä»¥ç­‰ä»·äºŽnn.Unfoldå’Œnn.Linearä»¥åŠnn.Foldçš„ä¸€ä¸ªç»„åˆã€‚ å…¶ä¸­nn.Unfoldæ“ä½œå¯ä»¥ä»Žè¾“å…¥ä¸­æå–å„ä¸ªæ»‘åŠ¨çª—å£çš„æ•°å€¼çŸ©é˜µï¼Œå¹¶å°†å…¶åŽ‹å¹³æˆä¸€ç»´ã€‚åˆ©ç”¨nn.Linearå°†nn.Unfoldçš„è¾“å‡ºå’Œå·ç§¯æ ¸åšä¹˜æ³•åŽï¼Œå†ä½¿ç”¨ nn.Foldæ“ä½œå°†ç»“æžœè½¬æ¢æˆè¾“å‡ºå›¾ç‰‡å½¢çŠ¶ã€‚
- nn.Foldï¼šé€†æ»‘åŠ¨çª—å£æå–å±‚ã€‚

å„ç§å¸¸ç”¨çš„å·ç§¯å±‚å’Œä¸Šé‡‡æ ·å±‚ï¼š

- æ™®é€šå·ç§¯

  ![image-20240723134724344](E:\Study\=my repo\vuepress-hope-bloc\my-docs\src\code\äººå·¥æ™ºèƒ½\Pytorch\assets\image-20240723134724344.png)

- ç©ºæ´žå·ç§¯

  ![image-20240723134732374](E:\Study\=my repo\vuepress-hope-bloc\my-docs\src\code\äººå·¥æ™ºèƒ½\Pytorch\assets\image-20240723134732374.png)

- åˆ†ç»„å·ç§¯ 

- æ·±åº¦å¯åˆ†ç¦»å·ç§¯

- è½¬ç½®å·ç§¯

- ä¸Šé‡‡æ ·å±‚

```py
import torch 
from torch import nn 
import torch.nn.functional as F 

# å·ç§¯è¾“å‡ºå°ºå¯¸è®¡ç®—å…¬å¼ o = (i + 2*p -k')//s  + 1 
# å¯¹ç©ºæ´žå·ç§¯ k' = d(k-1) + 1
# o æ˜¯è¾“å‡ºå°ºå¯¸ï¼Œi æ˜¯è¾“å…¥å°ºå¯¸ï¼Œp æ˜¯ padding å¤§å°ï¼Œ k æ˜¯å·ç§¯æ ¸å°ºå¯¸ï¼Œ sæ˜¯ stride æ­¥é•¿, dæ˜¯ dilation ç©ºæ´žå‚æ•°

inputs = torch.arange(0,25).view(1,1,5,5).float() # i = 5
filters = torch.tensor([[[[1.0,1],[1,1]]]]) # k = 2

outputs = F.conv2d(inputs, filters) # o = (5+2*0-2)//1+1 = 4
outputs_s2 = F.conv2d(inputs, filters, stride=2)  #o = (5+2*0-2)//2+1 = 2
outputs_p1 = F.conv2d(inputs, filters, padding=1) #o = (5+2*1-2)//1+1 = 6
outputs_d2 = F.conv2d(inputs,filters, dilation=2) #o = (5+2*0-(2(2-1)+1))//1+1 = 3


import torch 
from torch import nn 

features = torch.randn(8,64,128,128)
print("features.shape:",features.shape)
print("\n")

# æ™®é€šå·ç§¯
print("--conv--")
conv = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3)
conv_out = conv(features)
print("conv_out.shape:",conv_out.shape) 
print("conv.weight.shape:",conv.weight.shape)
print("\n")

# åˆ†ç»„å·ç§¯
print("--group conv--")
conv_group = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,groups=8)
group_out = conv_group(features)
print("group_out.shape:",group_out.shape) 
print("conv_group.weight.shape:",conv_group.weight.shape)
print("\n")

# æ·±åº¦å¯åˆ†ç¦»å·ç§¯
print("--separable conv--")
depth_conv = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,groups=64)
oneone_conv = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=1)
separable_conv = nn.Sequential(depth_conv,oneone_conv)
separable_out = separable_conv(features)
print("separable_out.shape:",separable_out.shape) 
print("depth_conv.weight.shape:",depth_conv.weight.shape)
print("oneone_conv.weight.shape:",oneone_conv.weight.shape)
print("\n")

# è½¬ç½®å·ç§¯
print("--conv transpose--")
conv_t = nn.ConvTranspose2d(in_channels=32,out_channels=64,kernel_size=3)
features_like = conv_t(conv_out)
print("features_like.shape:",features_like.shape)
print("conv_t.weight.shape:",conv_t.weight.shape)

import torch 
from torch import nn 

inputs = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)
print("inputs:")
print(inputs)
print("\n")

nearest = nn.Upsample(scale_factor=2, mode='nearest')
bilinear = nn.Upsample(scale_factor=2,mode="bilinear",align_corners=True)

print("nearest(inputs)ï¼š")
print(nearest(inputs))
print("\n")
print("bilinear(inputs)ï¼š")
print(bilinear(inputs)) 
```

### 6.2.3ã€å¾ªçŽ¯ç½‘ç»œç›¸å…³å±‚

- nn.LSTMï¼šé•¿çŸ­è®°å¿†å¾ªçŽ¯ç½‘ç»œå±‚ã€æ”¯æŒå¤šå±‚ã€‘ã€‚æœ€æ™®éä½¿ç”¨çš„å¾ªçŽ¯ç½‘ç»œå±‚ã€‚å…·æœ‰æºå¸¦è½¨é“ï¼Œé—å¿˜é—¨ï¼Œæ›´æ–°é—¨ï¼Œè¾“å‡ºé—¨ã€‚å¯ä»¥è¾ƒä¸ºæœ‰æ•ˆåœ°ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä»Žè€Œèƒ½å¤Ÿé€‚ç”¨é•¿æœŸä¾èµ–é—®é¢˜ã€‚è®¾ç½® bidirectional = True æ—¶å¯ä»¥å¾—åˆ°åŒå‘ LSTMã€‚éœ€è¦æ³¨æ„çš„æ—¶ï¼Œé»˜è®¤çš„è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶æ˜¯(seq,batch,feature), å¦‚æžœéœ€è¦å°† batch ç»´åº¦æ”¾åœ¨ç¬¬ 0 ç»´ï¼Œåˆ™è¦è®¾ç½® batch_first å‚æ•°è®¾ç½®ä¸º True
- nn.GRUï¼šé—¨æŽ§å¾ªçŽ¯ç½‘ç»œå±‚ã€æ”¯æŒå¤šå±‚ã€‘ã€‚LSTMçš„ä½Žé…ç‰ˆï¼Œä¸å…·æœ‰æºå¸¦è½¨é“ï¼Œå‚æ•°æ•°é‡å°‘äºŽLSTMï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«
- nn.RNNï¼šç®€å•å¾ªçŽ¯ç½‘ç»œå±‚ã€æ”¯æŒå¤šå±‚ã€‘ã€‚å®¹æ˜“å­˜åœ¨æ¢¯åº¦æ¶ˆå¤±ï¼Œä¸èƒ½å¤Ÿé€‚ç”¨é•¿æœŸä¾èµ–é—®é¢˜ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨
- nn.LSTMCellï¼šé•¿çŸ­è®°å¿†å¾ªçŽ¯ç½‘ç»œå•å…ƒã€‚å’Œ nn.LSTM åœ¨æ•´ä¸ªåºåˆ—ä¸Šè¿­ä»£ç›¸æ¯”ï¼Œå®ƒä»…åœ¨åºåˆ—ä¸Šè¿­ä»£ä¸€æ­¥ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨
- nn.GRUCellï¼šé—¨æŽ§å¾ªçŽ¯ç½‘ç»œå•å…ƒã€‚å’Œ nn.GRU åœ¨æ•´ä¸ªåºåˆ—ä¸Šè¿­ä»£ç›¸æ¯”ï¼Œå®ƒä»…åœ¨åºåˆ—ä¸Šè¿­ä»£ä¸€æ­¥ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨
- nn.RNNCellï¼šç®€å•å¾ªçŽ¯ç½‘ç»œå•å…ƒã€‚å’Œ nn.RNN åœ¨æ•´ä¸ªåºåˆ—ä¸Šè¿­ä»£ç›¸æ¯”ï¼Œå®ƒä»…åœ¨åºåˆ—ä¸Šè¿­ä»£ä¸€æ­¥ã€‚ä¸€èˆ¬è¾ƒå°‘ä½¿ç”¨

å„ç§ RNN åºåˆ—æ¨¡åž‹å±‚(RNN,GRU,LSTM ç­‰)å¯ä»¥ç”¨å‡½æ•°è¡¨ç¤ºå¦‚ä¸‹: $h_t = f(h_{t-1},x_t)$

å…¬å¼çš„å«ä¹‰ï¼št æ—¶åˆ»å¾ªçŽ¯ç¥žç»ç½‘ç»œçš„è¾“å‡ºå‘é‡ â„Žð‘¡ ç”± t-1 æ—¶åˆ»çš„è¾“å‡ºå‘é‡ â„Ž~ð‘¡âˆ’1~ å’Œ t æ—¶åˆ»çš„è¾“å…¥ ð‘–~ð‘¡~ å˜æ¢è€Œæ¥

- LSTM ç»“æž„è§£æžï¼ˆå‚è€ƒæ–‡ç« ï¼šã€Šäººäººéƒ½èƒ½çœ‹æ‡‚çš„ LSTMã€‹https://zhuanlan.zhihu.com/p/32085405ï¼‰

  LSTM é€šè¿‡å¼•å…¥äº†ä¸‰ä¸ªé—¨æ¥æŽ§åˆ¶ä¿¡æ¯çš„ä¼ é€’ï¼Œåˆ†åˆ«æ˜¯é—å¿˜é—¨ï¼Œè¾“å…¥é—¨ å’Œè¾“å‡ºé—¨ ã€‚ä¸‰ä¸ªé—¨çš„ä½œç”¨ä¸ºï¼š

  1. é—å¿˜é—¨: é—å¿˜é—¨ ð‘“~ð‘¡~ æŽ§åˆ¶ä¸Šä¸€æ—¶åˆ»çš„å†…éƒ¨çŠ¶æ€ éœ€è¦é—å¿˜å¤šå°‘ä¿¡æ¯ï¼›
  2. è¾“å…¥é—¨: è¾“å…¥é—¨ ð‘–~ð‘¡~ æŽ§åˆ¶å½“å‰æ—¶åˆ»çš„å€™é€‰çŠ¶æ€ æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦ä¿å­˜ï¼›
  3. è¾“å‡ºé—¨: è¾“å‡ºé—¨ ð‘œ~ð‘¡~ æŽ§åˆ¶å½“å‰æ—¶åˆ»çš„å†…éƒ¨çŠ¶æ€ æœ‰å¤šå°‘ä¿¡æ¯éœ€è¦è¾“å‡ºç»™å¤–éƒ¨çŠ¶æ€ ï¼›

- GRU ç»“æž„è§£æžï¼ˆå‚è€ƒæ–‡ç« ï¼šã€Šäººäººéƒ½èƒ½çœ‹æ‡‚çš„ GRUã€‹https://zhuanlan.zhihu.com/p/32481747ï¼‰

  GRU çš„ç»“æž„æ¯” LSTM æ›´ä¸ºç®€å•ä¸€äº›ï¼ŒGRU åªæœ‰ä¸¤ä¸ªé—¨ï¼Œæ›´æ–°é—¨å’Œé‡ç½®é—¨ 

  1. æ›´æ–°é—¨ï¼šæ›´æ–°é—¨ç”¨äºŽæŽ§åˆ¶æ¯ä¸€æ­¥â„Žð‘¡â„Žð‘¡è¢«æ›´æ–°çš„æ¯”ä¾‹ï¼Œæ›´æ–°é—¨è¶Šå¤§ï¼Œâ„Ž~ð‘¡~ æ›´æ–°å¹…åº¦è¶Šå¤§ã€‚
  2. é‡ç½®é—¨ï¼šé‡ç½®é—¨ç”¨äºŽæŽ§åˆ¶æ›´æ–°å€™é€‰å‘é‡ â„ŽÌƒ~ð‘¡~ ä¸­å‰ä¸€æ­¥çš„çŠ¶æ€ â„Ž~ð‘¡âˆ’1~ è¢«é‡æ–°æ”¾å…¥çš„æ¯”ä¾‹ï¼Œé‡ç½®é—¨è¶Šå¤§ï¼Œæ›´æ–°å€™é€‰å‘é‡ä¸­ â„Ž~ð‘¡âˆ’1~ è¢«é‡æ–°æ”¾è¿›æ¥çš„æ¯”ä¾‹è¶Šå¤§

  å…¬å¼ä¸­çš„å°åœˆè¡¨ç¤ºå“ˆè¾¾çŽ›ç§¯ï¼Œä¹Ÿå°±æ˜¯ä¸¤ä¸ªå‘é‡é€ä½ç›¸ä¹˜

  å…¶ä¸­ 1å¼å’Œ 2å¼è®¡ç®—çš„æ˜¯æ›´æ–°é—¨ ð‘¢~ð‘¡~ å’Œé‡ç½®é—¨ ð‘Ÿ~ð‘¡~ï¼Œæ˜¯ä¸¤ä¸ªé•¿åº¦å’Œ â„Ž~ð‘¡~ ç›¸åŒçš„å‘é‡ã€‚

  æ³¨æ„åˆ° 4å¼å®žé™…ä¸Šå’Œ ResNet çš„æ®‹å·®ç»“æž„æ˜¯ç›¸ä¼¼çš„ï¼Œéƒ½æ˜¯ f(x) = x + g(x) çš„å½¢å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°é˜²æ­¢é•¿åºåˆ—å­¦ä¹ åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚

```py
import torch 
from torch import nn 

inputs = torch.randn(8,200,64) #batch_size, seq_length, features

gru = nn.GRU(input_size=64,hidden_size=32,num_layers=1,batch_first=True)
gru_output,gru_hn = gru(inputs)
print("--GRU--")
print("gru_output.shape:",gru_output.shape)
print("gru_hn.shape:",gru_hn.shape)
print("\n")

print("--LSTM--")
lstm = nn.LSTM(input_size=64,hidden_size=32,num_layers=1,batch_first=True)
lstm_output,(lstm_hn,lstm_cn) = lstm(inputs)
print("lstm_output.shape:",lstm_output.shape)
print("lstm_hn.shape:",lstm_hn.shape)
print("lstm_cn.shape:",lstm_cn.shape)

from torchkeras import summary
summary(gru,input_data=inputs);
summary(lstm,input_data=inputs);
```

### 6.2.4ã€Transformer ç›¸å…³å±‚

- nn.Transformerï¼šTransformerç½‘ç»œç»“æž„ã€‚Transformerç½‘ç»œç»“æž„æ˜¯æ›¿ä»£å¾ªçŽ¯ç½‘ç»œçš„ä¸€ç§ç»“æž„ï¼Œè§£å†³äº†å¾ªçŽ¯ç½‘ç»œéš¾ä»¥å¹¶è¡Œï¼Œéš¾ä»¥æ•æ‰é•¿æœŸä¾èµ–çš„ç¼ºé™·ã€‚å®ƒæ˜¯ç›®å‰NLPä»»åŠ¡çš„ä¸»æµæ¨¡åž‹çš„ä¸»è¦æž„æˆéƒ¨åˆ†ã€‚
- nn.TransformerEncoderï¼šTransformerç¼–ç å™¨ç»“æž„ã€‚ç”±å¤šä¸ª nn.TransformerEncoderLayerç¼–ç å™¨å±‚ç»„æˆã€‚
- nn.TransformerDecoderï¼šTransformerè§£ç å™¨ç»“æž„ã€‚ç”±å¤šä¸ª nn.TransformerDecoderLayerè§£ç å™¨å±‚ç»„æˆã€‚
- nn.TransformerEncoderLayerï¼šTransformerçš„ç¼–ç å™¨å±‚ã€‚ä¸»è¦ç”±Multi-Head self-Attention, Feed-Forwardå‰é¦ˆç½‘ç»œ, LayerNormå½’ä¸€åŒ–å±‚, ä»¥åŠæ®‹å·®è¿žæŽ¥å±‚ç»„æˆã€‚
- nn.TransformerDecoderLayerï¼šTransformerçš„è§£ç å™¨å±‚ã€‚ä¸»è¦ç”±Masked Multi-Head self-Attention, Multi-Head cross-Attention, Feed-Forwardå‰é¦ˆç½‘ç»œ, LayerNormå½’ä¸€åŒ–å±‚, ä»¥åŠæ®‹å·®è¿žæŽ¥å±‚ç»„æˆã€‚
- nn.MultiheadAttentionï¼šå¤šå¤´æ³¨æ„åŠ›å±‚ã€‚ç”¨äºŽåœ¨åºåˆ—æ–¹å‘ä¸Šèžåˆç‰¹å¾ã€‚ä½¿ç”¨çš„æ˜¯Scaled Dot Production Attentionï¼Œå¹¶å¼•å…¥äº†å¤šä¸ªæ³¨æ„åŠ›å¤´ã€‚

å‚è€ƒé˜…è¯»ææ–™ï¼š  
TransformerçŸ¥ä¹ŽåŽŸç†è®²è§£ï¼šhttps://zhuanlan.zhihu.com/p/48508221  
Transformerå“ˆä½›åšå®¢ä»£ç è®²è§£ï¼šhttp://nlp.seas.harvard.edu/annotated-transformer/

```py
import torch 
from torch import nn 

# éªŒè¯ MultiheadAttention å’Œ head æ•°é‡æ— å…³
inputs = torch.randn(8,200,64) # batch_size, seq_length, features
attention_h8 = nn.MultiheadAttention(
    embed_dim = 64,
    num_heads = 8,
    bias=True,
    batch_first=True
)
attention_h16 = nn.MultiheadAttention(
    embed_dim = 64,
    num_heads = 16,
    bias=True,
    batch_first=True
)
out_h8 = attention_h8(inputs,inputs,inputs)
out_h16 = attention_h16(inputs,inputs,inputs)

from torchkeras import summary 
summary(attention_h8,input_data_args=(inputs,inputs,inputs));
summary(attention_h16,input_data_args=(inputs,inputs,inputs));
```

```py
import torch 
from torch import nn 
from copy import deepcopy

# å¤šå¤´æ³¨æ„åŠ›çš„ä¸€ç§ç®€æ´å®žçŽ°

class ScaledDotProductAttention(nn.Module):
    "Compute 'Scaled Dot Product Attention'"
    def __init__(self):
        super(ScaledDotProductAttention, self).__init__()

    def forward(self,query, key, value, mask=None, dropout=None):
        d_k = query.size(-1)
        scores = query@key.transpose(-2,-1) / d_k**0.5     
        if mask is not None:
            scores = scores.masked_fill(mask == 0, -1e20)
        p_attn = F.softmax(scores, dim = -1)
        if dropout is not None:
            p_attn = dropout(p_attn)
        return p_attn@value, p_attn
    
class MultiHeadAttention(nn.Module):
    def __init__(self, h, d_model, dropout=0.1):
        "Take in model size and number of heads."
        super(MultiHeadAttention, self).__init__()
        assert d_model % h == 0
        # We assume d_v always equals d_k
        self.d_k = d_model // h
        self.h = h
        self.linears = nn.ModuleList([deepcopy(nn.Linear(d_model, d_model)) for _ in range(4)])
        
        self.attn = None
        self.dropout = nn.Dropout(p=dropout)
        self.attention = ScaledDotProductAttention()
        
    def forward(self, query, key, value, mask=None):
        "Implements Figure 2"
        if mask is not None:
            # Same mask applied to all h heads.
            mask = mask.unsqueeze(1)
        nbatches = query.size(0)
        
        # 1) Do all the linear projections in batch from d_model => h x d_k 
        query, key, value = \
            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)
             for l, x in zip(self.linears, (query, key, value))]
        
        # 2) Apply attention on all the projected vectors in batch. 
        x, self.attn = self.attention(query, key, value, mask=mask, 
                                 dropout=self.dropout)
        
        # 3) "Concat" using a view and apply a final linear. 
        x = x.transpose(1, 2).contiguous() \
             .view(nbatches, -1, self.h * self.d_k)
        return self.linears[-1](x)
    
```

### 6.2.5ã€è‡ªå®šä¹‰æ¨¡åž‹å±‚

å¦‚æžœ Pytorch çš„å†…ç½®æ¨¡åž‹å±‚ä¸èƒ½å¤Ÿæ»¡è¶³éœ€æ±‚ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ç»§æ‰¿ nn.Module åŸºç±»æž„å»ºè‡ªå®šä¹‰çš„æ¨¡åž‹å±‚

å®žé™…ä¸Šï¼Œpytorch ä¸åŒºåˆ†æ¨¡åž‹å’Œæ¨¡åž‹å±‚ï¼Œéƒ½æ˜¯é€šè¿‡ç»§æ‰¿ nn.Module è¿›è¡Œæž„å»ºã€‚

å› æ­¤ï¼Œæˆ‘ä»¬åªè¦ç»§æ‰¿ nn.Module åŸºç±»å¹¶å®žçŽ° forward æ–¹æ³•å³å¯è‡ªå®šä¹‰æ¨¡åž‹å±‚ã€‚

ä¸‹é¢æ˜¯ Pytorch çš„ nn.Linear å±‚çš„æºç ï¼Œæˆ‘ä»¬å¯ä»¥ä»¿ç…§å®ƒæ¥è‡ªå®šä¹‰æ¨¡åž‹å±‚ã€‚

```py
import torch
from torch import nn
import torch.nn.functional as F

class Linear(nn.Module):
    __constants__ = ['in_features', 'out_features']

    def __init__(self, in_features, out_features, bias=True):
        super(Linear, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))
        if bias:
            self.bias = nn.Parameter(torch.Tensor(out_features))
        else:
            self.register_parameter('bias', None)
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, input):
        return F.linear(input, self.weight, self.bias)

    def extra_repr(self):
        return 'in_features={}, out_features={}, bias={}'.format(
            self.in_features, self.out_features, self.bias is not None
        )
```

## 6.3ã€æŸå¤±å‡½æ•° losses

ä¸€èˆ¬æ¥è¯´ï¼Œç›‘ç£å­¦ä¹ çš„ç›®æ ‡å‡½æ•°ç”±æŸå¤±å‡½æ•°å’Œæ­£åˆ™åŒ–é¡¹ç»„æˆã€‚(Objective = Loss + Regularization)

Pytorch ä¸­çš„æŸå¤±å‡½æ•°ä¸€èˆ¬åœ¨è®­ç»ƒæ¨¡åž‹æ—¶å€™æŒ‡å®š

> Pytorch ä¸­å†…ç½®çš„æŸå¤±å‡½æ•°çš„å‚æ•°å’Œ tensorflow ä¸åŒï¼Œæ˜¯ y_pred åœ¨å‰ï¼Œy_true åœ¨åŽï¼Œè€Œ Tensorflow æ˜¯ y_true åœ¨å‰ï¼Œy_pred åœ¨åŽ

- å¯¹äºŽ **å›žå½’æ¨¡åž‹**ï¼Œé€šå¸¸ä½¿ç”¨çš„å†…ç½®æŸå¤±å‡½æ•°æ˜¯ **å‡æ–¹æŸå¤±å‡½æ•° nn.MSELoss**

- å¯¹äºŽ **äºŒåˆ†ç±»æ¨¡åž‹**ï¼Œé€šå¸¸ä½¿ç”¨çš„æ˜¯ **äºŒå…ƒäº¤å‰ç†µæŸå¤±å‡½æ•°nn.BCELoss** (è¾“å…¥å·²ç»æ˜¯ sigmoid æ¿€æ´»å‡½æ•°ä¹‹åŽçš„ç»“æžœ) æˆ–è€… nn.BCEWithLogitsLoss (è¾“å…¥å°šæœªç»è¿‡ nn.Sigmoid æ¿€æ´»å‡½æ•°) 

- å¯¹äºŽ **å¤šåˆ†ç±»æ¨¡åž‹**ï¼Œä¸€èˆ¬æŽ¨èä½¿ç”¨ **äº¤å‰ç†µæŸå¤±å‡½æ•° nn.CrossEntropyLoss** (y_true éœ€è¦æ˜¯ä¸€ç»´çš„ï¼Œæ˜¯ç±»åˆ«ç¼–ç ã€‚y_pred æœªç»è¿‡ nn.Softmax æ¿€æ´»)

  æ­¤å¤–ï¼Œå¦‚æžœå¤šåˆ†ç±»çš„ y_pred ç»è¿‡äº† nn.LogSoftmax æ¿€æ´»ï¼Œå¯ä»¥ä½¿ç”¨ nn.NLLLoss æŸå¤±å‡½æ•°(The negative log likelihood loss)ã€‚ è¿™ç§æ–¹æ³•å’Œç›´æŽ¥ä½¿ç”¨ nn.CrossEntropyLoss ç­‰ä»·

å¦‚æžœæœ‰éœ€è¦ï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼Œè‡ªå®šä¹‰æŸå¤±å‡½æ•°éœ€è¦æŽ¥æ”¶ä¸¤ä¸ªå¼ é‡ y_predï¼Œy_true ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæ ‡é‡ä½œä¸ºæŸå¤±å‡½æ•°å€¼

Pytorch ä¸­çš„æ­£åˆ™åŒ–é¡¹ä¸€èˆ¬é€šè¿‡è‡ªå®šä¹‰çš„æ–¹å¼å’ŒæŸå¤±å‡½æ•°ä¸€èµ·æ·»åŠ ä½œä¸ºç›®æ ‡å‡½æ•°

å¦‚æžœä»…ä»…ä½¿ç”¨ L2 æ­£åˆ™åŒ–ï¼Œä¹Ÿå¯ä»¥åˆ©ç”¨ä¼˜åŒ–å™¨çš„ weight_decay å‚æ•°æ¥å®žçŽ°ç›¸åŒçš„æ•ˆæžœ

### 6.3.1ã€å†…ç½®æŸå¤±å‡½æ•°

å†…ç½®çš„æŸå¤±å‡½æ•°ä¸€èˆ¬æœ‰ç±»çš„å®žçŽ°å’Œå‡½æ•°çš„å®žçŽ°ä¸¤ç§å½¢å¼

ç±»çš„å®žçŽ°å½¢å¼é€šå¸¸æ˜¯è°ƒç”¨å‡½æ•°çš„å®žçŽ°å½¢å¼å¹¶ç”¨ nn.Module å°è£…åŽå¾—åˆ°çš„

æˆ‘ä»¬å¸¸ç”¨çš„æ˜¯ç±»çš„å®žçŽ°å½¢å¼ã€‚å®ƒä»¬å°è£…åœ¨ torch.nn æ¨¡å—ä¸‹ï¼Œå¹¶ä¸”ç±»åä»¥ Loss ç»“å°¾

å¸¸ç”¨çš„ä¸€äº›å†…ç½®æŸå¤±å‡½æ•°è¯´æ˜Žå¦‚ä¸‹ï¼š

- nn.MSELossï¼ˆå‡æ–¹è¯¯å·®æŸå¤±ï¼Œä¹Ÿå«åš L2 æŸå¤±ï¼Œç”¨äºŽå›žå½’ï¼‰
- nn.L1Loss ï¼ˆL1 æŸå¤±ï¼Œä¹Ÿå«åšç»å¯¹å€¼è¯¯å·®æŸå¤±ï¼Œç”¨äºŽå›žå½’ï¼‰
- nn.SmoothL1Loss (å¹³æ»‘ L1 æŸå¤±ï¼Œå½“è¾“å…¥åœ¨ -1 åˆ° 1 ä¹‹é—´æ—¶ï¼Œå¹³æ»‘ä¸º L2 æŸå¤±ï¼Œç”¨äºŽå›žå½’)
- nn.BCELoss (äºŒå…ƒäº¤å‰ç†µï¼Œç”¨äºŽäºŒåˆ†ç±»ï¼Œè¾“å…¥å·²ç»è¿‡ nn.Sigmoid æ¿€æ´»ï¼Œå¯¹ä¸å¹³è¡¡æ•°æ®é›†å¯ä»¥ç”¨ weigths å‚æ•°è°ƒæ•´ç±»åˆ«æƒé‡)
- nn.BCEWithLogitsLoss (äºŒå…ƒäº¤å‰ç†µï¼Œç”¨äºŽäºŒåˆ†ç±»ï¼Œè¾“å…¥æœªç»è¿‡ nn.Sigmoid æ¿€æ´»)
- nn.CrossEntropyLoss (äº¤å‰ç†µï¼Œç”¨äºŽå¤šåˆ†ç±»ï¼Œè¦æ±‚labelä¸ºç¨€ç–ç¼–ç ï¼Œè¾“å…¥æœªç»è¿‡ nn.Softmax æ¿€æ´»ï¼Œå¯¹ä¸å¹³è¡¡æ•°æ®é›†å¯ä»¥ç”¨ weigths å‚æ•°è°ƒæ•´ç±»åˆ«æƒé‡)
- nn.NLLLoss (è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ï¼Œç”¨äºŽå¤šåˆ†ç±»ï¼Œè¦æ±‚ label ä¸ºç¨€ç–ç¼–ç ï¼Œè¾“å…¥ç»è¿‡ nn.LogSoftmax æ¿€æ´»)
- nn.KLDivLoss (KL æ•£åº¦æŸå¤±ï¼Œä¹Ÿå«ç›¸å¯¹ç†µï¼Œç­‰äºŽäº¤å‰ç†µå‡åŽ»ä¿¡æ¯ç†µï¼Œç”¨äºŽæ ‡ç­¾ä¸ºæ¦‚çŽ‡å€¼çš„å¤šåˆ†ç±»ï¼Œè¦æ±‚è¾“å…¥ç»è¿‡ nn.LogSoftmax æ¿€æ´»)
- nn.CosineSimilarity(ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œå¯ç”¨äºŽå¤šåˆ†ç±»)
- nn.AdaptiveLogSoftmaxWithLoss (ä¸€ç§é€‚åˆéžå¸¸å¤šç±»åˆ«ä¸”ç±»åˆ«åˆ†å¸ƒå¾ˆä¸å‡è¡¡çš„æŸå¤±å‡½æ•°ï¼Œä¼šè‡ªé€‚åº”åœ°å°†å¤šä¸ªå°ç±»åˆ«åˆæˆä¸€ä¸ª cluster)

äºŒå…ƒäº¤å‰ç†µã€å¤šå…ƒäº¤å‰ç†µã€å¯¹æ•°æŸå¤± LogLossã€è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤± NLLLossã€KL æ•£åº¦ä¹‹é—´çš„åŒºåˆ«å’Œè”ç³»ï¼šç•¥

```py
import numpy as np
import pandas as pd
import torch 
from torch import nn 
import torch.nn.functional as F 

# nn.BCELoss() å’Œ nn.BCEWithLogitsLoss() å…³ç³»
y_pred = torch.tensor([5.0,3,10,-5,-3,-10.0])
y_true = torch.tensor([1.0,1,1,0,0,0])

bce = nn.BCELoss()(torch.sigmoid(y_pred),y_true)
print(bce)


bce_logits = nn.BCEWithLogitsLoss()(y_pred,y_true)
print(bce_logits)

# nn.CrossEntropyLoss() å’Œ  nn.NLLLoss() å…³ç³»
y_pred = torch.tensor([[10.0,0.0,-10.0],[8.0,8.0,8.0]])
y_true = torch.tensor([0,2])

# ç›´æŽ¥è°ƒç”¨äº¤å‰ç†µæŸå¤±
ce = nn.CrossEntropyLoss()(y_pred,y_true)
print(ce)

# ç­‰ä»·äºŽå…ˆè®¡ç®— nn.LogSoftmax æ¿€æ´»ï¼Œå†è°ƒç”¨ nn.NLLLoss
y_pred_logsoftmax = nn.LogSoftmax(dim = 1)(y_pred)
nll = nn.NLLLoss()(y_pred_logsoftmax,y_true)
print(nll)

# nn.CrossEntropyLoss() å’Œ  KLDivLoss å…³ç³»
import torch.nn.functional as F 

y_pred = torch.tensor([[10.0,0.0,-10.0],[8.0,8.0,8.0]],requires_grad=True)
y_true = torch.tensor([0,2])

ce = nn.CrossEntropyLoss(reduction="mean")(y_pred,y_true)
print(ce)


#KLDivLossè¦æ±‚targetä¸ºå‘é‡å½¢å¼ç¼–ç ä¸”predsç»è¿‡LogSoftmaxæ¿€æ´»
pred = F.log_softmax(y_pred,dim=1)
target = F.one_hot(y_true).float()
kl = nn.KLDivLoss(reduction="batchmean")(pred,target)
print(kl)
```

### 6.3.2ã€è‡ªå®šä¹‰æŸå¤±å‡½æ•°

è‡ªå®šä¹‰æŸå¤±å‡½æ•°æŽ¥æ”¶ä¸¤ä¸ªå¼ é‡ y_pred , y_true ä½œä¸ºè¾“å…¥å‚æ•°ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªæ ‡é‡ä½œä¸ºæŸå¤±å‡½æ•°å€¼

ä¹Ÿå¯ä»¥å¯¹ nn.Module è¿›è¡Œå­ç±»åŒ–ï¼Œé‡å†™ forward æ–¹æ³•å®žçŽ°æŸå¤±çš„è®¡ç®—é€»è¾‘ï¼Œä»Žè€Œå¾—åˆ°æŸå¤±å‡½æ•°çš„ç±»çš„å®žçŽ°

#### è‡ªå®šä¹‰æŸå¤±å‡½æ•° FocalLoss èŒƒä¾‹

Focal Lossæ˜¯ä¸€ç§å¯¹ binary_crossentropy çš„æ”¹è¿›æŸå¤±å‡½æ•°å½¢å¼

å®ƒåœ¨æ ·æœ¬ä¸å‡è¡¡å’Œå­˜åœ¨è¾ƒå¤šæ˜“åˆ†ç±»çš„æ ·æœ¬æ—¶ç›¸æ¯” binary_crossentropy å…·æœ‰æ˜Žæ˜¾çš„ä¼˜åŠ¿

å®ƒæœ‰ä¸¤ä¸ªå¯è°ƒå‚æ•°ï¼Œalpha å‚æ•°å’Œ gamma å‚æ•°ã€‚å…¶ä¸­ alpha å‚æ•°ä¸»è¦ç”¨äºŽè¡°å‡è´Ÿæ ·æœ¬çš„æƒé‡ï¼Œgamma å‚æ•°ä¸»è¦ç”¨äºŽè¡°å‡å®¹æ˜“è®­ç»ƒæ ·æœ¬çš„æƒé‡ã€‚ä»Žè€Œè®©æ¨¡åž‹æ›´åŠ èšç„¦åœ¨æ­£æ ·æœ¬å’Œå›°éš¾æ ·æœ¬ä¸Šã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆè¿™ä¸ªæŸå¤±å‡½æ•°å«åš Focal Lossã€‚

![image-20240724160609623](E:\Study\=my repo\vuepress-hope-bloc\my-docs\src\code\äººå·¥æ™ºèƒ½\Pytorch\assets\image-20240724160609623.png)

```py
import torch 
from torch import nn 
class FocalLoss(nn.Module):

    def __init__(self,gamma=2.0,alpha=0.75):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha

    def forward(self,y_pred,y_true):
        bce = torch.nn.BCELoss(reduction = "none")(y_pred,y_true)
        p_t = (y_true * y_pred) + ((1 - y_true) * (1 - y_pred))
        alpha_factor = y_true * self.alpha + (1 - y_true) * (1 - self.alpha)
        modulating_factor = torch.pow(1.0 - p_t, self.gamma)
        loss = torch.mean(alpha_factor * modulating_factor * bce)
        return loss
    
    
# å›°éš¾æ ·æœ¬
y_pred_hard = torch.tensor([[0.5],[0.5]])
y_true_hard = torch.tensor([[1.0],[0.0]])

# å®¹æ˜“æ ·æœ¬
y_pred_easy = torch.tensor([[0.9],[0.1]])
y_true_easy = torch.tensor([[1.0],[0.0]])

focal_loss = FocalLoss()
bce_loss = nn.BCELoss()


print("focal_loss(easy samples):", focal_loss(y_pred_easy,y_true_easy)) # tensor(0.0005)
print("bce_loss(easy samples):", bce_loss(y_pred_easy,y_true_easy)) # tensor(0.1054)

print("focal_loss(hard samples):", focal_loss(y_pred_hard,y_true_hard)) # tensor(0.0866)
print("bce_loss(hard samples):", bce_loss(y_pred_hard,y_true_hard)) # tensor(0.6931)


#å¯è§ focal_loss è®©å®¹æ˜“æ ·æœ¬çš„æƒé‡è¡°å‡åˆ°åŽŸæ¥çš„ 0.0005/0.1054 = 0.00474
#è€Œè®©å›°éš¾æ ·æœ¬çš„æƒé‡åªè¡°å‡åˆ°åŽŸæ¥çš„ 0.0866/0.6931=0.12496

# å› æ­¤ç›¸å¯¹è€Œè¨€ï¼Œfocal_losså¯ä»¥è¡°å‡å®¹æ˜“æ ·æœ¬çš„æƒé‡ã€‚

```

#### SCELoss æ¡ˆä¾‹

Symmetric Cross Entropy Loss ä¹Ÿæ˜¯ä¸€ç§å¯¹äº¤å‰ç†µæŸå¤±çš„æ”¹è¿›æŸå¤±ï¼Œä¸»è¦ç”¨åœ¨æ ‡ç­¾ä¸­å­˜åœ¨æ˜Žæ˜¾å™ªå£°çš„åœºæ™¯ã€‚

```py
def ce(y,p):
    p = torch.clamp(p,min=1e-4,max=1-1e-4)
    y = torch.clamp(y,min=1e-4,max=1-1e-4)
    return -y*torch.log(p) - (1-y)*torch.log(1-p)

def rce(y,p):
    return ce(p,y)

# æ­£å¸¸æ ‡ç­¾
y = torch.tensor(1.0)
p = torch.tensor(0.8)
print(rce(y,p)/ce(y,p)) # tensor(8.2502)


# å™ªå£°æ ‡ç­¾
y = torch.tensor(0.0)
p = torch.tensor(0.8)
print(rce(y,p)/ce(y,p)) # tensor(4.5786)
```

```py
import torch 
from torch import nn
import  torch.nn.functional as F 

class SCELoss(nn.Module):
    def __init__(self, num_classes=10, a=1, b=1):
        super(SCELoss, self).__init__()
        self.num_classes = num_classes
        self.a = a #ä¸¤ä¸ªè¶…å‚æ•°
        self.b = b
        self.cross_entropy = nn.CrossEntropyLoss()

    def forward(self, pred, labels):
        # CE éƒ¨åˆ†ï¼Œæ­£å¸¸çš„äº¤å‰ç†µæŸå¤±
        ce = self.cross_entropy(pred, labels)
        # RCE
        pred = F.softmax(pred, dim=1)
        pred = torch.clamp(pred, min=1e-4, max=1.0)
        label_one_hot = F.one_hot(labels, self.num_classes).float().to(pred.device)
        label_one_hot = torch.clamp(label_one_hot, min=1e-4, max=1.0) #æœ€å°è®¾ä¸º 1e-4ï¼Œå³ A å– -4
        rce = (-1 * torch.sum(pred * torch.log(label_one_hot), dim=1))

        loss = self.a * ce + self.b * rce.mean()
        return loss
    
```

### 6.3.3ã€L1 å’Œ L2æ­£åˆ™åŒ–é¡¹

L1 æ­£åˆ™ã€L2 æ­£åˆ™ã€Dropoutã€Early_stopping æ˜¯ç¥žç»ç½‘ç»œå¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼ˆæ­£åˆ™åŒ–ï¼šé˜²æ­¢æ¨¡åž‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡æ‹Ÿåˆï¼‰

é€šå¸¸è®¤ä¸º L1 æ­£åˆ™åŒ–å¯ä»¥äº§ç”Ÿç¨€ç–æƒå€¼çŸ©é˜µï¼Œå³äº§ç”Ÿä¸€ä¸ªå‚æ•°ç¨€ç–çš„æ¨¡åž‹ã€‚è€Œ L2 æ­£åˆ™åŒ–å¯ä»¥è®©æ¨¡åž‹çš„å‚æ•°å–ç»å¯¹å€¼è¾ƒå°çš„æ•°

è€ƒè™‘ä¸¤ç§æ­£åˆ™åŒ–å‡½æ•°çš„ç­‰å€¼é¢ä¸ŽåŽŸå§‹ Loss å‡½æ•°çš„ç­‰å€¼é¢çš„å…³ç³»ã€‚

- ä»¥äºŒç»´æƒ…å†µä¸ºä¾‹ï¼ŒL1 æ­£åˆ™åŒ–å‡½æ•°çš„ç­‰å€¼é¢æ˜¯ä¸ªè±å½¢ï¼ŒL2 æ­£åˆ™åŒ–å‡½æ•°çš„ç­‰å€¼é¢æ˜¯ä¸ªåœ†å½¢ã€‚æœ€ä¼˜å‚æ•°å¿…å®šå–åœ¨æ­£åˆ™åŒ–å‡½æ•°çš„æŸæ¡ç­‰å€¼é¢å’ŒåŽŸå§‹Losså‡½æ•°çš„æŸæ¡ç­‰å€¼é¢çš„åˆ‡ç‚¹å¤„ã€‚

- ä»Žæ±‚å¯¼è§’åº¦è€ƒè™‘ï¼Œæœ€ä¼˜å‚æ•°æ˜¯ä¸ªæžå€¼ç‚¹ï¼Œè¦æ±‚è¯¥å¤„ æ­£åˆ™åŒ–å‡½æ•°çš„æ¢¯åº¦ç­‰äºŽ åŽŸå§‹Losså‡½æ•°çš„æ¢¯åº¦çš„è´Ÿæ•°ã€‚

  è€Œæ¢¯åº¦æ–¹å‘å¿…å®šåž‚ç›´äºŽç­‰å€¼é¢çš„åˆ‡çº¿æ–¹å‘ï¼Œæ‰€ä»¥å¯ä»¥æŽ¨æ–­å¿…å®šæžå€¼ç‚¹å¿…å®šåœ¨æ­£åˆ™åŒ–å‡½æ•°æŸæ¡ç­‰å€¼é¢å’ŒåŽŸå§‹Losså‡½æ•°çš„æŸæ¡ç­‰å€¼é¢çš„åˆ‡ç‚¹å¤„ã€‚

- ä»Žæ•°å€¼è§’åº¦è€ƒè™‘ï¼Œå¦‚æžœè¯¥æžå€¼ç‚¹ä¸åœ¨ä¸¤ä¸ªç­‰å€¼é¢çš„åˆ‡ç‚¹ï¼Œé‚£ä¹ˆæ²¿ç€åŽŸå§‹å‡½æ•°Lossçš„ç­‰å€¼é¢(åŽŸå§‹Lossä¸å˜)ï¼Œä¸€å®šå¯ä»¥æ‰¾åˆ°ä¸€ä¸ªç‚¹æ­£åˆ™åŒ–å‡½æ•°å–å€¼æ›´å°ã€‚

  è¿™æ ·å°±ç”¨åè¯æ³•è¯æ˜Žäº†æœ€ä¼˜å‚æ•°å¿…å®šå–åœ¨æ­£åˆ™åŒ–å‡½æ•°çš„æŸæ¡ç­‰å€¼é¢å’ŒåŽŸå§‹Losså‡½æ•°çš„æŸæ¡ç­‰å€¼é¢çš„åˆ‡ç‚¹å¤„ã€‚

ç”±äºŽ L1 æ­£åˆ™åŒ–å‡½æ•°çš„ç­‰å€¼é¢æ˜¯ä¸ªè±å½¢ï¼Œæ›´å®¹æ˜“å’Œå‡¸çš„ Loss å‡½æ•°çš„ç­‰å€¼é¢ç›¸åˆ‡åœ¨åæ ‡è½´ä¸Šï¼Œæ‰€ä»¥å€¾å‘äºŽå–å¾—å‚æ•°ç¨€ç–çš„æ¨¡åž‹ï¼Œè€Œ L2 æ­£åˆ™åŒ–åˆ™æ›´å€¾å‘äºŽä½¿å¾—æžå°ç‚¹åˆ°åæ ‡åŽŸç‚¹çš„è·ç¦»æ›´è¿‘ï¼Œä½†ä¸ä¼šå¯¼è‡´å‚æ•°ç¨€ç–ã€‚

```py
import torch 
# L2 æ­£åˆ™åŒ–
def L2Loss(model,alpha):
    l2_loss = torch.tensor(0.0, requires_grad=True)
    for name, param in model.named_parameters():
        if 'bias' not in name: # ä¸€èˆ¬ä¸å¯¹åç½®é¡¹ä½¿ç”¨æ­£åˆ™
            l2_loss = l2_loss + (0.5 * alpha * torch.sum(torch.pow(param, 2)))
    return l2_loss

# L1 æ­£åˆ™åŒ–
def L1Loss(model,beta):
    l1_loss = torch.tensor(0.0, requires_grad=True)
    for name, param in model.named_parameters():
        if 'bias' not in name:
            l1_loss = l1_loss +  beta * torch.sum(torch.abs(param))
    return l1_loss
```

### 6.3.4ã€L1L2 æ­£åˆ™é¡¹ä½¿ç”¨å®Œæ•´èŒƒä¾‹

ä»¥ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ä¸ºä¾‹ï¼Œæ¼”ç¤ºç»™æ¨¡åž‹çš„ç›®æ ‡å‡½æ•°æ·»åŠ è‡ªå®šä¹‰L1å’ŒL2æ­£åˆ™åŒ–é¡¹çš„æ–¹æ³•ã€‚

è¿™ä¸ªèŒƒä¾‹åŒæ—¶æ¼”ç¤ºäº†ä»¥ä¸‹ FocalLoss çš„ä½¿ç”¨ã€‚

1. å‡†å¤‡æ•°æ®

   ```py
   import numpy as np 
   import pandas as pd 
   from matplotlib import pyplot as plt
   import torch
   from torch import nn
   import torch.nn.functional as F
   from torch.utils.data import Dataset,DataLoader,TensorDataset
   import torchkeras 
   %matplotlib inline
   %config InlineBackend.figure_format = 'svg'
   
   # æ­£è´Ÿæ ·æœ¬æ•°é‡
   n_positive,n_negative = 1000,6000
   
   # ç”Ÿæˆæ­£æ ·æœ¬, å°åœ†çŽ¯åˆ†å¸ƒ
   r_p = 5.0 + torch.normal(0.0,1.0,size = [n_positive,1]) 
   theta_p = 2*np.pi*torch.rand([n_positive,1])
   Xp = torch.cat([r_p*torch.cos(theta_p),r_p*torch.sin(theta_p)],axis = 1)
   Yp = torch.ones_like(r_p)
   
   # ç”Ÿæˆè´Ÿæ ·æœ¬, å¤§åœ†çŽ¯åˆ†å¸ƒ
   r_n = 8.0 + torch.normal(0.0,1.0,size = [n_negative,1]) 
   theta_n = 2*np.pi*torch.rand([n_negative,1])
   Xn = torch.cat([r_n*torch.cos(theta_n),r_n*torch.sin(theta_n)],axis = 1)
   Yn = torch.zeros_like(r_n)
   
   # æ±‡æ€»æ ·æœ¬
   X = torch.cat([Xp,Xn],axis = 0)
   Y = torch.cat([Yp,Yn],axis = 0)
   
   
   # å¯è§†åŒ–
   plt.figure(figsize = (6,6))
   plt.scatter(Xp[:,0],Xp[:,1],c = "r")
   plt.scatter(Xn[:,0],Xn[:,1],c = "g")
   plt.legend(["positive","negative"]);
   
   # åˆ›å»º TensorDatasetï¼Œç”¨äºŽå­˜å‚¨ç‰¹å¾å’Œæ ‡ç­¾
   ds = TensorDataset(X,Y)
   # å°†æ•°æ®é›†æŒ‰ 7:3 æ¯”ä¾‹åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶åˆ›å»º DataLoader ç”¨äºŽæ‰¹é‡æ•°æ®åŠ è½½
   ds_train,ds_val = torch.utils.data.random_split(ds,[int(len(ds)*0.7),len(ds)-int(len(ds)*0.7)])
   dl_train = DataLoader(ds_train,batch_size = 100,shuffle=True,num_workers=2)
   dl_val = DataLoader(ds_val,batch_size = 100,num_workers=2)
   #èŽ·å–ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®
   features,labels = next(iter(dl_train))
   ```

2. å®šä¹‰æ¨¡åž‹

   ```py
   class Net(nn.Module):
       def __init__(self):
           super().__init__()
           # ç®€å•çš„ä¸‰å±‚å…¨è¿žæŽ¥ç¥žç»ç½‘ç»œã€‚fc1ã€fc2 å’Œ fc3 åˆ†åˆ«æ˜¯ä¸‰å±‚çš„å…¨è¿žæŽ¥å±‚
           self.fc1 = nn.Linear(2,4)
           self.fc2 = nn.Linear(4,8) 
           self.fc3 = nn.Linear(8,1)
           
       def forward(self,x):
           x = F.relu(self.fc1(x))
           x = F.relu(self.fc2(x))
           y = self.fc3(x)
           return y
           
   net = Net() 
   
   from torchkeras import summary
   
   summary(net,features);
   ```

3. è®­ç»ƒæ¨¡åž‹

   ```py
   # L2æ­£åˆ™åŒ–
   def L2Loss(model,alpha):
       l2_loss = torch.tensor(0.0, requires_grad=True)
       for name, param in model.named_parameters():
           if 'bias' not in name: #ä¸€èˆ¬ä¸å¯¹åç½®é¡¹ä½¿ç”¨æ­£åˆ™
               l2_loss = l2_loss + (0.5 * alpha * torch.sum(torch.pow(param, 2)))
       return l2_loss
   
   # L1æ­£åˆ™åŒ–
   def L1Loss(model,beta):
       l1_loss = torch.tensor(0.0, requires_grad=True)
       for name, param in model.named_parameters():
           if 'bias' not in name:
               l1_loss = l1_loss +  beta * torch.sum(torch.abs(param))
       return l1_loss
   ```

   ```py
   from torchkeras import KerasModel
   from torchkeras.metrics import AUC
   
   net = Net()
   
   # å°†L2æ­£åˆ™å’ŒL1æ­£åˆ™æ·»åŠ åˆ°FocalLossæŸå¤±ï¼Œä¸€èµ·ä½œä¸ºç›®æ ‡å‡½æ•°
   def focal_loss_with_regularization(y_pred,y_true):
       y_probs = torch.sigmoid(y_pred)
       focal = FocalLoss()(y_probs,y_true) 
       l2_loss = L2Loss(net,0.001) #æ³¨æ„è®¾ç½®æ­£åˆ™åŒ–é¡¹ç³»æ•°
       l1_loss = L1Loss(net,0.001)
       total_loss = focal + l2_loss + l1_loss
       return total_loss
   
   
   optimizer = torch.optim.Adam(net.parameters(),lr = 0.002)
   model = KerasModel(net=net,
                      loss_fn = focal_loss_with_regularization ,
                      metrics_dict = {"auc":AUC()},
                      optimizer= optimizer )
   
   
   dfhistory = model.fit(train_data=dl_train,
         val_data=dl_val,
         epochs=20,
         ckpt_path='checkpoint',
         patience=3,
         monitor='val_auc',
         mode='max',
         plot=True,
         cpu=True
       )
   ```

   ```py
   # ç»“æžœå¯è§†åŒ–
   fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize = (12,5))
   ax1.scatter(Xp[:,0],Xp[:,1], c="r")
   ax1.scatter(Xn[:,0],Xn[:,1],c = "g")
   ax1.legend(["positive","negative"]);
   ax1.set_title("y_true");
   
   Xp_pred = X[torch.squeeze(torch.sigmoid(net.forward(X))>=0.5)]
   Xn_pred = X[torch.squeeze(torch.sigmoid(net.forward(X))<0.5)]
   
   ax2.scatter(Xp_pred[:,0],Xp_pred[:,1],c = "r")
   ax2.scatter(Xn_pred[:,0],Xn_pred[:,1],c = "g")
   ax2.legend(["positive","negative"]);
   ax2.set_title("y_pred");
   ```

### 6.3.5ã€é€šè¿‡ä¼˜åŒ–å™¨å®žçŽ° L2 æ­£åˆ™åŒ–

å¦‚æžœä»…ä»…éœ€è¦ä½¿ç”¨ L2 æ­£åˆ™åŒ–ï¼Œé‚£ä¹ˆä¹Ÿå¯ä»¥åˆ©ç”¨ä¼˜åŒ–å™¨çš„ weight_decay å‚æ•°æ¥å®žçŽ°ã€‚

weight_decay å‚æ•°å¯ä»¥è®¾ç½®å‚æ•°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¡°å‡ï¼Œè¿™å’Œ L2 æ­£åˆ™åŒ–çš„ä½œç”¨æ•ˆæžœç­‰ä»·

Pytorch çš„ä¼˜åŒ–å™¨æ”¯æŒä¸€ç§ç§°ä¹‹ä¸º Per-parameter options çš„æ“ä½œï¼Œå°±æ˜¯å¯¹æ¯ä¸€ä¸ªå‚æ•°è¿›è¡Œç‰¹å®šçš„å­¦ä¹ çŽ‡ï¼Œæƒé‡è¡°å‡çŽ‡æŒ‡å®šï¼Œä»¥æ»¡è¶³æ›´ä¸ºç»†è‡´çš„è¦æ±‚ã€‚

```py
weight_params = [param for name, param in model.named_parameters() if "bias" not in name]
bias_params = [param for name, param in model.named_parameters() if "bias" in name]

optimizer = torch.optim.SGD([{'params': weight_params, 'weight_decay':1e-5},
                             {'params': bias_params, 'weight_decay':0}],
                            lr=1e-2, momentum=0.9)
```

## 6.4ã€TensorBoard å¯è§†åŒ–

åœ¨ç‚¼ä¸¹è¿‡ç¨‹ä¸­ï¼Œå¦‚æžœèƒ½å¤Ÿä½¿ç”¨ä¸°å¯Œçš„å›¾åƒæ¥å±•ç¤ºæ¨¡åž‹çš„ç»“æž„ï¼ŒæŒ‡æ ‡çš„å˜åŒ–ï¼Œå‚æ•°çš„åˆ†å¸ƒï¼Œè¾“å…¥çš„å½¢æ€ç­‰ä¿¡æ¯ï¼Œæ— ç–‘ä¼šæå‡æˆ‘ä»¬å¯¹é—®é¢˜çš„æ´žå¯ŸåŠ›ï¼Œå¹¶å¢žåŠ è®¸å¤šç‚¼ä¸¹çš„ä¹è¶£ã€‚

ensorBoard æ­£æ˜¯è¿™æ ·ä¸€ä¸ªç¥žå¥‡çš„ç‚¼ä¸¹å¯è§†åŒ–è¾…åŠ©å·¥å…·ã€‚å®ƒåŽŸæ˜¯ TensorFlow çš„å°å¼Ÿï¼Œä½†å®ƒä¹Ÿèƒ½å¤Ÿå¾ˆå¥½åœ°å’Œ Pytorch è¿›è¡Œé…åˆã€‚ç”šè‡³åœ¨ Pytorch ä¸­ä½¿ç”¨ TensorBoard æ¯” TensorFlow ä¸­ä½¿ç”¨ TensorBoard è¿˜è¦æ¥çš„æ›´åŠ ç®€å•å’Œè‡ªç„¶ã€‚

### 6.4.0ã€Tensorboard å¯è§†åŒ–æ¦‚è¿°

pytorch ä¸­åˆ©ç”¨ TensorBoard å¯è§†åŒ–çš„å¤§æ¦‚è¿‡ç¨‹ï¼š

- é¦–å…ˆåœ¨ Pytorch ä¸­æŒ‡å®šä¸€ä¸ªç›®å½•åˆ›å»ºä¸€ä¸ª torch.utils.tensorboard.SummaryWriter æ—¥å¿—å†™å…¥å™¨
- æ®éœ€è¦å¯è§†åŒ–çš„ä¿¡æ¯ï¼Œåˆ©ç”¨æ—¥å¿—å†™å…¥å™¨å°†ç›¸åº”ä¿¡æ¯æ—¥å¿—å†™å…¥æˆ‘ä»¬æŒ‡å®šçš„ç›®å½•
- æœ€åŽå°±å¯ä»¥ä¼ å…¥æ—¥å¿—ç›®å½•ä½œä¸ºå‚æ•°å¯åŠ¨ TensorBoard

ä¸»è¦ä»‹ç» Pytorch ä¸­åˆ©ç”¨ TensorBoard è¿›è¡Œå¦‚ä¸‹æ–¹é¢ä¿¡æ¯çš„å¯è§†åŒ–çš„æ–¹æ³•

- å¯è§†åŒ–æ¨¡åž‹ç»“æž„ï¼š writer.add_graph
- å¯è§†åŒ–æŒ‡æ ‡å˜åŒ–ï¼š writer.add_scalar
- å¯è§†åŒ–å‚æ•°åˆ†å¸ƒï¼š writer.add_histogram
- å¯è§†åŒ–åŽŸå§‹å›¾åƒï¼š writer.add_image æˆ– writer.add_images
- å¯è§†åŒ–äººå·¥ç»˜å›¾ï¼š writer.add_figure

ä½œè€…åœ¨ torchkeras åº“ä¸­é›†æˆäº†ä¸€ä¸ª torchkeras.callback.TensorBoard å›žè°ƒå‡½æ•°å·¥å…·ï¼Œ

åˆ©ç”¨è¯¥å·¥å…·é…åˆ torchkeras.LightModel å¯ä»¥ç”¨æžå°‘çš„ä»£ç åœ¨ TensorBoard ä¸­å®žçŽ°ç»å¤§éƒ¨åˆ†å¸¸ç”¨çš„å¯è§†åŒ–åŠŸèƒ½ã€‚

åŒ…æ‹¬ï¼š

- å¯è§†åŒ–æ¨¡åž‹ç»“æž„
- å¯è§†åŒ–æŒ‡æ ‡å˜åŒ–
- å¯è§†åŒ–å‚æ•°åˆ†å¸ƒ
- å¯è§†åŒ–è¶…å‚è°ƒæ•´
