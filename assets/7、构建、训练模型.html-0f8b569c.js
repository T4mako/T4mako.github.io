import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{o as s,c as a,d as t}from"./app-00d6fe81.js";const p={},e=t(`<h2 id="_7-1、构建模型" tabindex="-1"><a class="header-anchor" href="#_7-1、构建模型" aria-hidden="true">#</a> 7.1、构建模型</h2><p>构建模型有三种方法：</p><ol><li>继承 nn.Module 基类构建自定义模型（最常见）</li><li>使用 nn.Sequential 按层顺序构建模型（最简单）</li><li>继承 nn.Module 基类构建模型并辅助应用模型容器进行封装（nn.Sequential,nn.ModuleList,nn.ModuleDict）（最为灵活也较为复杂）</li></ol><p>模型定义好后，会给参数（w，b）赋值</p><blockquote><p>pytorch hub 模块，调用他人的网络架构</p></blockquote><h3 id="_7-1-1、继承-nn-module-基类构建自定义模型" tabindex="-1"><a class="header-anchor" href="#_7-1-1、继承-nn-module-基类构建自定义模型" aria-hidden="true">#</a> 7.1.1、继承 nn.Module 基类构建自定义模型</h3><p>模型中：</p><ul><li><strong>用到的层</strong> 在 <strong><code>__init__</code></strong> 函数中定义</li><li>在 <strong><code>forward</code></strong> 方法中定义模型的正向传播逻辑</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>adaptive_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>adaptive_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y
        
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-1-2、使用-nn-sequential-按层顺序构建模型" tabindex="-1"><a class="header-anchor" href="#_7-1-2、使用-nn-sequential-按层顺序构建模型" aria-hidden="true">#</a> 7.1.2、使用 nn.Sequential 按层顺序构建模型</h3><p>使用 nn.Sequential 按层顺序构建模型 <strong>无需定义 forward 方法。仅仅适合于简单的模型</strong>。</p><p>以下是使用 nn.Sequential 搭建模型的一些等价方法</p><ol><li><p>利用 add_module 方法</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>利用变长参数</p><p>这种方式构建时不能给每个层指定名称</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (4): Dropout2d(p=0.1, inplace=False)
  (5): AdaptiveMaxPool2d(output_size=(1, 1))
  (6): Flatten(start_dim=1, end_dim=-1)
  (7): Linear(in_features=64, out_features=32, bias=True)
  (8): ReLU()
  (9): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>利用 OrderedDict</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict

net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span>
          <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装" tabindex="-1"><a class="header-anchor" href="#_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装" aria-hidden="true">#</a> 7.1.3、继承 nn.Module 基类构建模型并辅助应用模型容器进行封装</h3><p>当模型的结构比较复杂时，我们可以应用模型容器（nn.Sequential,nn.ModuleList,nn.ModuleDict）对模型的部分结构进行封装</p><p>这样做会让模型整体更加有层次感，有时候也能减少代码量。</p><blockquote><p>注意，在下面的范例中我们每次仅仅使用一种模型容器，但实际上这些模型容器的使用是非常灵活的，可以在一个模型中任意组合任意嵌套使用。</p></blockquote><ol><li><p>nn.Sequential 作为模型容器</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y 
    
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (conv): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
  )
  (dense): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=64, out_features=32, bias=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>nn.ModuleList 作为模型容器</p><p>注意下面中的 ModuleList 不能用 Python 中的列表代替。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>nn.ModuleDict 作为模型容器</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers_dict <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;pool&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;conv2&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;dropout&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;adaptive&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;flatten&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;linear1&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;relu&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;linear2&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
              <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;pool&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;pool&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;adaptive&quot;</span><span class="token punctuation">,</span>
                  <span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>layers_dict<span class="token punctuation">[</span>layer<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers_dict): ModuleDict(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (adaptive): AdaptiveMaxPool2d(output_size=(1, 1))
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (linear1): Linear(in_features=64, out_features=32, bias=True)
    (relu): ReLU()
    (linear2): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h2 id="_7-2、训练模型" tabindex="-1"><a class="header-anchor" href="#_7-2、训练模型" aria-hidden="true">#</a> 7.2、训练模型</h2><p>Pytorch 通常需要用户编写自定义训练循环</p><p>有 3 类典型的训练循环代码风格：</p><ul><li>脚本形式训练循环</li><li>函数形式训练循环</li><li>类形式训练循环</li></ul><p><strong>训练模式</strong> 和 <strong>预测模式</strong> 的切换：</p><ul><li>一般在训练模型时加上 <strong>model.train()</strong>，这样会正常使用 Batch Normalization 和 Dropout</li><li>测试的时候选择 <strong>model.eval()</strong>，这样就不会使用 Batch Normalization 和 Dropout</li></ul><p>下面以 minist 数据集的多分类模型的训练为例，演示这 3 种训练模型的风格</p><p>其中类形式训练循环我们同时演示 torchkeras.KerasModel 和 torchkeras.LightModel 两种示范</p><h3 id="_7-2-0、准备数据" tabindex="-1"><a class="header-anchor" href="#_7-2-0、准备数据" aria-hidden="true">#</a> 7.2.0、准备数据</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">import</span> torchvision 
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

<span class="token comment"># 将图像数据转换为张量（tensor）</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

ds_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
ds_val <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

dl_train <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
dl_val <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 60000</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_val<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 10000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-1、脚本风格" tabindex="-1"><a class="header-anchor" href="#_7-2-1、脚本风格" aria-hidden="true">#</a> 7.2.1、脚本风格</h3><p>脚本风格的训练循环非常常见</p><p>构建模型：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 构建模型</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=10, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>训练模型</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm <span class="token comment"># 进度条库</span>

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

<span class="token comment"># 于打印带有时间戳的日志信息</span>
<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\\n&quot;</span><span class="token punctuation">)</span>
    
<span class="token comment"># 交叉熵损失函数、Adam 优化器、准确率评估指标    </span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token comment"># 训练的轮数、检查点路径、早停监控指标、容忍度和模式，以及历史记录的字典</span>
epochs <span class="token operator">=</span> <span class="token number">20</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>
<span class="token comment"># early_stopping 相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">5</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token comment"># 在每个 epoch 中，首先进行训练模式的前向和反向传播，然后进行验证模式的前向传播，并记录损失和指标。所有指标和损失在每个 epoch 结束时都会被存储在 history 字典中</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    <span class="token comment"># 训练模式</span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 初始化本轮训练的总损失和步数计数器</span>
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token comment"># 使用 tqdm 包装数据加载器 dl_train，以显示训练进度条。enumerate函数用于生成数据批次的索引和值</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 深拷贝 metrics_dict，用于记录本轮训练的评估指标</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    <span class="token comment"># 遍历训练数据集 dl_train，每个 batch 是一个批次的训练数据</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        <span class="token comment"># 解包批次数据，features 是输入特征，labels 是对应的标签。</span>
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        <span class="token comment"># forward</span>
        <span class="token comment"># 向前传播，生成预测值</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        <span class="token comment"># 计算损失（目标函数）</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment"># backward 反向传播计算梯度。</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 使用优化器更新模型参数。</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 清零优化器中的梯度，以便下一步计算。</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment"># metrics</span>
        <span class="token comment"># 计算当前批次的评估指标，train_metrics_dict 中包含了准确率等指标。</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
        <span class="token comment"># 将当前批次的损失和评估指标存入 step_log 字典。</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 累加当前批次的损失到总损失中。</span>
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token comment"># 增加步数计数器。</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 如果不是最后一个批次，更新进度条的后缀为 step_log。如果是最后一个批次，计算整个 epoch 的平均损失和评估指标，更新进度条的后缀为epoch_log，并重置评估指标。            </span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    <span class="token comment"># 将模型设置为评估模式，禁用 dropout 等只在训练期间有效的层</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 初始化本轮验证的总损失和步数计数器</span>
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token comment"># 使用tqdm包装验证数据加载器dl_val，以显示验证进度条</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 深拷贝metrics_dict，用于记录本轮验证的评估指标</span>
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    <span class="token comment"># 禁用梯度计算，以节省内存并加快计算</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
		   <span class="token comment"># 解包批次数据，features是输入特征，labels是对应的标签</span>
            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment"># forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            <span class="token comment"># 计算当前批次的损失，使用预定义的损失函数 loss_fn</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment"># metrics</span>
            <span class="token comment"># 计算当前批次的评估指标，val_metrics_dict中包含了准确率等指标</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
		   <span class="token comment"># 将当前批次的损失和评估指标存入step_log字典</span>
            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
 		   <span class="token comment"># 累加当前批次的损失到总损失中。</span>
            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 增加步数计数器。</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token comment"># 如果不是最后一个批次，更新进度条的后缀为step_log。如果是最后一个批次，计算整个epoch的平均损失和评估指标，更新进度条的后缀为epoch_log，并重置评估指标。</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>
                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
    <span class="token comment"># 将本轮验证的损失和评估指标存入history字典中</span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    <span class="token comment"># 早停机制：根据验证集上的性能指标决定是否保存当前模型参数，并在指定的轮次内指标没有提升时停止训练</span>
    <span class="token comment"># 获取监控指标的历史记录</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    <span class="token comment"># 根据监控模式（最大化或最小化），找到最佳得分的索引</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token comment"># 如果当前轮次是最佳得分，保存模型参数，并打印提示信息。</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
    <span class="token comment"># 如果在指定的容忍度内（patience）没有取得进步，打印提示信息并停止训练。</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    <span class="token comment"># 加载保存的最佳模型参数。</span>
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 将历史记录转换为 DataFrame：</span>
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-2、函数风格" tabindex="-1"><a class="header-anchor" href="#_7-2-2、函数风格" aria-hidden="true">#</a> 7.2.2、函数风格</h3><p>该风格在脚本形式上做了进一步的函数封装</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=10, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\\n&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">StepRunner</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> net<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span>
                 stage <span class="token operator">=</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span> metrics_dict <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> 
                 optimizer <span class="token operator">=</span> <span class="token boolean">None</span>
                 <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">,</span>self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">,</span>self<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">,</span>self<span class="token punctuation">.</span>stage <span class="token operator">=</span> net<span class="token punctuation">,</span>loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token punctuation">,</span>stage
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optimizer
            
    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#loss</span>
        preds <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward()</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>optimizer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>stage<span class="token operator">==</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span> 
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>step_metrics
    
    <span class="token keyword">def</span> <span class="token function">train_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#训练模式, dropout层发生作用</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
    
    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">eval_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#预测模式, dropout层不发生作用</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>stage<span class="token operator">==</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>train_step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span> 
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>eval_step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
<span class="token keyword">class</span> <span class="token class-name">EpochRunner</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>steprunner<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>steprunner <span class="token operator">=</span> steprunner
        self<span class="token punctuation">.</span>stage <span class="token operator">=</span> steprunner<span class="token punctuation">.</span>stage
        
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
        loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
            loss<span class="token punctuation">,</span> step_metrics <span class="token operator">=</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span>
            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
            total_loss <span class="token operator">+=</span> loss
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> epoch_log


<span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metrics_dict<span class="token punctuation">,</span> 
                train_data<span class="token punctuation">,</span> val_data<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> 
                epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span><span class="token punctuation">,</span>
                patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> monitor<span class="token operator">=</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&quot;min&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 1，train -------------------------------------------------  </span>
        train_step_runner <span class="token operator">=</span> StepRunner<span class="token punctuation">(</span>net <span class="token operator">=</span> net<span class="token punctuation">,</span>stage<span class="token operator">=</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span>
                loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token operator">=</span>deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span><span class="token punctuation">,</span>
                optimizer <span class="token operator">=</span> optimizer<span class="token punctuation">)</span>
        train_epoch_runner <span class="token operator">=</span> EpochRunner<span class="token punctuation">(</span>train_step_runner<span class="token punctuation">)</span>
        train_metrics <span class="token operator">=</span> train_epoch_runner<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>

        <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> train_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

        <span class="token comment"># 2，validate -------------------------------------------------</span>
        <span class="token keyword">if</span> val_data<span class="token punctuation">:</span>
            val_step_runner <span class="token operator">=</span> StepRunner<span class="token punctuation">(</span>net <span class="token operator">=</span> net<span class="token punctuation">,</span>stage<span class="token operator">=</span><span class="token string">&quot;val&quot;</span><span class="token punctuation">,</span>
                loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token operator">=</span>deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>
            val_epoch_runner <span class="token operator">=</span> EpochRunner<span class="token punctuation">(</span>val_step_runner<span class="token punctuation">)</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                val_metrics <span class="token operator">=</span> val_epoch_runner<span class="token punctuation">(</span>val_data<span class="token punctuation">)</span>
            val_metrics<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
            <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> val_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

        <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
        arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
        best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
        <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
                 arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
            <span class="token keyword">break</span> 
        net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

dfhistory <span class="token operator">=</span> train_model<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
    optimizer<span class="token punctuation">,</span>
    loss_fn<span class="token punctuation">,</span>
    metrics_dict<span class="token punctuation">,</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-3、类风格" tabindex="-1"><a class="header-anchor" href="#_7-2-3、类风格" aria-hidden="true">#</a> 7.2.3、类风格</h3><p>此处使用torchkeras.KerasModel高层次API接口中的fit方法训练模型。</p><p>使用该形式训练模型非常简洁明了</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> KerasModel 

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
    
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=10, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

model <span class="token operator">=</span> KerasModel<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
                   loss_fn<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                   optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">,</span>
    plot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    cpu<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_7-3、使用-gpu-训练模型" tabindex="-1"><a class="header-anchor" href="#_7-3、使用-gpu-训练模型" aria-hidden="true">#</a> 7.3、使用 GPU 训练模型</h2><p>训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代</p><ol><li>当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据</li><li>当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用 GPU 来进行加速</li></ol><p>Pytorch 中使用 GPU 加速模型非常简单，只要将模型和数据移动到 GPU 上。核心代码只有以下几行：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 定义模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动模型到 cuda</span>

<span class="token comment"># 训练模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动数据到 cuda</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 或者  labels = labels.cuda() if torch.cuda.is_available() else labels</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果要使用多个 GPU 训练模型，也非常简单。只需要在将模型设置为数据并行风格模型。 则模型移动到 GPU 上之后，会在每一个 GPU 上拷贝一个副本，并把数据平分到各个 GPU 上进行训练。核心代码如下：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 定义模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>model<span class="token punctuation">)</span> <span class="token comment"># 包装为并行风格模型</span>

<span class="token comment"># 训练模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动数据到 cuda</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 或者 labels = labels.cuda() if torch.cuda.is_available() else labels</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-0、gpu-相关操作汇总" tabindex="-1"><a class="header-anchor" href="#_7-3-0、gpu-相关操作汇总" aria-hidden="true">#</a> 7.3.0、GPU 相关操作汇总</h3><ol><li><p>查看 GPU 信息</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 

<span class="token comment"># 1，查看 gpu 信息</span>
if_cuda <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;if_cuda=&quot;</span><span class="token punctuation">,</span>if_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>

gpu_count <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;gpu_count=&quot;</span><span class="token punctuation">,</span>gpu_count<span class="token punctuation">)</span> <span class="token comment"># 1</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>将张量在 GPU 和 CPU 间移动</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 2，将张量在gpu和cpu间移动</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor_gpu <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 或者 tensor_gpu = tensor.cuda()</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_gpu<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_gpu<span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>

tensor_cpu <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 或者 tensor_cpu = tensor_gpu.cpu() </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_cpu<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cpu</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>将模型中的全部张量移动到 GPU 上</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 3，将模型中的全部张量移动到gpu上</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># False</span>
net<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 将模型中的全部参数张量依次到GPU上，注意，无需重新赋值为 net = net.to(&quot;cuda:0&quot;)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>创建支持多个 GPU 数据并行的模型</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 4，创建支持多个gpu数据并行的模型</span>
linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cpu</span>

model <span class="token operator">=</span> nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>linear<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>device_ids<span class="token punctuation">)</span> <span class="token comment"># [0]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>

<span class="token comment">#注意保存参数时要指定保存model.module的参数</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;model_parameter.pt&quot;</span><span class="token punctuation">)</span> 

linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
linear<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;model_parameter.pt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="_7-3-1、矩阵乘法案例" tabindex="-1"><a class="header-anchor" href="#_7-3-1、矩阵乘法案例" aria-hidden="true">#</a> 7.3.1、矩阵乘法案例</h3><p>下面分别使用 CPU 和 GPU 作一个矩阵乘法，并比较其计算效率。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> time
<span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

<span class="token comment"># 使用 CPU</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># 使用 Gpu</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">,</span>device <span class="token operator">=</span> device<span class="token punctuation">)</span> <span class="token comment">#可以指定在GPU上创建张量</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#也可以在CPU上创建张量后移动到GPU上</span>
b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment">#或者 b = b.cuda() if torch.cuda.is_available() else b </span>
tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-2、线性回归范例" tabindex="-1"><a class="header-anchor" href="#_7-3-2、线性回归范例" aria-hidden="true">#</a> 7.3.2、线性回归范例</h3><p>下面对比使用 CPU 和 GPU 训练一个线性回归模型的效率</p><p>使用 CPU：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 准备数据</span>
n <span class="token operator">=</span> <span class="token number">1000000</span> <span class="token comment">#样本数量</span>

X <span class="token operator">=</span> <span class="token number">10</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5.0</span>  <span class="token comment">#torch.rand是均匀分布 </span>
w0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> X@w0<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b0 <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># @表示矩阵乘法,增加正态扰动</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>w0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>b0<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#正向传播</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> x@self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        
linear <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 训练模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        Y_pred <span class="token operator">=</span> linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span> 
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>Y_pred<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> 
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch<span class="token operator">%</span><span class="token number">50</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">:</span>epoch<span class="token punctuation">,</span><span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;time used:&quot;</span><span class="token punctuation">,</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>

train<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 GPU：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 准备数据</span>
n <span class="token operator">=</span> <span class="token number">1000000</span> <span class="token comment"># 样本数量</span>

X <span class="token operator">=</span> <span class="token number">10</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5.0</span>  <span class="token comment">#torch.rand 是均匀分布 </span>
w0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> X@w0<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b0 <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># @表示矩阵乘法,增加正态扰动</span>

<span class="token comment"># 数据移动到 GPU 上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;torch.cuda.is_available() = &quot;</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> X<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> Y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;X.device:&quot;</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Y.device:&quot;</span><span class="token punctuation">,</span>Y<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>w0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>b0<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 正向传播</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> x@self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        
linear <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 移动模型到GPU上</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
linear<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 查看模型是否已经移动到 GPU 上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;if on cuda:&quot;</span><span class="token punctuation">,</span><span class="token builtin">next</span><span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        Y_pred <span class="token operator">=</span> linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span> 
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>Y_pred<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> 
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch<span class="token operator">%</span><span class="token number">50</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">:</span>epoch<span class="token punctuation">,</span><span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;time used:&quot;</span><span class="token punctuation">,</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
    
train<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-3、图片分类范例" tabindex="-1"><a class="header-anchor" href="#_7-3-3、图片分类范例" aria-hidden="true">#</a> 7.3.3、图片分类范例</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">import</span> torchvision 
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

<span class="token comment"># 准备数据</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
ds_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
ds_val <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
dl_train <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
dl_val <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_val<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">def</span> <span class="token function">create_net</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> net

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 CPU 训练：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
<span class="token comment">#注：多分类使用 torchmetrics 中的评估指标，二分类使用 torchkeras.metrics 中的评估指标</span>

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\\n&quot;</span><span class="token punctuation">)</span>
    

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 

loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

epochs <span class="token operator">=</span> <span class="token number">3</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>

<span class="token comment">#early_stopping 相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">1</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        <span class="token comment">#forward</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 

            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment">#forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment">#metrics</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch           
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 GPU 训练：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
<span class="token comment">#注：多分类使用torchmetrics中的评估指标，二分类使用torchkeras.metrics中的评估指标</span>

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\\n&quot;</span><span class="token punctuation">)</span>
    
net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 


loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>


<span class="token comment"># =========================移动模型到GPU上==============================</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
loss_fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token keyword">for</span> name<span class="token punctuation">,</span>fn <span class="token keyword">in</span> metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment"># ====================================================================</span>


epochs <span class="token operator">=</span> <span class="token number">5</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>

<span class="token comment">#early_stopping相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">1</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        
        <span class="token comment"># =========================移动数据到GPU上==============================</span>
        features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment"># ====================================================================</span>
        
        <span class="token comment">#forward</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 

            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment"># =========================移动数据到GPU上==============================</span>
            features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            <span class="token comment"># ====================================================================</span>
            
            <span class="token comment">#forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment">#metrics</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch           
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-4、torchkeras-kerasmodel-中使用-gpu" tabindex="-1"><a class="header-anchor" href="#_7-3-4、torchkeras-kerasmodel-中使用-gpu" aria-hidden="true">#</a> 7.3.4、torchkeras.KerasModel 中使用 GPU</h3><p>从上面的例子可以看到，在 pytorch 中使用 GPU 并不复杂，但对于经常炼丹的同学来说，模型和数据老是移来移去还是蛮麻烦的。</p><p>一不小心就会忘了移动某些数据或者某些 module，导致报错。</p><p>torchkeras.KerasModel 在设计的时候考虑到了这一点，如果环境当中存在可用的 GPU，会自动使用 GPU，反之则使用 CPU。</p><p>通过引入 accelerate 的一些基础功能，torchkeras.KerasModel 以非常优雅的方式在 GPU 和 CPU 之间切换。</p><p>详细实现可以参考 torchkeras.KerasModel 的源码。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span>  accelerate 
accelerator <span class="token operator">=</span> accelerate<span class="token punctuation">.</span>Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>accelerator<span class="token punctuation">.</span>device<span class="token punctuation">)</span>  <span class="token comment"># cuda</span>

<span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> KerasModel 
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 
model <span class="token operator">=</span> KerasModel<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
                   loss_fn<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                   optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,76),o=[e];function c(i,l){return s(),a("div",null,o)}const k=n(p,[["render",c],["__file","7、构建、训练模型.html.vue"]]);export{k as default};
