const a=JSON.parse('{"key":"v-63e313d3","path":"/code/python/Machine%20Learning/Deep%20Learning/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html","title":"机器学习基础概念","lang":"zh-CN","frontmatter":{"title":"机器学习基础概念","description":"梯度下降 误差： 训练误差：模型在训练数据上的误差 泛化误差：模型在新数据上的误差 数据集： 训练集 验证集 测试集 k 折交叉验证 过拟合与欠拟合 权重衰退： 使用均方范数作为硬性限制，控制模型复杂度，减少过拟合 通过限制参数值 w 的选择范围来控制模型容量∣∣w∣∣2≤θ||w||^2 \\\\le \\\\theta∣∣w∣∣2≤θ ，通常不限制 bias，小的 theta 意味着更强的正则项","head":[["meta",{"property":"og:url","content":"https://T4mako.github.io/code/python/Machine%20Learning/Deep%20Learning/%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html"}],["meta",{"property":"og:site_name","content":"T4mako"}],["meta",{"property":"og:title","content":"机器学习基础概念"}],["meta",{"property":"og:description","content":"梯度下降 误差： 训练误差：模型在训练数据上的误差 泛化误差：模型在新数据上的误差 数据集： 训练集 验证集 测试集 k 折交叉验证 过拟合与欠拟合 权重衰退： 使用均方范数作为硬性限制，控制模型复杂度，减少过拟合 通过限制参数值 w 的选择范围来控制模型容量∣∣w∣∣2≤θ||w||^2 \\\\le \\\\theta∣∣w∣∣2≤θ ，通常不限制 bias，小的 theta 意味着更强的正则项"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"T4mako"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"机器学习基础概念\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"T4mako\\",\\"url\\":\\"https://github.com/T4mako/T4mako.github.io\\"}]}"]]},"headers":[{"level":3,"title":"梯度下降","slug":"梯度下降","link":"#梯度下降","children":[]},{"level":3,"title":"误差：","slug":"误差","link":"#误差","children":[]},{"level":3,"title":"数据集：","slug":"数据集","link":"#数据集","children":[]},{"level":3,"title":"k 折交叉验证","slug":"k-折交叉验证","link":"#k-折交叉验证","children":[]},{"level":3,"title":"过拟合与欠拟合","slug":"过拟合与欠拟合","link":"#过拟合与欠拟合","children":[]},{"level":3,"title":"权重衰退：","slug":"权重衰退","link":"#权重衰退","children":[]},{"level":3,"title":"dropout 丢弃法","slug":"dropout-丢弃法","link":"#dropout-丢弃法","children":[]},{"level":3,"title":"数值稳定性","slug":"数值稳定性","link":"#数值稳定性","children":[]}],"readingTime":{"minutes":1.33,"words":399},"filePathRelative":"code/python/Machine Learning/Deep Learning/基础概念.md","excerpt":"<h3> 梯度下降</h3>\\n<h3> 误差：</h3>\\n<ul>\\n<li>训练误差：模型在训练数据上的误差</li>\\n<li>泛化误差：模型在新数据上的误差</li>\\n</ul>\\n<h3> 数据集：</h3>\\n<ul>\\n<li>训练集</li>\\n<li>验证集</li>\\n<li>测试集</li>\\n</ul>\\n<h3> k 折交叉验证</h3>\\n<h3> 过拟合与欠拟合</h3>\\n<h3> 权重衰退：</h3>\\n<ul>\\n<li>\\n<p>使用均方范数作为硬性限制，控制模型复杂度，减少过拟合</p>\\n<p>通过限制参数值 w 的选择范围来控制模型容量<span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi mathvariant=\\"normal\\">∣</mi><mi mathvariant=\\"normal\\">∣</mi><mi>w</mi><mi mathvariant=\\"normal\\">∣</mi><msup><mi mathvariant=\\"normal\\">∣</mi><mn>2</mn></msup><mo>≤</mo><mi>θ</mi></mrow><annotation encoding=\\"application/x-tex\\">||w||^2 \\\\le  \\\\theta</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1.0641em;vertical-align:-0.25em;\\"></span><span class=\\"mord\\">∣∣</span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.02691em;\\">w</span><span class=\\"mord\\">∣</span><span class=\\"mord\\"><span class=\\"mord\\">∣</span><span class=\\"msupsub\\"><span class=\\"vlist-t\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.8141em;\\"><span style=\\"top:-3.063em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\">2</span></span></span></span></span></span></span></span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">≤</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6944em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.02778em;\\">θ</span></span></span></span> ，通常不限制 bias，小的 theta 意味着更强的正则项</p>\\n</li>\\n</ul>","autoDesc":true}');export{a as data};
