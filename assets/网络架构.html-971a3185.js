const e=JSON.parse('{"key":"v-6a99ff50","path":"/code/python/Machine%20Learning/Deep%20Learning/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.html","title":"深度学习","lang":"zh-CN","frontmatter":{"title":"深度学习","description":"基础概念 机器学习概念 梯度下降 误差 训练误差：模型在训练数据上的误差 泛化误差：模型在新数据上的误差 k 折交叉验证 过拟合与欠拟合 权重衰退 使用均方范数作为硬性限制，控制模型复杂度，减少过拟合 通过限制参数值 w 的选择范围来控制模型容量∣∣w∣∣2≤θ||w||^2 \\\\le \\\\theta∣∣w∣∣2≤θ ，通常不限制 bias，小的 theta 意味着更强的正则项","head":[["meta",{"property":"og:url","content":"https://T4mako.github.io/code/python/Machine%20Learning/Deep%20Learning/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.html"}],["meta",{"property":"og:site_name","content":"T4mako"}],["meta",{"property":"og:title","content":"深度学习"}],["meta",{"property":"og:description","content":"基础概念 机器学习概念 梯度下降 误差 训练误差：模型在训练数据上的误差 泛化误差：模型在新数据上的误差 k 折交叉验证 过拟合与欠拟合 权重衰退 使用均方范数作为硬性限制，控制模型复杂度，减少过拟合 通过限制参数值 w 的选择范围来控制模型容量∣∣w∣∣2≤θ||w||^2 \\\\le \\\\theta∣∣w∣∣2≤θ ，通常不限制 bias，小的 theta 意味着更强的正则项"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"T4mako"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"深度学习\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"T4mako\\",\\"url\\":\\"https://github.com/T4mako/T4mako.github.io\\"}]}"]]},"headers":[{"level":2,"title":"基础概念","slug":"基础概念","link":"#基础概念","children":[{"level":3,"title":"机器学习概念","slug":"机器学习概念","link":"#机器学习概念","children":[]},{"level":3,"title":"数据集操作","slug":"数据集操作","link":"#数据集操作","children":[]},{"level":3,"title":"硬件、计算性能","slug":"硬件、计算性能","link":"#硬件、计算性能","children":[]},{"level":3,"title":"微调","slug":"微调","link":"#微调","children":[]}]},{"level":2,"title":"全连接层 fc","slug":"全连接层-fc","link":"#全连接层-fc","children":[{"level":3,"title":"线性回归","slug":"线性回归","link":"#线性回归","children":[]},{"level":3,"title":"Softmax 分类","slug":"softmax-分类","link":"#softmax-分类","children":[]},{"level":3,"title":"多层感知机 MLP","slug":"多层感知机-mlp","link":"#多层感知机-mlp","children":[]}]},{"level":2,"title":"卷积神经网络 CNN","slug":"卷积神经网络-cnn","link":"#卷积神经网络-cnn","children":[{"level":3,"title":"多输入输出通道","slug":"多输入输出通道","link":"#多输入输出通道","children":[]},{"level":3,"title":"卷积层 conv（convolution）","slug":"卷积层-conv-convolution","link":"#卷积层-conv-convolution","children":[]},{"level":3,"title":"池化层 pool","slug":"池化层-pool","link":"#池化层-pool","children":[]},{"level":3,"title":"全连接层 fc","slug":"全连接层-fc-1","link":"#全连接层-fc-1","children":[]}]},{"level":2,"title":"经典多层神经网路","slug":"经典多层神经网路","link":"#经典多层神经网路","children":[{"level":3,"title":"LeNet （1980s）","slug":"lenet-1980s","link":"#lenet-1980s","children":[]},{"level":3,"title":"AlexNet（2012 年）","slug":"alexnet-2012-年","link":"#alexnet-2012-年","children":[]},{"level":3,"title":"Vgg（2014 年）","slug":"vgg-2014-年","link":"#vgg-2014-年","children":[]},{"level":3,"title":"NiN","slug":"nin","link":"#nin","children":[]},{"level":3,"title":"GoogLeNet","slug":"googlenet","link":"#googlenet","children":[]},{"level":3,"title":"Resnet（2015年）","slug":"resnet-2015年","link":"#resnet-2015年","children":[]},{"level":3,"title":"DenseNet","slug":"densenet","link":"#densenet","children":[]}]},{"level":2,"title":"批量归一化层","slug":"批量归一化层","link":"#批量归一化层","children":[]},{"level":2,"title":"目标检测算法","slug":"目标检测算法","link":"#目标检测算法","children":[]},{"level":2,"title":"迁移学习","slug":"迁移学习","link":"#迁移学习","children":[]},{"level":2,"title":"RNN 递归神经网络","slug":"rnn-递归神经网络","link":"#rnn-递归神经网络","children":[]},{"level":2,"title":"LSTM 网络","slug":"lstm-网络","link":"#lstm-网络","children":[]},{"level":2,"title":"词向量模型 Word2Vec","slug":"词向量模型-word2vec","link":"#词向量模型-word2vec","children":[]},{"level":2,"title":"GAN 对抗生成网络","slug":"gan-对抗生成网络","link":"#gan-对抗生成网络","children":[]},{"level":2,"title":"CycleGan","slug":"cyclegan","link":"#cyclegan","children":[]},{"level":2,"title":"KNN","slug":"knn","link":"#knn","children":[]},{"level":2,"title":"随机森林","slug":"随机森林","link":"#随机森林","children":[]}],"readingTime":{"minutes":11.15,"words":3346},"filePathRelative":"code/python/Machine Learning/Deep Learning/网络架构.md","excerpt":"<h2> 基础概念</h2>\\n<h3> 机器学习概念</h3>\\n<h4> 梯度下降</h4>\\n<h4> 误差</h4>\\n<ul>\\n<li>训练误差：模型在训练数据上的误差</li>\\n<li>泛化误差：模型在新数据上的误差</li>\\n</ul>\\n<h4> k 折交叉验证</h4>\\n<h4> 过拟合与欠拟合</h4>\\n<h4> 权重衰退</h4>\\n<ul>\\n<li>\\n<p>使用均方范数作为硬性限制，控制模型复杂度，减少过拟合</p>\\n<p>通过限制参数值 w 的选择范围来控制模型容量<span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi mathvariant=\\"normal\\">∣</mi><mi mathvariant=\\"normal\\">∣</mi><mi>w</mi><mi mathvariant=\\"normal\\">∣</mi><msup><mi mathvariant=\\"normal\\">∣</mi><mn>2</mn></msup><mo>≤</mo><mi>θ</mi></mrow><annotation encoding=\\"application/x-tex\\">||w||^2 \\\\le  \\\\theta</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1.0641em;vertical-align:-0.25em;\\"></span><span class=\\"mord\\">∣∣</span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.02691em;\\">w</span><span class=\\"mord\\">∣</span><span class=\\"mord\\"><span class=\\"mord\\">∣</span><span class=\\"msupsub\\"><span class=\\"vlist-t\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.8141em;\\"><span style=\\"top:-3.063em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\">2</span></span></span></span></span></span></span></span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">≤</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6944em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.02778em;\\">θ</span></span></span></span> ，通常不限制 bias，小的 theta 意味着更强的正则项</p>\\n</li>\\n</ul>","autoDesc":true}');export{e as data};
