const n=JSON.parse(`{"key":"v-6a99ff50","path":"/code/python/Machine%20Learning/Deep%20Learning/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.html","title":"","lang":"zh-CN","frontmatter":{"description":"线性回归 import torch import torch.nn as nn import torch.optim as optim import numpy as np import matplotlib.pyplot as plt # 生成示例数据 np.random.seed(0) X = 2 * np.random.rand(100, 1) y = 4 + 3 * X + np.random.randn(100, 1) # y = 4 + 3 * X + 噪声 # 将数据转换为 PyTorch 张量 X_tensor = torch.tensor(X, dtype=torch.float32) y_tensor = torch.tensor(y, dtype=torch.float32) # 定义线性回归模型 class LinearRegressionModel(nn.Module): def __init__(self): super(LinearRegressionModel, self).__init__() self.linear = nn.Linear(1, 1) #（输入维度，输出维度）输入x，输出y def forward(self, x): return self.linear(x) # 实例化模型 model = LinearRegressionModel() # 定义损失函数和优化器 criterion = nn.MSELoss() # 均方误差损失 optimizer = optim.SGD(model.parameters(), lr=0.01) # 随机梯度下降优化器 # 训练模型 num_epochs = 1000 for epoch in range(num_epochs): model.train() # 前向传播 y_pred = model(X_tensor) # 计算损失 loss = criterion(y_pred, y_tensor) # 反向传播 optimizer.zero_grad() loss.backward() optimizer.step() if (epoch + 1) % 100 == 0: print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}') # 绘制结果 model.eval() with torch.no_grad(): predicted = model(X_tensor).numpy() plt.scatter(X, y, color='blue', label='实际数据') plt.plot(X, predicted, color='red', label='拟合直线') plt.xlabel('X') plt.ylabel('y') plt.legend() plt.title('线性回归示例') plt.show()","head":[["meta",{"property":"og:url","content":"https://T4mako.github.io/code/python/Machine%20Learning/Deep%20Learning/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.html"}],["meta",{"property":"og:site_name","content":"T4mako"}],["meta",{"property":"og:description","content":"线性回归 import torch import torch.nn as nn import torch.optim as optim import numpy as np import matplotlib.pyplot as plt # 生成示例数据 np.random.seed(0) X = 2 * np.random.rand(100, 1) y = 4 + 3 * X + np.random.randn(100, 1) # y = 4 + 3 * X + 噪声 # 将数据转换为 PyTorch 张量 X_tensor = torch.tensor(X, dtype=torch.float32) y_tensor = torch.tensor(y, dtype=torch.float32) # 定义线性回归模型 class LinearRegressionModel(nn.Module): def __init__(self): super(LinearRegressionModel, self).__init__() self.linear = nn.Linear(1, 1) #（输入维度，输出维度）输入x，输出y def forward(self, x): return self.linear(x) # 实例化模型 model = LinearRegressionModel() # 定义损失函数和优化器 criterion = nn.MSELoss() # 均方误差损失 optimizer = optim.SGD(model.parameters(), lr=0.01) # 随机梯度下降优化器 # 训练模型 num_epochs = 1000 for epoch in range(num_epochs): model.train() # 前向传播 y_pred = model(X_tensor) # 计算损失 loss = criterion(y_pred, y_tensor) # 反向传播 optimizer.zero_grad() loss.backward() optimizer.step() if (epoch + 1) % 100 == 0: print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}') # 绘制结果 model.eval() with torch.no_grad(): predicted = model(X_tensor).numpy() plt.scatter(X, y, color='blue', label='实际数据') plt.plot(X, predicted, color='red', label='拟合直线') plt.xlabel('X') plt.ylabel('y') plt.legend() plt.title('线性回归示例') plt.show()"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:author","content":"T4mako"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"T4mako\\",\\"url\\":\\"https://github.com/T4mako/T4mako.github.io\\"}]}"]]},"headers":[{"level":2,"title":"线性回归","slug":"线性回归","link":"#线性回归","children":[]},{"level":2,"title":"Softmax 分类","slug":"softmax-分类","link":"#softmax-分类","children":[]},{"level":2,"title":"多层感知机","slug":"多层感知机","link":"#多层感知机","children":[]},{"level":2,"title":"卷积神经网络 CNN","slug":"卷积神经网络-cnn","link":"#卷积神经网络-cnn","children":[{"level":3,"title":"输入层","slug":"输入层","link":"#输入层","children":[]},{"level":3,"title":"卷积层 conv（convolution）","slug":"卷积层-conv-convolution","link":"#卷积层-conv-convolution","children":[]},{"level":3,"title":"池化层 pool","slug":"池化层-pool","link":"#池化层-pool","children":[]},{"level":3,"title":"全连接层 fc","slug":"全连接层-fc","link":"#全连接层-fc","children":[]}]},{"level":2,"title":"经典多层神经网路","slug":"经典多层神经网路","link":"#经典多层神经网路","children":[{"level":3,"title":"AlexNet（2012 年）","slug":"alexnet-2012-年","link":"#alexnet-2012-年","children":[]},{"level":3,"title":"Vgg（2014 年）","slug":"vgg-2014-年","link":"#vgg-2014-年","children":[]},{"level":3,"title":"Resnet（2015年）","slug":"resnet-2015年","link":"#resnet-2015年","children":[]}]},{"level":2,"title":"迁移学习","slug":"迁移学习","link":"#迁移学习","children":[]},{"level":2,"title":"RNN 递归神经网络","slug":"rnn-递归神经网络","link":"#rnn-递归神经网络","children":[]},{"level":2,"title":"LSTM 网络","slug":"lstm-网络","link":"#lstm-网络","children":[]},{"level":2,"title":"词向量模型 Word2Vec","slug":"词向量模型-word2vec","link":"#词向量模型-word2vec","children":[]},{"level":2,"title":"GAN 对抗生成网络","slug":"gan-对抗生成网络","link":"#gan-对抗生成网络","children":[]},{"level":2,"title":"CycleGan","slug":"cyclegan","link":"#cyclegan","children":[]},{"level":2,"title":"KNN","slug":"knn","link":"#knn","children":[]},{"level":2,"title":"随机森林","slug":"随机森林","link":"#随机森林","children":[]}],"readingTime":{"minutes":5.88,"words":1765},"filePathRelative":"code/python/Machine Learning/Deep Learning/网络架构.md","excerpt":"<h2> 线性回归</h2>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">import</span> torch\\n<span class=\\"token keyword\\">import</span> torch<span class=\\"token punctuation\\">.</span>nn <span class=\\"token keyword\\">as</span> nn\\n<span class=\\"token keyword\\">import</span> torch<span class=\\"token punctuation\\">.</span>optim <span class=\\"token keyword\\">as</span> optim\\n<span class=\\"token keyword\\">import</span> numpy <span class=\\"token keyword\\">as</span> np\\n<span class=\\"token keyword\\">import</span> matplotlib<span class=\\"token punctuation\\">.</span>pyplot <span class=\\"token keyword\\">as</span> plt\\n\\n<span class=\\"token comment\\"># 生成示例数据</span>\\nnp<span class=\\"token punctuation\\">.</span>random<span class=\\"token punctuation\\">.</span>seed<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">)</span>\\nX <span class=\\"token operator\\">=</span> <span class=\\"token number\\">2</span> <span class=\\"token operator\\">*</span> np<span class=\\"token punctuation\\">.</span>random<span class=\\"token punctuation\\">.</span>rand<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">100</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">)</span>\\ny <span class=\\"token operator\\">=</span> <span class=\\"token number\\">4</span> <span class=\\"token operator\\">+</span> <span class=\\"token number\\">3</span> <span class=\\"token operator\\">*</span> X <span class=\\"token operator\\">+</span> np<span class=\\"token punctuation\\">.</span>random<span class=\\"token punctuation\\">.</span>randn<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">100</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">)</span>  <span class=\\"token comment\\"># y = 4 + 3 * X + 噪声</span>\\n\\n<span class=\\"token comment\\"># 将数据转换为 PyTorch 张量</span>\\nX_tensor <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>tensor<span class=\\"token punctuation\\">(</span>X<span class=\\"token punctuation\\">,</span> dtype<span class=\\"token operator\\">=</span>torch<span class=\\"token punctuation\\">.</span>float32<span class=\\"token punctuation\\">)</span>\\ny_tensor <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>tensor<span class=\\"token punctuation\\">(</span>y<span class=\\"token punctuation\\">,</span> dtype<span class=\\"token operator\\">=</span>torch<span class=\\"token punctuation\\">.</span>float32<span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\"># 定义线性回归模型</span>\\n<span class=\\"token keyword\\">class</span> <span class=\\"token class-name\\">LinearRegressionModel</span><span class=\\"token punctuation\\">(</span>nn<span class=\\"token punctuation\\">.</span>Module<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    <span class=\\"token keyword\\">def</span> <span class=\\"token function\\">__init__</span><span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n        <span class=\\"token builtin\\">super</span><span class=\\"token punctuation\\">(</span>LinearRegressionModel<span class=\\"token punctuation\\">,</span> self<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>__init__<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n        self<span class=\\"token punctuation\\">.</span>linear <span class=\\"token operator\\">=</span> nn<span class=\\"token punctuation\\">.</span>Linear<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">)</span> <span class=\\"token comment\\">#（输入维度，输出维度）输入x，输出y</span>\\n\\n    <span class=\\"token keyword\\">def</span> <span class=\\"token function\\">forward</span><span class=\\"token punctuation\\">(</span>self<span class=\\"token punctuation\\">,</span> x<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n        <span class=\\"token keyword\\">return</span> self<span class=\\"token punctuation\\">.</span>linear<span class=\\"token punctuation\\">(</span>x<span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\"># 实例化模型</span>\\nmodel <span class=\\"token operator\\">=</span> LinearRegressionModel<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\"># 定义损失函数和优化器</span>\\ncriterion <span class=\\"token operator\\">=</span> nn<span class=\\"token punctuation\\">.</span>MSELoss<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>  <span class=\\"token comment\\"># 均方误差损失</span>\\noptimizer <span class=\\"token operator\\">=</span> optim<span class=\\"token punctuation\\">.</span>SGD<span class=\\"token punctuation\\">(</span>model<span class=\\"token punctuation\\">.</span>parameters<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">,</span> lr<span class=\\"token operator\\">=</span><span class=\\"token number\\">0.01</span><span class=\\"token punctuation\\">)</span>  <span class=\\"token comment\\"># 随机梯度下降优化器</span>\\n\\n<span class=\\"token comment\\"># 训练模型</span>\\nnum_epochs <span class=\\"token operator\\">=</span> <span class=\\"token number\\">1000</span>\\n<span class=\\"token keyword\\">for</span> epoch <span class=\\"token keyword\\">in</span> <span class=\\"token builtin\\">range</span><span class=\\"token punctuation\\">(</span>num_epochs<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    model<span class=\\"token punctuation\\">.</span>train<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n    \\n    <span class=\\"token comment\\"># 前向传播</span>\\n    y_pred <span class=\\"token operator\\">=</span> model<span class=\\"token punctuation\\">(</span>X_tensor<span class=\\"token punctuation\\">)</span>\\n    \\n    <span class=\\"token comment\\"># 计算损失</span>\\n    loss <span class=\\"token operator\\">=</span> criterion<span class=\\"token punctuation\\">(</span>y_pred<span class=\\"token punctuation\\">,</span> y_tensor<span class=\\"token punctuation\\">)</span>\\n    \\n    <span class=\\"token comment\\"># 反向传播</span>\\n    optimizer<span class=\\"token punctuation\\">.</span>zero_grad<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n    loss<span class=\\"token punctuation\\">.</span>backward<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n    optimizer<span class=\\"token punctuation\\">.</span>step<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n    \\n    <span class=\\"token keyword\\">if</span> <span class=\\"token punctuation\\">(</span>epoch <span class=\\"token operator\\">+</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">%</span> <span class=\\"token number\\">100</span> <span class=\\"token operator\\">==</span> <span class=\\"token number\\">0</span><span class=\\"token punctuation\\">:</span>\\n        <span class=\\"token keyword\\">print</span><span class=\\"token punctuation\\">(</span><span class=\\"token string-interpolation\\"><span class=\\"token string\\">f'Epoch [</span><span class=\\"token interpolation\\"><span class=\\"token punctuation\\">{</span>epoch <span class=\\"token operator\\">+</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">}</span></span><span class=\\"token string\\">/</span><span class=\\"token interpolation\\"><span class=\\"token punctuation\\">{</span>num_epochs<span class=\\"token punctuation\\">}</span></span><span class=\\"token string\\">], Loss: </span><span class=\\"token interpolation\\"><span class=\\"token punctuation\\">{</span>loss<span class=\\"token punctuation\\">.</span>item<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span><span class=\\"token format-spec\\">.4f</span><span class=\\"token punctuation\\">}</span></span><span class=\\"token string\\">'</span></span><span class=\\"token punctuation\\">)</span>\\n\\n<span class=\\"token comment\\"># 绘制结果</span>\\nmodel<span class=\\"token punctuation\\">.</span><span class=\\"token builtin\\">eval</span><span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n<span class=\\"token keyword\\">with</span> torch<span class=\\"token punctuation\\">.</span>no_grad<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    predicted <span class=\\"token operator\\">=</span> model<span class=\\"token punctuation\\">(</span>X_tensor<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">.</span>numpy<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\nplt<span class=\\"token punctuation\\">.</span>scatter<span class=\\"token punctuation\\">(</span>X<span class=\\"token punctuation\\">,</span> y<span class=\\"token punctuation\\">,</span> color<span class=\\"token operator\\">=</span><span class=\\"token string\\">'blue'</span><span class=\\"token punctuation\\">,</span> label<span class=\\"token operator\\">=</span><span class=\\"token string\\">'实际数据'</span><span class=\\"token punctuation\\">)</span>\\nplt<span class=\\"token punctuation\\">.</span>plot<span class=\\"token punctuation\\">(</span>X<span class=\\"token punctuation\\">,</span> predicted<span class=\\"token punctuation\\">,</span> color<span class=\\"token operator\\">=</span><span class=\\"token string\\">'red'</span><span class=\\"token punctuation\\">,</span> label<span class=\\"token operator\\">=</span><span class=\\"token string\\">'拟合直线'</span><span class=\\"token punctuation\\">)</span>\\nplt<span class=\\"token punctuation\\">.</span>xlabel<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'X'</span><span class=\\"token punctuation\\">)</span>\\nplt<span class=\\"token punctuation\\">.</span>ylabel<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'y'</span><span class=\\"token punctuation\\">)</span>\\nplt<span class=\\"token punctuation\\">.</span>legend<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\nplt<span class=\\"token punctuation\\">.</span>title<span class=\\"token punctuation\\">(</span><span class=\\"token string\\">'线性回归示例'</span><span class=\\"token punctuation\\">)</span>\\nplt<span class=\\"token punctuation\\">.</span>show<span class=\\"token punctuation\\">(</span><span class=\\"token punctuation\\">)</span>\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}`);export{n as data};
