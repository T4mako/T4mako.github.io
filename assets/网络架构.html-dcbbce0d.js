import{_ as t}from"./plugin-vue_export-helper-c27b6911.js";import{o as p,c as e,d as a,b as n,f as s}from"./app-2ac1fdf0.js";const o={},c=a(`<h2 id="全连接层-fc" tabindex="-1"><a class="header-anchor" href="#全连接层-fc" aria-hidden="true">#</a> 全连接层 fc</h2><h3 id="线性回归" tabindex="-1"><a class="header-anchor" href="#线性回归" aria-hidden="true">#</a> 线性回归</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 生成示例数据</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">4</span> <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> X <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># y = 4 + 3 * X + 噪声</span>

<span class="token comment"># 将数据转换为 PyTorch 张量</span>
X_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 定义线性回归模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegressionModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LinearRegressionModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#（输入维度，输出维度）输入x，输出y</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 实例化模型</span>
model <span class="token operator">=</span> LinearRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 均方误差损失</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token comment"># 随机梯度下降优化器</span>

<span class="token comment"># 训练模型</span>
num_epochs <span class="token operator">=</span> <span class="token number">1000</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 前向传播</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X_tensor<span class="token punctuation">)</span>
    
    <span class="token comment"># 计算损失</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y_tensor<span class="token punctuation">)</span>
    
    <span class="token comment"># 反向传播</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span>

<span class="token comment"># 绘制结果</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>X_tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">&#39;blue&#39;</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;实际数据&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">&#39;red&#39;</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;拟合直线&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&#39;X&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&#39;y&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&#39;线性回归示例&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="softmax-分类" tabindex="-1"><a class="header-anchor" href="#softmax-分类" aria-hidden="true">#</a> Softmax 分类</h3><p>Softmax 是多分类任务，隐藏层为线性层，输出为多个。</p>`,5),l=n("p",null,[s("为了使输出为概率，使用 "),n("strong",null,"softmax"),s(),n("span",{class:"katex"},[n("span",{class:"katex-mathml"},[n("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[n("semantics",null,[n("mrow",null,[n("mi",null,"s"),n("mi",null,"i"),n("mi",null,"g"),n("mi",null,"m"),n("mi",null,"a"),n("mo",{stretchy:"false"},"("),n("mi",{mathvariant:"bold"},"z"),n("msub",null,[n("mo",{stretchy:"false"},")"),n("mi",null,"i")]),n("mo",null,"="),n("mfrac",null,[n("msup",null,[n("mi",null,"e"),n("msub",null,[n("mi",null,"z"),n("mi",null,"i")])]),n("mrow",null,[n("msubsup",null,[n("mo",null,"∑"),n("mrow",null,[n("mi",null,"j"),n("mo",null,"="),n("mn",null,"1")]),n("mi",null,"K")]),n("msup",null,[n("mi",null,"e"),n("msub",null,[n("mi",null,"z"),n("mi",null,"j")])])])]),n("mspace",{width:"1em"}),n("mtext",null,"for "),n("mi",null,"i"),n("mo",null,"="),n("mn",null,"1"),n("mo",{separator:"true"},","),n("mn",null,"2"),n("mo",{separator:"true"},","),n("mo",null,"…"),n("mo",{separator:"true"},","),n("mi",null,"K")]),n("annotation",{encoding:"application/x-tex"},"sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\quad \\text{for } i = 1, 2, \\ldots, K")])])]),n("span",{class:"katex-html","aria-hidden":"true"},[n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),n("span",{class:"mord mathnormal"},"s"),n("span",{class:"mord mathnormal"},"i"),n("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),n("span",{class:"mord mathnormal"},"ma"),n("span",{class:"mopen"},"("),n("span",{class:"mord mathbf"},"z"),n("span",{class:"mclose"},[n("span",{class:"mclose"},")"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.3117em"}},[n("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[n("span",{class:"pstrut",style:{height:"2.7em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mathnormal mtight"},"i")])])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.15em"}},[n("span")])])])])]),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),n("span",{class:"mrel"},"="),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"1.6629em","vertical-align":"-0.7519em"}}),n("span",{class:"mord"},[n("span",{class:"mopen nulldelimiter"}),n("span",{class:"mfrac"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.911em"}},[n("span",{style:{top:"-2.5703em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mop mtight"},[n("span",{class:"mop op-symbol small-op mtight",style:{position:"relative",top:"0em"}},"∑"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.8852em"}},[n("span",{style:{top:"-2.1786em","margin-left":"0em","margin-right":"0.0714em"}},[n("span",{class:"pstrut",style:{height:"2.5em"}}),n("span",{class:"sizing reset-size3 size1 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j"),n("span",{class:"mrel mtight"},"="),n("span",{class:"mord mtight"},"1")])])]),n("span",{style:{top:"-2.8971em","margin-right":"0.0714em"}},[n("span",{class:"pstrut",style:{height:"2.5em"}}),n("span",{class:"sizing reset-size3 size1 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"K")])])])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.4603em"}},[n("span")])])])])]),n("span",{class:"mspace mtight",style:{"margin-right":"0.1952em"}}),n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight"},"e"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.779em"}},[n("span",{style:{top:"-2.9714em","margin-right":"0.0714em"}},[n("span",{class:"pstrut",style:{height:"2.5em"}}),n("span",{class:"sizing reset-size3 size1 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.3448em"}},[n("span",{style:{top:"-2.3448em","margin-left":"-0.044em","margin-right":"0.1em"}},[n("span",{class:"pstrut",style:{height:"2.6595em"}}),n("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.5092em"}},[n("span")])])])])])])])])])])])])])])])]),n("span",{style:{top:"-3.23em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),n("span",{style:{top:"-3.394em"}},[n("span",{class:"pstrut",style:{height:"3em"}}),n("span",{class:"sizing reset-size6 size3 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight"},"e"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.7385em"}},[n("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[n("span",{class:"pstrut",style:{height:"2.5em"}}),n("span",{class:"sizing reset-size3 size1 mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mtight"},[n("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z"),n("span",{class:"msupsub"},[n("span",{class:"vlist-t vlist-t2"},[n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.3448em"}},[n("span",{style:{top:"-2.3448em","margin-left":"-0.044em","margin-right":"0.1em"}},[n("span",{class:"pstrut",style:{height:"2.6595em"}}),n("span",{class:"mord mathnormal mtight"},"i")])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.3147em"}},[n("span")])])])])])])])])])])])])])])])])]),n("span",{class:"vlist-s"},"​")]),n("span",{class:"vlist-r"},[n("span",{class:"vlist",style:{height:"0.7519em"}},[n("span")])])])]),n("span",{class:"mclose nulldelimiter"})]),n("span",{class:"mspace",style:{"margin-right":"1em"}}),n("span",{class:"mord text"},[n("span",{class:"mord"},"for ")]),n("span",{class:"mord mathnormal"},"i"),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),n("span",{class:"mrel"},"="),n("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),n("span",{class:"base"},[n("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),n("span",{class:"mord"},"1"),n("span",{class:"mpunct"},","),n("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),n("span",{class:"mord"},"2"),n("span",{class:"mpunct"},","),n("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),n("span",{class:"minner"},"…"),n("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),n("span",{class:"mpunct"},","),n("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),n("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K")])])]),s(" 函数，通过真实值与预测值的概率经过 "),n("strong",null,"交叉熵损失"),s(" 得到 0,1 值")],-1),i=a(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 1. 数据准备：下载MNIST数据集，并进行预处理</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># 2. 定义模型：一个简单的两层神经网络</span>
<span class="token keyword">class</span> <span class="token class-name">SimpleNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>  <span class="token comment"># 输入层 (28*28像素)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>     <span class="token comment"># 输出层 (10类)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span>            <span class="token comment"># 将输入展平</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment"># 第一个全连接层和ReLU激活函数</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                  <span class="token comment"># 第二个全连接层</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># 使用softmax函数生成概率分布</span>

<span class="token comment"># 3. 初始化模型、损失函数和优化器</span>
model <span class="token operator">=</span> SimpleNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 交叉熵损失函数 (softmax和损失结合)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 4. 训练模型</span>
num_epochs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>          <span class="token comment"># 前向传播</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token comment"># 计算损失</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># 梯度清零</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                  <span class="token comment"># 反向传播</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment"># 更新模型参数</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span>

<span class="token comment"># 5. 测试模型</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
correct <span class="token operator">=</span> <span class="token number">0</span>
total <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 预测最大概率的类</span>
        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Accuracy of the model on the 10000 test images: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">%&#39;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="多层感知机-mlp" tabindex="-1"><a class="header-anchor" href="#多层感知机-mlp" aria-hidden="true">#</a> 多层感知机 MLP</h3><p>感知机为二分类。给定输入 x，权重 w，偏移 b，感知机输出 0 或 1（有时为 -1 或 1）。它不能拟合 XOR 函数</p><p>多层感知机（MLP）的简单例子：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim

<span class="token comment"># 定义MLP模型</span>
<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 定义第一层全连接层</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        <span class="token comment"># 激活函数ReLU</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 定义第二层全连接层</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 第一层 + 激活函数</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token comment"># 输出层</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

<span class="token comment"># 模型实例化</span>
input_size <span class="token operator">=</span> <span class="token number">10</span>   <span class="token comment"># 输入特征数</span>
hidden_size <span class="token operator">=</span> <span class="token number">20</span>  <span class="token comment"># 隐藏层神经元数</span>
output_size <span class="token operator">=</span> <span class="token number">3</span>   <span class="token comment"># 输出类别数</span>

model <span class="token operator">=</span> MLP<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

<span class="token comment"># 损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

<span class="token comment"># 假设我们有一个大小为10的输入张量</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>  <span class="token comment"># 批次大小为5</span>
labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 随机生成5个类别标签</span>

<span class="token comment"># 前向传播</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 计算损失</span>
loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

<span class="token comment"># 反向传播和优化</span>
optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 梯度清零</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 反向传播</span>
optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 更新参数</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="卷积神经网络-cnn" tabindex="-1"><a class="header-anchor" href="#卷积神经网络-cnn" aria-hidden="true">#</a> 卷积神经网络 CNN</h2><p>卷积神经网络通常用于 <strong>图像、文本</strong> 处理</p><p>整体架构大致为：conv，relu，conv，relu，pool，conv....，fc</p><blockquote><p>n 层神经网络：有 n 层带参数的层（pool，relu 不算层）</p></blockquote><h3 id="输入层" tabindex="-1"><a class="header-anchor" href="#输入层" aria-hidden="true">#</a> 输入层</h3><h3 id="卷积层-conv-convolution" tabindex="-1"><a class="header-anchor" href="#卷积层-conv-convolution" aria-hidden="true">#</a> 卷积层 conv（convolution）</h3><p>卷积层中的 w 是卷积核，b 是偏置</p><p>![image-20240821222130729](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\python\\Machine Learning\\强化学习\\assets\\image-20240821222130729.png)</p><p>计算的记过成为 <strong>特征图</strong></p><p>一次卷积可以有多个 Filter，卷积后的深度就为 Filter 的个数（上述 7*3*3 经过 2 个 3*3*3 的 filter 变为 3*3*2 的特征图）卷积结果计算公式：</p><p>![image-20240822133826745](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\python\\Machine Learning\\强化学习\\assets\\image-20240822133826745.png)</p><p>可以对一次卷积后的特征图再卷积再卷积</p><p><strong>卷积层</strong> 涉及 <strong>参数</strong>：</p><ul><li>滑动窗口步长</li><li>卷积核尺寸</li><li>边缘填充</li><li>卷积核个数</li></ul><p>卷积层的权重（w + b）参数：所有卷积核的像素数 + 卷积核个数（偏置）</p><h3 id="池化层-pool" tabindex="-1"><a class="header-anchor" href="#池化层-pool" aria-hidden="true">#</a> 池化层 pool</h3><p>用于 <strong>压缩特征图</strong></p><p>例如 MAX POOLING： 2*2 的特征为一组，筛选最大的值</p><h3 id="全连接层-fc-1" tabindex="-1"><a class="header-anchor" href="#全连接层-fc-1" aria-hidden="true">#</a> 全连接层 fc</h3><p>通过前面 conv 和 pool 得到最后的特征图（假设为 32*32*10），任务为 n 分类任务</p><p>将特征图拉成特征向量 [1,32*32*10] ，则全连接层参数为 [32*32*10,n]</p><h2 id="经典多层神经网路" tabindex="-1"><a class="header-anchor" href="#经典多层神经网路" aria-hidden="true">#</a> 经典多层神经网路</h2><h3 id="alexnet-2012-年" tabindex="-1"><a class="header-anchor" href="#alexnet-2012-年" aria-hidden="true">#</a> AlexNet（2012 年）</h3><h3 id="vgg-2014-年" tabindex="-1"><a class="header-anchor" href="#vgg-2014-年" aria-hidden="true">#</a> Vgg（2014 年）</h3><h3 id="resnet-2015年" tabindex="-1"><a class="header-anchor" href="#resnet-2015年" aria-hidden="true">#</a> Resnet（2015年）</h3><p>vgg 在层数更多时，训练效果反而不好</p><p>resnet 将好的层保留，不好的层跳过。做法是通过对层数堆叠的值与同等映射的值进行比较</p><ul><li><p>若果层数堆叠的值不好，将层数堆叠权重设为 0</p><p>![image-20240822141714082](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\python\\Machine Learning\\强化学习\\assets\\image-20240822141714082.png)</p></li></ul><h2 id="迁移学习" tabindex="-1"><a class="header-anchor" href="#迁移学习" aria-hidden="true">#</a> 迁移学习</h2><p>深度学习的常见问题</p><ul><li>训练数据量过少。导致欠拟合、过拟合 <ul><li>使用数据增强</li></ul></li><li>参数调节过多、时间成本大</li></ul><p><strong>迁移学习</strong> 就是使用 <strong>他人的</strong> 与自己项1目相似（数据集相似，参数相似）的项目的网络的 <strong>w，b</strong> 参数</p><ul><li>继续训练 w，b 参数</li><li>微调网络（特别是 fc），继续训练一部分 w，b 参数</li></ul><p>迁移学习的速度非常快、pytorch 官网有迁移学习的例子</p><h2 id="rnn-递归神经网络" tabindex="-1"><a class="header-anchor" href="#rnn-递归神经网络" aria-hidden="true">#</a> RNN 递归神经网络</h2><p>RNN 的特点是带有时间序列，常用于 NLP，RNN 网络会将之前的结果全部记下来（h<sub>0</sub>，h<sub>1</sub> .......），即输入过多，效果并不好</p><p>![image-20240826143426351](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\python\\Machine Learning\\强化学习\\assets\\image-20240826143426351.png)</p><h2 id="lstm-网络" tabindex="-1"><a class="header-anchor" href="#lstm-网络" aria-hidden="true">#</a> LSTM 网络</h2><p>相较于 RNN，添加控制参数 c，决定什么样的信息会被保留，什么样的会被遗忘</p><h2 id="词向量模型-word2vec" tabindex="-1"><a class="header-anchor" href="#词向量模型-word2vec" aria-hidden="true">#</a> 词向量模型 Word2Vec</h2><p>文本向量化：</p><ul><li>使用一定维度的向量描述词语</li><li>数据维度越高，能提供的信息越多</li><li>相似的词在特征表达中比较相似</li></ul><p>词向量模型训练过程：</p><ul><li>输入： 一个一个词，根据词向量大表（随机初始化）转换为向量</li><li>输出：一个词，输出可能性最高的词，类似多分类任务</li><li>更新词向量大表中输入数据的词向量</li></ul><p>不同架构模型：</p><ul><li>CBOW</li><li>Skip-gram</li></ul><p>如果一个语料库很大，可能的结果就很多，最后一层 softmax 计算起来十分耗时。解决方案:</p><ul><li>输入两个单词，看他们是不是前后对应的输入和输出，相当于一个二分类任务</li><li>由于训练数据来自文本，上述方法的结果都为 1，因此引入 <strong>负采样</strong>，即认为添加结果为 0 的输入</li></ul><h2 id="gan-对抗生成网络" tabindex="-1"><a class="header-anchor" href="#gan-对抗生成网络" aria-hidden="true">#</a> GAN 对抗生成网络</h2><p>对抗生成网络有 <strong>生成器</strong> 与 <strong>判别器</strong></p><ul><li>生成器生成想要的东西</li><li>判别器用于判别</li></ul><p>![image-20240828214817355](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\python\\Machine Learning\\强化学习\\assets\\image-20240828214817355.png)</p><h2 id="cyclegan" tabindex="-1"><a class="header-anchor" href="#cyclegan" aria-hidden="true">#</a> CycleGan</h2><p>PatchGAN 的作用：</p><ul><li>输入一个 N * N 的矩阵个，基于感受野来计算损失</li><li>基于感受野在特征图上的预测结果和标签（也需设置成 N * N）计算损失</li></ul><h2 id="knn" tabindex="-1"><a class="header-anchor" href="#knn" aria-hidden="true">#</a> KNN</h2><h2 id="随机森林" tabindex="-1"><a class="header-anchor" href="#随机森林" aria-hidden="true">#</a> 随机森林</h2>`,62),u=[c,l,i];function r(k,m){return p(),e("div",null,u)}const h=t(o,[["render",r],["__file","网络架构.html.vue"]]);export{h as default};
