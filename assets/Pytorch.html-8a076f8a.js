import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{r as l,o as c,c as o,b as s,f as n,e as p,d as a}from"./app-ade67b06.js";const i={},u=s("h2",{id:"_1、安装-pytoch",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_1、安装-pytoch","aria-hidden":"true"},"#"),n(" 1、安装 Pytoch")],-1),r=s("p",null,"创建新环境并下载 Pytorch",-1),m=a("<li><p>打开 Anaconda Prompt</p></li><li><p>使用指令 <code>conda create -n evn_name python=3.6 </code> 创建环境</p></li><li><p>使用指令 <code>conda activate evn_name</code> 切换环境</p></li><li><p>通过 <code>pip list</code> 查看环境的所有包</p></li>",4),d={href:"https://pytorch.org/",target:"_blank",rel:"noopener noreferrer"},k=a(`<div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>conda <span class="token function">install</span> pytorch torchvision torchaudio pytorch-cuda<span class="token operator">=</span><span class="token number">11.8</span> <span class="token parameter variable">-c</span> pytorch <span class="token parameter variable">-c</span> nvidia
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,1),h=a(`<p>在新环境下下载 Jupyter</p><h2 id="_2、简单回归问题" tabindex="-1"><a class="header-anchor" href="#_2、简单回归问题" aria-hidden="true">#</a> 2、简单回归问题</h2><ul><li>梯度下降 Gradient Descent</li><li>线性回归</li><li>逻辑回归</li></ul><h3 id="手写数字识别案例" tabindex="-1"><a class="header-anchor" href="#手写数字识别案例" aria-hidden="true">#</a> 手写数字识别案例</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch <span class="token keyword">import</span> optim

<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> utils <span class="token keyword">import</span> plot_image<span class="token punctuation">,</span>plot_curve<span class="token punctuation">,</span>one_hot


batch_size <span class="token operator">=</span> <span class="token number">512</span>

<span class="token comment"># step1. 加载数据</span>
train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
    torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">&#39;mnist_data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                               transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                                   torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>
                                       <span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                               <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
    torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">&#39;mnist_data/&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                               transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                                   torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                   torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>
                                       <span class="token punctuation">(</span><span class="token number">0.1307</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.3081</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                               <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

x<span class="token punctuation">,</span> y <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plot_image<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">&#39;image sample&#39;</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># xw+b</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># x: [b, 1, 28, 28]</span>
        <span class="token comment"># h1 = relu(xw1+b1)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># h2 = relu(h1w2+b2)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># h3 = h2w3+b3</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x



net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># [w1, b1, w2, b2, w3, b3]</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>


train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># x: [b, 1, 28, 28], y: [512]</span>
        <span class="token comment"># [b, 1, 28, 28] =&gt; [b, 784]</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span>
        <span class="token comment"># =&gt; [b, 10]</span>
        out <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># [b, 10]</span>
        y_onehot <span class="token operator">=</span> one_hot<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        <span class="token comment"># loss = mse(out, y_onehot)</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>out<span class="token punctuation">,</span> y_onehot<span class="token punctuation">)</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># w&#39; = w - lr*grad</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">10</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> batch_idx<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plot_curve<span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span>

total_correct <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> x<span class="token punctuation">,</span>y <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
    x  <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment"># out: [b, 10] =&gt; pred: [b]</span>
    pred <span class="token operator">=</span> out<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    correct <span class="token operator">=</span> pred<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_correct <span class="token operator">+=</span> correct

total_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>
acc <span class="token operator">=</span> total_correct <span class="token operator">/</span> total_num
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;test acc:&#39;</span><span class="token punctuation">,</span> acc<span class="token punctuation">)</span>

x<span class="token punctuation">,</span> y <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
out <span class="token operator">=</span> net<span class="token punctuation">(</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pred <span class="token operator">=</span> out<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
plot_image<span class="token punctuation">(</span>x<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> <span class="token string">&#39;test&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3、张量" tabindex="-1"><a class="header-anchor" href="#_3、张量" aria-hidden="true">#</a> 3、张量</h2><h3 id="数据类型" tabindex="-1"><a class="header-anchor" href="#数据类型" aria-hidden="true">#</a> 数据类型</h3><p>在 python 中有数据类型 int、float......，在 PyTorch 中对应 IntTensor，FloatTensor，同时该数据类型有维度，如 int 标量 3 的维度是 0，矩阵的维度是 2</p><p>注：PyTorch 没有对应 python 中 string 类型的数据类型，解决方案有：one-hot [0,1,0...]、Embedding（Word2vec，glove）</p><p>数据类型</p><table><thead><tr><th>数据类型</th><th>dtype</th><th>CPU Tensor</th><th>GPU Tensor</th></tr></thead><tbody><tr><td>32bit float</td><td><code>torch.float</code> or <code>torch.float32</code></td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>64bit float</td><td><code>torch.double</code> or <code>torch.float64</code></td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr><tr><td>8bit integer</td><td><code>torch.uint8</code></td><td>torch.ByteTensor</td><td>torch.cuda.ByteTensor</td></tr><tr><td>32bit integer</td><td><code>torch.int32</code> or <code>torch.int</code></td><td>torch.IntTensor</td><td>torch.cuda.IntTensor</td></tr><tr><td>64bit integer</td><td><code>torch.int64</code> or <code>torch.long</code></td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr></tbody></table><ul><li>Dimension（维度）为 0 的一般称为 <code>标量</code></li><li>Dimension（维度）为 1 的一般称为 <code>张量</code>（数学中成为向量）</li></ul><h3 id="常用方法" tabindex="-1"><a class="header-anchor" href="#常用方法" aria-hidden="true">#</a> 常用方法</h3><table><thead><tr><th>方法</th><th>含义</th></tr></thead><tbody><tr><td><code>a.type()</code></td><td>获取 tensor 的类型</td></tr><tr><td><code>isinstance(a,torch.FloatTensor)</code></td><td>合法化检验，判断 tensor 是否是某个类型的 tensor，cpu tensor 和 cuda tensor 返回结果不同</td></tr><tr><td><code>torch.from_numpy(a)</code></td><td>使用 numpy 创建 tensor</td></tr><tr><td><code>torch.tensor(value)</code></td><td>创建 tensor，参数中接收的是数据的内容</td></tr><tr><td><code>torch.FloatTensor(nums/shape/value)</code> <br><code>torch.IntTensor(nums/shape/value)</code> <br><code>torch.Tensor(nums/shape/value)</code>...</td><td>参数接收个数， shape 或 value 创建 tensor <br><code>torch.FloatTensor(2),torch.FloatTensor(2,3),torch.FloatTensor([2.,8.3])</code></td></tr><tr><td><code>torch.empty(shape)</code></td><td>创建未初始化 tensor</td></tr><tr><td><code>torch.set_default_tensor_type(torch.DoubleTensor)</code></td><td>设置 pytorch 默认 tensor 类型，使用 torch.Tensor() 方法默认创建默认类型 tensor</td></tr><tr><td><code>a = a.cuda()</code></td><td>返回一个 gpu 上的引用</td></tr><tr><td><code>a.dim()</code></td><td>返回 tensor 的维度（size 的长度）</td></tr><tr><td><code>a.shape</code></td><td>返回 tensor 的 size（不同维度长度的数组）</td></tr><tr><td><code>torch.rand(shape)</code></td><td>参数接收 size 数组，产生 [0,1] 均匀分布随机值的 tensor</td></tr><tr><td><code>torch.rand_like(a)</code></td><td>创建与 tensor a shape 相同的随机 tensor</td></tr><tr><td><code>torch.randint(min,max,shape)</code></td><td>创建值左闭右开的随机 tensor</td></tr><tr><td><code>torch.randn(shape)</code></td><td>参数接收 size 数组，产生 [0,1] 正态分布随机值的 tensor</td></tr><tr><td><code>torch.randperm(num)</code></td><td>生成 0 - num 左闭右开的位置随机的 tensor</td></tr><tr><td><code>torch.ones(shape)</code></td><td>生成全是 1 的 tensor</td></tr><tr><td><code>torch.zeros(shape)</code></td><td>生成全是 0 的 tensor</td></tr><tr><td><code>torch.eye(shape)</code></td><td>对角是 1 的 tensor</td></tr><tr><td><code>torch.full(shape,value)</code></td><td>生成值都一样的 tensor</td></tr><tr><td><code>torch.arange(min,max,step)</code></td><td>生成值为等差数列的 tensor</td></tr><tr><td><code>torch.linspace(min,max,steps=nums)</code></td><td>生成 nums 个等差值的 tensor</td></tr><tr><td><code>a.size(i)</code></td><td>返回 size 数组索引为 i 的值</td></tr><tr><td><code>a.shape[i]</code></td><td>返回 size 数组索引为 i 的值，也可以直接使用 <code>a.shape</code> 获取 size 对象，可以直接使用 <code>list(a.shape)</code> 将 size 转换为 list</td></tr><tr><td><code>a.numel()</code></td><td>返回 tensor 占用的内存</td></tr></tbody></table><ol><li><p>创建 dim 0 的 tensor：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.2</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">7.</span><span class="token punctuation">)</span> <span class="token comment"># dim 为 0</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>创建 dim 1 的 tensor</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.2</span><span class="token punctuation">,</span><span class="token number">3.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># 使用 numpy 创建</span>
data <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>创建 dim 2 的 tensor</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>shape
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>创建 dim 3 的 tensor</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>shape
a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token builtin">list</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="tensor-索引及切片" tabindex="-1"><a class="header-anchor" href="#tensor-索引及切片" aria-hidden="true">#</a> tensor 索引及切片</h3><p>索引</p><ul><li>无论什么方法通过索引取出维度必然下降</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([3,28,28])</span>
a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([28,28])</span>
a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token comment"># tensor(0.8082)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>切片</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([2,3,28,28])</span>
a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([2,1,28,28])</span>
a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([2,2,28,28])</span>
a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([2,1,28,28])</span>
a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">28</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">28</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4,3,14,14])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>a.index_select(num,tensor) 函数</p><ul><li>第一个参数 num 表示对那个维度进行操作</li><li>第二个参数 <ul><li>torch.tensor[x,y]，左右都为闭区间，表示该维度上的范围</li><li>torch.arange(x)，该维度从 0 - x 左闭右开的范围</li></ul></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([2,3,28,28])</span>
a<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4,2,28,28])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>...</p><ul><li>... 代表若干个 :</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4,3,28,28])</span>
a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([3,28,28])</span>
a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4,28,28])</span>
a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4,3,28,2])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>masked_select()</p><ul><li>通过掩码索引</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
mask <span class="token operator">=</span> x<span class="token punctuation">.</span>ge<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token comment"># 元素值大于 0.5 的</span>
torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span>mask<span class="token punctuation">)</span> <span class="token comment"># size 为 [x] 一维 </span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>take()</p><ul><li>先将元素打平成一维</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>take<span class="token punctuation">(</span>src<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># tensor([4,5,8])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="维度变换" tabindex="-1"><a class="header-anchor" href="#维度变换" aria-hidden="true">#</a> 维度变换</h3><h4 id="view-reshape" tabindex="-1"><a class="header-anchor" href="#view-reshape" aria-hidden="true">#</a> view reshape</h4><ul><li>使用 a.view(shape) 方法对 tensor 进行变换</li><li>变换后新的 tensor 会丢失原来的维度信息</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span> <span class="token comment"># 维度变换为二维 4 1*28*28 , shape 为 4,784</span>
a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># 4,28,28</span>
b <span class="token operator">=</span> a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">784</span><span class="token punctuation">)</span>
b<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># Logic Bug</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="unsqueeze" tabindex="-1"><a class="header-anchor" href="#unsqueeze" aria-hidden="true">#</a> unsqueeze</h4><ul><li>使用 a.unsqueeze(index) 方法添加维度</li><li>通过索引添加，正数在前负数在后</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># [1,4,1,28,28]</span>
a<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># [4,1,28,28,1]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="squeeze" tabindex="-1"><a class="header-anchor" href="#squeeze" aria-hidden="true">#</a> squeeze</h4><ul><li>使用 a.squeeze(index) 方法减少维度，只能减少维度值是 1 的维度</li><li>不添加 index 参数，挤压所有维度值是 1 的维度</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>b<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1,32,1,1])</span>
b<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([32])</span>
b<span class="token punctuation">.</span>squzzez<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([32,1,1])</span>
b<span class="token punctuation">.</span>squzzez<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1,32,1])</span>
b<span class="token punctuation">.</span>squzzez<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1,32,1,1])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="expand" tabindex="-1"><a class="header-anchor" href="#expand" aria-hidden="true">#</a> expand</h4><ul><li>a.expand(shape) 方法可以将维度值扩展</li><li>只能扩展值为 1 的维度到 n</li><li>-1 代表原来的维度不变</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">)</span>
b<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1,32,1,1])</span>
b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">,</span><span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4，32，14，14])</span>
b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.size([1， 32，1， 1])</span>
b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1, 32，1，-4]) -4 是无意义的</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="repeat" tabindex="-1"><a class="header-anchor" href="#repeat" aria-hidden="true">#</a> repeat</h4><ul><li>a.repeat(shape) 可以将维度值进行拷贝</li><li>该方法内存占用多，推荐使用 expand</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>b<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1, 32，1, 1])</span>
b<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4，1024，1, 1])</span>
b<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([4，32，1，1])</span>
b<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.size([4，32， 32，32])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="t" tabindex="-1"><a class="header-anchor" href="#t" aria-hidden="true">#</a> t</h4><ul><li>矩阵转置，t 方法只能用于维度为 2 的 tensor</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="transpose" tabindex="-1"><a class="header-anchor" href="#transpose" aria-hidden="true">#</a> transpose</h4><ul><li>a.transpose(a,b) 方法用于两个维度交换</li><li>交换后的 tensor 进行 view 变换前使用 contiguous 方法，将数据变为连续，变换回来需再交换</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a<span class="token punctuation">.</span>shape <span class="token comment"># [4,3,32,32]</span>
a1 <span class="token operator">=</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment"># [4,32,32,3]</span>
a2 <span class="token operator">=</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">32</span><span class="token operator">*</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="permute" tabindex="-1"><a class="header-anchor" href="#permute" aria-hidden="true">#</a> permute</h4><ul><li>permute 方法通过索引交换维度</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># [4,28,32,3]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="broadcast-自动扩张机制" tabindex="-1"><a class="header-anchor" href="#broadcast-自动扩张机制" aria-hidden="true">#</a> Broadcast 自动扩张机制</h4><p>Broadcast 可以对需要扩张的 tensor 自动扩张成 size 与另一个 tensor 相同的机制</p><p>Broadcast 适用范围：须变换 tensor 与目标 tensor 对应维度值相同或是 1</p><h3 id="合并与分割" tabindex="-1"><a class="header-anchor" href="#合并与分割" aria-hidden="true">#</a> 合并与分割</h3><ul><li><p><code>torch.cat([tensor],dim)</code></p><ul><li><p>用于 tensor 在相同维度的合并，参数：</p><ul><li>tensor 列表</li><li>dim 要变换的维度索引</li></ul></li><li><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([9,32,8])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li><li><p><code>torch.stack([tensor],dim)</code></p><ul><li><p>用于 tensor 的聚集，并在 dim 索引上产生新的维度，数量为 tensor 列表的数量，参数：</p><ul><li>tensor 列表</li><li>dim 要变换的维度索引</li></ul></li><li><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([2,32,8])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li><li><p><code>torch.split(list/len,dim)</code></p><ul><li><p>用于对 tensor 某个维度进行拆分，拆分方式可以指定一个 list 或指定长度，参数：</p><ul><li>list / len：指定拆分方式</li><li>dim：维度索引</li></ul></li><li><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>b<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([32，8])</span>
c<span class="token operator">=</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
c<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([2，32，8])</span>
aa<span class="token punctuation">,</span> bb <span class="token operator">=</span> c<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
aa<span class="token punctuation">.</span>shape <span class="token punctuation">,</span> bb<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([1 32，8])， torch.size([1， 32，8])</span>
aa<span class="token punctuation">,</span> bb <span class="token operator">=</span> c<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
aa<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>bb<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([1，32，8])， torch.size([1，32，8])</span>
aa<span class="token punctuation">,</span> bb <span class="token operator">=</span> c<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># error</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li><li><p><code>torch.chunk(num,dim)</code></p><ul><li><p>用于对 tensor 某个维度进行拆分，拆分成 num 个 tensor，参数：</p><ul><li>num：拆分的数量</li><li>dim：维度索引</li></ul></li><li><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>b<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([32，8])</span>
c<span class="token operator">=</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span>o<span class="token punctuation">)</span>
c<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([2，32，8])</span>
aa<span class="token punctuation">,</span>bb <span class="token operator">=</span> c<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
aa shape<span class="token punctuation">,</span>bb<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([1，32，8]), torch.size([1，32，8])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li></ul><h3 id="数学运算" tabindex="-1"><a class="header-anchor" href="#数学运算" aria-hidden="true">#</a> 数学运算</h3>`,64),g=s("li",null,[n("加减乘除 "),s("ul",null,[s("li",null,"tensor 可以使用 +、-、*、/ 或 add、sub、mul、div 方法进行运算，运算时会有 broadcast 机制")])],-1),v={href:"http://torch.mm",target:"_blank",rel:"noopener noreferrer"},b=s("li",null,[n("torch.matmul，该方法适用于所有维度的 tensor "),s("ul",null,[s("li",null,"多维矩阵乘法规则：后两维矩阵相乘，前面的保持不变或进行 broadcast")])],-1),y=s("li",null,"@，与 matmul 方法相同",-1),x=a("<li>幂运算、对数运算 <ul><li>a.pow(num) / a**num</li><li>a.sqrt()：平方根</li><li>a.rsqrt()：平方根的倒数</li><li>torch.exp(a)：tensor 中每一个数做为 e 为底的次方</li><li>torch.log(a)：tensor 中每一个数取 e 的对数</li></ul></li><li>其他 <ul><li>a.floor()</li><li>a.ceil()</li><li>a.trunc()：取整数</li><li>a.frac()：取小数</li><li>a.max()</li><li>a.min()</li><li>a.clamp(num)：最小值限定</li><li>a.clamp(num1,num2)：区间限定</li><li>sum，mean（均值），prod（累乘），argmax（最大值索引），argmin（最小值索引）</li></ul></li>",2),w=s("h3",{id:"属性统计",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#属性统计","aria-hidden":"true"},"#"),n(" 属性统计")],-1),f=s("ul",null,[s("li",null,[s("p",null,"a.norm(num,dim)："),s("p",null,"参数 num 代表做几范数"),s("p",null,"dim 表示对对应维度索引操作"),s("ul",null,[s("li",null,[s("p",null,[n("a.norm(1)：求合 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",null,"∑"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"x"),s("mi",{mathvariant:"normal"},"∣")]),s("annotation",{encoding:"application/x-tex"},"\\sum|x|")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord"},"∣")])])])])]),s("li",null,[s("p",null,"a.norm(2)：平方和开根 $\\sqrt{\\sum|x|^2 } $")]),s("li",null,[s("p",null,"a.norm(2,dim=1)：指定维度")])]),s("p",null,"对某个维度取范数，对应维度就会消掉"),s("p",null,"![image-20240704134612532](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240704134612532.png)")]),s("li",null,[s("p",null,"min，max，sum，mean（均值），prod（累乘），argmax（最大值索引），argmin（最小值索引）"),s("p",null,[n("min，max 带 "),s("code",null,"dim"),n(" 参数返回该 dim 索引的最大值和索引两个tensor")]),s("p",null,[n("min，max 带 "),s("code",null,"keepdim = True"),n(" 参数返回的最大值 tensor 与原维度相同")]),s("p",null,[n("注意：argmax，argmin 不带参数调用会将维度打平，传入参数 "),s("code",null,"dim=x"),n("，计算对应维度最值索引")])]),s("li",null,[s("p",null,"a.topk(num,dim,largest)"),s("ul",null,[s("li",null,[s("p",null,"num：几个最大值")]),s("li",null,[s("p",null,"dim：维度索引")]),s("li",null,[s("p",null,"largest：默认为 True，False 为最小的几个"),s("div",{class:"language-python line-numbers-mode","data-ext":"py"},[s("pre",{class:"language-python"},[s("code",null,[n("a"),s("span",{class:"token punctuation"},"."),n("topk"),s("span",{class:"token punctuation"},"("),s("span",{class:"token number"},"3"),s("span",{class:"token punctuation"},","),n("dim"),s("span",{class:"token operator"},"="),s("span",{class:"token number"},"1"),s("span",{class:"token punctuation"},")"),n(`
a`),s("span",{class:"token punctuation"},"."),n("topk"),s("span",{class:"token punctuation"},"("),s("span",{class:"token number"},"5"),s("span",{class:"token punctuation"},","),n("dim"),s("span",{class:"token operator"},"="),s("span",{class:"token number"},"1"),s("span",{class:"token punctuation"},","),n("largest"),s("span",{class:"token operator"},"="),s("span",{class:"token boolean"},"False"),s("span",{class:"token punctuation"},")"),n(`
`)])]),s("div",{class:"line-numbers","aria-hidden":"true"},[s("div",{class:"line-number"}),s("div",{class:"line-number"})])])])])]),s("li",null,[s("p",null,"a.kthvalue(num,dim)"),s("ul",null,[s("li",null,"返回 dim 索引维度上第 num 小的 tensor 及其索引")])]),s("li",null,[s("p",null,"compare"),s("ul",null,[s("li",null,">,<,>=,<=,!=,=="),s("li",null,"torch.eq(a,b) 判断对应值是否相等"),s("li",null,"torch.equal(a,b) 判断完全是否一样")])])],-1),z=a(`<h3 id="高阶操作" tabindex="-1"><a class="header-anchor" href="#高阶操作" aria-hidden="true">#</a> 高阶操作</h3><ul><li><p>torch.where(condition,x,y)</p><p>根据条件返回 x，y 两个 tensor 的合并，condition 为 True 选 x，反之选 y</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>cond <span class="token comment"># [[0.6,0.7],[0.8,0.4]]</span>
a <span class="token comment">#[[0,0],[0,0]]</span>
b <span class="token comment">#[[1,1],[1,1]]</span>
torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>cond<span class="token operator">&gt;</span><span class="token number">0.5</span><span class="token punctuation">,</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token comment">#[[0,0][0,1]]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>torch.gather(input,dim,index,out=None)</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>prob<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
idx<span class="token operator">=</span>prob<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span>， k<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
    (tensor([[2.4437，1.5195，1.3598],
    [1.6027, 1.4003,0.7402],
    [2.8965，0.3600，0.1961],
    [2.2636，0.9490，0.3886]]),
    tensor([[7，4，9],
    [7，4, 9],
    [8，1, 3],
    [8，6，o]]))
&#39;&#39;&#39;</span>
idx<span class="token operator">=</span>idx<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
label<span class="token operator">=</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">100</span> <span class="token comment"># tensor([100， 101, 102， 103，104， 105， 106，107，108，109])</span>
torch<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>label<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token operator">=</span>idx<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[107，104，109],
[107，104，109],
[108, 101, 103],
[108, 106,100]])
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h2 id="_4、梯度、激活函数、链式法则、反向传播" tabindex="-1"><a class="header-anchor" href="#_4、梯度、激活函数、链式法则、反向传播" aria-hidden="true">#</a> 4、梯度、激活函数、链式法则、反向传播</h2><h3 id="梯度" tabindex="-1"><a class="header-anchor" href="#梯度" aria-hidden="true">#</a> 梯度</h3>`,4),_=s("ul",null,[s("li",null,[s("p",null,"导数 ， 函数变化率")]),s("li",null,[s("p",null,"偏微分，函数对不同变量的导数")]),s("li",null,[s("p",null,"梯度：函数对不同导数构成的向量"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mo",null,"▽"),s("mi",null,"f"),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"f")]),s("msub",null,[s("mi",null,"x"),s("mn",null,"1")])]),s("mo",{separator:"true"},";"),s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"f")]),s("msub",null,[s("mi",null,"x"),s("mn",null,"2")])]),s("mo",{separator:"true"},";"),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mo",{separator:"true"},";"),s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"f")]),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"n")]),s("mo",{separator:"true"},",")])]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," \\bigtriangledown f = (\\frac{\\partial f}{x_1};\\frac{\\partial f}{x_2};...;\\frac{\\partial f}{x_n,} ) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},"▽"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.2519em","vertical-align":"-0.8804em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.836em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mpunct"},";"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.836em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mpunct"},";"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mpunct"},";"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},",")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8804em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose"},")")])])])])])])],-1),M=s("p",null,"如何通过梯度寻找到极小值解（：a 为 learning rate 学习率）：",-1),S=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"θ"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"="),s("msub",null,[s("mi",null,"θ"),s("mi",null,"t")]),s("mo",null,"−"),s("msub",null,[s("mi",null,"α"),s("mi",null,"t")]),s("mo",null,"▽"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"θ"),s("mi",null,"t")]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," \\theta_{t+1} = \\theta_t - \\alpha_t\\bigtriangledown f(\\theta_t) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9028em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8444em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0037em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"▽"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])])])],-1),L=s("h3",{id:"激活函数",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#激活函数","aria-hidden":"true"},"#"),n(" 激活函数")],-1),T=s("ul",null,[s("li",null,[s("p",null,[n("Sigmoid / Logistics"),s("br"),n(" 将数进一步压缩到 [0,1]")]),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mn",null,"1"),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])])]),s("mspace",{linebreak:"newline"}),s("msup",null,[s("mi",null,"σ"),s("msup",null,[s("mrow"),s("mo",{mathvariant:"normal",lspace:"0em",rspace:"0em"},"′")])]),s("mo",null,"="),s("mi",null,"σ"),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("mi",null,"σ"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," f(x) = \\sigma(x) = \\frac{1}{1 + e^{-x}} \\\\ \\sigma^{'} = \\sigma(1-\\sigma) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0908em","vertical-align":"-0.7693em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6973em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9925em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9925em"}},[s("span",{style:{top:"-2.9925em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.5795em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8278em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"′")])])])])])])])])])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mclose"},")")])])])])]),s("p",null,"在 pytorch 中使用 sigmod"),s("div",{class:"language-python line-numbers-mode","data-ext":"py"},[s("pre",{class:"language-python"},[s("code",null,[s("span",{class:"token keyword"},"from"),n(" torch"),s("span",{class:"token punctuation"},"."),n("nn "),s("span",{class:"token keyword"},"import"),n(" functional "),s("span",{class:"token keyword"},"as"),n(` F
a `),s("span",{class:"token operator"},"="),n(" torch"),s("span",{class:"token punctuation"},"."),n("linspace"),s("span",{class:"token punctuation"},"("),s("span",{class:"token operator"},"-"),s("span",{class:"token number"},"100"),s("span",{class:"token punctuation"},","),s("span",{class:"token number"},"100"),s("span",{class:"token punctuation"},","),s("span",{class:"token number"},"10"),s("span",{class:"token punctuation"},")"),n(`
torch`),s("span",{class:"token punctuation"},"."),n("sigmod"),s("span",{class:"token punctuation"},"("),n("a"),s("span",{class:"token punctuation"},")"),n(`
F`),s("span",{class:"token punctuation"},"."),n("sigmod"),s("span",{class:"token punctuation"},"("),n("a"),s("span",{class:"token punctuation"},")"),n(),s("span",{class:"token comment"},"# 与上面相同，已过时"),n(`
`)])]),s("div",{class:"line-numbers","aria-hidden":"true"},[s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"})])])]),s("li",null,[s("p",null,"Tanh"),s("p",null,[n("该函数在 RNN 中用的多"),s("br"),n(" 将数进一步压缩到 [-1,1]")]),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mtable",{rowspacing:"0.16em",columnspacing:"1em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mi",null,"tanh"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"−"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])]),s("mrow",null,[s("msup",null,[s("mi",null,"e"),s("mi",null,"x")]),s("mo",null,"+"),s("msup",null,[s("mi",null,"e"),s("mrow",null,[s("mo",null,"−"),s("mi",null,"x")])])])])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("mo",null,"="),s("mn",null,"2"),s("mi",null,"s"),s("mi",null,"i"),s("mi",null,"g"),s("mi",null,"m"),s("mi",null,"o"),s("mi",null,"i"),s("mi",null,"d"),s("mo",{stretchy:"false"},"("),s("mn",null,"2"),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"−"),s("mn",null,"1")]),s("annotation",{encoding:"application/x-tex"}," f(x) =\\begin{equation} \\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\end{equation} = 2 sigmoid(2x)-1 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"=")]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.2177em","vertical-align":"-0.8588em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3588em"}},[s("span",{style:{top:"-3.3588em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},"tanh"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.4483em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.5904em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6973em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6644em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"x")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7713em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"x")])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8588em"}},[s("span")])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3588em"}},[s("span",{style:{top:"-3.3588em"}},[s("span",{class:"pstrut",style:{height:"3.4483em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8588em"}},[s("span")])])])]),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"2"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"2"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6444em"}}),s("span",{class:"mord"},"1")])])])])])]),s("li",null,[s("p",null,"ReLU"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.16em",columnspacing:"1em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mtext",null,"ReLU"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"max"),s("mo",null,"⁡"),s("mo",{stretchy:"false"},"("),s("mn",null,"0"),s("mo",{separator:"true"},","),s("mi",null,"x"),s("mo",{stretchy:"false"},")")])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"}," \\begin{equation} \\text{ReLU}(x) = \\max(0, x) \\end{equation} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2em","vertical-align":"-0.35em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.85em"}},[s("span",{style:{top:"-3.01em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord text"},[s("span",{class:"mord"},"ReLU")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mop"},"max"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.35em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.85em"}},[s("span",{style:{top:"-2.85em"}},[s("span",{class:"pstrut",style:{height:"2.84em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.35em"}},[s("span")])])])])])])])]),s("p",null,"在 pytorch 中使用 ReLU"),s("div",{class:"language-python line-numbers-mode","data-ext":"py"},[s("pre",{class:"language-python"},[s("code",null,[s("span",{class:"token keyword"},"from"),n(" torch"),s("span",{class:"token punctuation"},"."),n("nn "),s("span",{class:"token keyword"},"import"),n(" functional "),s("span",{class:"token keyword"},"as"),n(` F
a `),s("span",{class:"token operator"},"="),n(" torch"),s("span",{class:"token punctuation"},"."),n("linspace"),s("span",{class:"token punctuation"},"("),s("span",{class:"token operator"},"-"),s("span",{class:"token number"},"1"),s("span",{class:"token punctuation"},","),s("span",{class:"token number"},"1"),s("span",{class:"token punctuation"},","),s("span",{class:"token number"},"10"),s("span",{class:"token punctuation"},")"),n(`
torch`),s("span",{class:"token punctuation"},"."),n("relu"),s("span",{class:"token punctuation"},"("),n("a"),s("span",{class:"token punctuation"},")"),n(`
F`),s("span",{class:"token punctuation"},"."),n("relu"),s("span",{class:"token punctuation"},"("),n("a"),s("span",{class:"token punctuation"},")"),n(`
`)])]),s("div",{class:"line-numbers","aria-hidden":"true"},[s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"}),s("div",{class:"line-number"})])])])],-1),q=s("h3",{id:"loss-及其梯度",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#loss-及其梯度","aria-hidden":"true"},"#"),n(" Loss 及其梯度")],-1),E=s("p",null,"Loss 有",-1),P=s("ul",null,[s("li",null,[s("p",null,"Mean Squared Error（MSE）均方误差"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"l"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"s"),s("mo",null,"="),s("mtable",{rowspacing:"0.16em",columnspacing:"1em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mtext",null,"MSE"),s("mo",null,"="),s("mo",null,"∑"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"y"),s("mi",null,"i")]),s("mo",null,"−"),s("msub",null,[s("mover",{accent:"true"},[s("mi",null,"y"),s("mo",null,"^")]),s("mi",null,"i")]),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"2")])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])])]),s("annotation",{encoding:"application/x-tex"}," loss = \\begin{equation} \\text{MSE} = \\sum(y_i - \\hat{y}_i)^2 \\end{equation} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"oss"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"=")]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.6em","vertical-align":"-0.55em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"mord"},[s("span",{class:"mord text"},[s("span",{class:"mord"},"MSE")]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mop op-symbol large-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6944em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y")]),s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.1944em"}},[s("span",{class:"mord"},"^")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1944em"}},[s("span")])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.55em"}},[s("span")])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.55em"}},[s("span")])])])])])])])])])]),s("li",null,[s("p",null,"Cross Entropy Loss"),s("ul",null,[s("li",null,"可用于二分类"),s("li",null,"多分类"),s("li",null,"+softmax"),s("li",null,"Leave it to Logistic Regression Part")])])],-1),F=s("h4",{id:"mse",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#mse","aria-hidden":"true"},"#"),n(" MSE")],-1),j=s("ul",null,[s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"l"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"s"),s("mo",null,"="),s("mo",null,"∑"),s("mo",{stretchy:"false"},"["),s("mi",null,"y"),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mi",null,"w"),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")"),s("msup",null,[s("mo",{stretchy:"false"},"]"),s("mn",null,"2")]),s("mo",null,"="),s("mo",null,"∑"),s("mo",{stretchy:"false"},"["),s("mi",null,"y"),s("mo",null,"−"),s("msub",null,[s("mi",null,"f"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("msup",null,[s("mo",{stretchy:"false"},"]"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"loss = \\sum[y-(xw+b)]^2 = \\sum[y-f_\\theta(x)]^2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"oss"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},[s("span",{class:"mclose"},"]"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1076em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},[s("span",{class:"mclose"},"]"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mn",null,"2"),s("mo",null,"−"),s("mi",null,"n"),s("mi",null,"o"),s("mi",null,"r"),s("mi",null,"m"),s("mo",null,"="),s("mi",{mathvariant:"normal"},"∣"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"y"),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mi",null,"w"),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")"),s("mi",{mathvariant:"normal"},"∣"),s("msub",null,[s("mi",{mathvariant:"normal"},"∣"),s("mn",null,"2")]),s("mo",null,"="),s("msqrt",null,[s("mrow",null,[s("mo",null,"∑"),s("mrow",null,[s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"y"),s("mrow",null,[s("mn",null,"1"),s("mi",null,"i"),s("mi",null,"j")])]),s("mo",null,"−"),s("msub",null,[s("mi",null,"y"),s("mrow",null,[s("mn",null,"2"),s("mi",null,"i"),s("mi",null,"j")])]),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"2")])])])])]),s("annotation",{encoding:"application/x-tex"},"L2-norm = ||y-(xw+b)||_2 = \\sqrt{\\sum{(y_{1ij}-y_{2ij})^2}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord"},"2"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"∣∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},"∣"),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.24em","vertical-align":"-0.3231em"}}),s("span",{class:"mord sqrt"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9169em"}},[s("span",{class:"svg-align",style:{top:"-3.2em"}},[s("span",{class:"pstrut",style:{height:"3.2em"}}),s("span",{class:"mord",style:{"padding-left":"1em"}},[s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7401em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])]),s("span",{style:{top:"-2.8769em"}},[s("span",{class:"pstrut",style:{height:"3.2em"}}),s("span",{class:"hide-tail",style:{"min-width":"1.02em",height:"1.28em"}},[s("svg",{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.28em",viewBox:"0 0 400000 1296",preserveAspectRatio:"xMinYMin slice"},[s("path",{d:`M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z`})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3231em"}},[s("span")])])])])])])])]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"l"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"s"),s("mo",null,"="),s("mi",null,"n"),s("mi",null,"o"),s("mi",null,"r"),s("mi",null,"m"),s("mo",{stretchy:"false"},"("),s("mi",null,"y"),s("mo",null,"−"),s("mo",{stretchy:"false"},"("),s("mi",null,"w"),s("mi",null,"x"),s("mo",null,"+"),s("mi",null,"b"),s("mo",{stretchy:"false"},")"),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"loss = norm(y-(wx+b))^2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal"},"oss"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])])],-1),O=s("p",null,"loss 对 theta 求导：",-1),D=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{rowspacing:"0.16em",columnspacing:"1em"},[s("mtr",null,[s("mtd",{class:"mtr-glue"}),s("mtd",null,[s("mstyle",{scriptlevel:"0",displaystyle:"true"},[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mtext",null,"loss")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"θ")])]),s("mo",null,"="),s("mn",null,"2"),s("mo",null,"∑"),s("mo",{stretchy:"false"},"["),s("mi",null,"y"),s("mo",null,"−"),s("msub",null,[s("mi",null,"f"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},"]"),s("mrow",null,[s("mo",{fence:"true"},"("),s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("msub",null,[s("mi",null,"f"),s("mi",null,"θ")]),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"θ")])]),s("mo",{fence:"true"},")")])])])]),s("mtd",{class:"mtr-glue"}),s("mtd",{class:"mml-eqn-num"})])]),s("annotation",{encoding:"application/x-tex"}," \\begin{equation} \\frac{\\partial \\text{loss}}{\\partial \\theta} = 2\\sum [y - f_\\theta(x)] \\left( \\frac{\\partial f_\\theta(x)}{\\partial \\theta} \\right) \\end{equation} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.4em","vertical-align":"-0.95em"}}),s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.45em"}},[s("span",{style:{top:"-3.45em"}},[s("span",{class:"pstrut",style:{height:"3.45em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord text"},[s("span",{class:"mord"},"loss")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord"},"2"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-symbol large-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1076em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")]"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size3"},"(")]),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.427em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1076em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"θ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size3"},")")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.95em"}},[s("span")])])])])])]),s("span",{class:"tag"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.45em"}},[s("span",{style:{top:"-3.45em"}},[s("span",{class:"pstrut",style:{height:"3.45em"}}),s("span",{class:"eqn-num"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.95em"}},[s("span")])])])])])])])],-1),N=a(`<p>使用 pytorch 自动求导与 mse 的使用</p><ul><li>F.mse_loss(prod,label)</li><li>torch.autograd.grad(prod,[w1,w2...]) 返回 list[w1 grad,w2 grad....]</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 简单线性模型 prod = xw + b = 1 * 2 + 0</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
w <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">2.</span><span class="token punctuation">)</span> <span class="token comment"># dim = 1, val = 2, b = 0</span>
<span class="token comment"># 此时没有设置那个变量需要 grad 信息，需重新设置</span>
mse <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token operator">*</span>w<span class="token punctuation">)</span> <span class="token comment"># 第一个参数 prod 的值，第二个参数 label 的值（此处相反）</span>
w<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 设置 w 有梯度信息（它作为变量）</span>
mse <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token operator">*</span>w<span class="token punctuation">)</span> <span class="token comment"># 重新设置图信息</span>
torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>mse<span class="token punctuation">,</span><span class="token punctuation">[</span>w<span class="token punctuation">]</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>loss.back() 执行完后 w1，w2.. 附带 grad 属性，并清除梯度信息</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
w <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
mse <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token operator">*</span>w<span class="token punctuation">)</span>
w<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span>
mse <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token operator">*</span>w<span class="token punctuation">)</span>
mse<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
w<span class="token punctuation">.</span>grad <span class="token comment"># tensor[2.]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="softmax" tabindex="-1"><a class="header-anchor" href="#softmax" aria-hidden="true">#</a> softmax</h4><p>softmax 是一个激活函数，用于将不同的输入数压缩称总和为 1 的概率数</p><p>![image-20240706152006704](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240706152006704.png)</p><p>softmax 的梯度/导数结论：</p><p>![image-20240706155454356](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240706155454356.png)</p><p>softmax 在 pytorch 中的使用</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span>
p <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 自动建图</span>
torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span>a<span class="token punctuation">]</span><span class="token punctuation">,</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span>a<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="感知机的梯度推导" tabindex="-1"><a class="header-anchor" href="#感知机的梯度推导" aria-hidden="true">#</a> 感知机的梯度推导</h3><h4 id="单层单输出感知机模型" tabindex="-1"><a class="header-anchor" href="#单层单输出感知机模型" aria-hidden="true">#</a> 单层单输出感知机模型</h4>`,14),R=s("ul",null,[s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mi",null,"X"),s("mi",null,"W"),s("mo",null,"+"),s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"},"y = XW + b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])])]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"y"),s("mo",null,"="),s("mo",null,"∑"),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mo",null,"∗"),s("msub",null,[s("mi",null,"w"),s("mi",null,"i")]),s("mo",null,"+"),s("mi",null,"b")]),s("annotation",{encoding:"application/x-tex"},"y = \\sum x_i * w_i + b")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop op-symbol small-op",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"∗"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"b")])])])])],-1),B=s("p",null,"![image-20240706170053299](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240706170053299.png)",-1),U=s("ul",null,[s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"x"),s("mi",null,"j"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"x_j^i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2194em","vertical-align":"-0.3948em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8247em"}},[s("span",{style:{top:"-2.4413em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3948em"}},[s("span")])])])])])])])]),n(" 表示神经网络第 i 层第 j 个结点（神经网络第 0 层为输入层），经过激活函数的 O 同理")]),s("li",null,[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")]),s("mi",null,"l")])]),s("annotation",{encoding:"application/x-tex"},"w_{ij}^l")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2439em","vertical-align":"-0.3948em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8491em"}},[s("span",{style:{top:"-2.4413em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3948em"}},[s("span")])])])])])])])]),n(" l 表示第 l 层，i 对应上一层的 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"x"),s("mi",null,"i"),s("mrow",null,[s("mi",null,"l"),s("mo",null,"−"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"},"x_i^{l-1}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1661em","vertical-align":"-0.2769em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8892em"}},[s("span",{style:{top:"-2.4231em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])]),s("span",{style:{top:"-3.1031em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2769em"}},[s("span")])])])])])])])]),n(" 结点，j 对应下一层的 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"x"),s("mi",null,"j"),s("mi",null,"l")])]),s("annotation",{encoding:"application/x-tex"},"x_j^{l}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2439em","vertical-align":"-0.3948em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8491em"}},[s("span",{style:{top:"-2.4413em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.01968em"}},"l")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3948em"}},[s("span")])])])])])])])]),n(" 结点")]),s("li",null,[n("t 表示 target，E 表示做 loss "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mo",{stretchy:"false"},"("),s("mi",null,"O"),s("mo",null,"−"),s("mi",null,"t"),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"},"(O - t)^2")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])])],-1),C=s("p",null,"![image-20240706170840460](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240706170840460.png)",-1),V=s("p",null,[n("loss 对 w"),s("sub",null,"j0"),n(" 求导")],-1),G=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"E")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"j"),s("mn",null,"0")])])])]),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"O"),s("mn",null,"0")]),s("mo",null,"−"),s("mi",null,"t"),s("mo",{stretchy:"false"},")"),s("msub",null,[s("mi",null,"O"),s("mn",null,"0")]),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("msub",null,[s("mi",null,"O"),s("mn",null,"0")]),s("mo",{stretchy:"false"},")"),s("msubsup",null,[s("mi",null,"x"),s("mi",null,"j"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"}," \\frac{\\partial E}{\\partial w_{j0}} = (O_0 - t)O_0(1-O_0)x^0_j ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.3435em","vertical-align":"-0.9721em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j"),s("span",{class:"mord mtight"},"0")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9721em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mclose"},")"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2472em","vertical-align":"-0.3831em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-2.453em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3831em"}},[s("span")])])])])])])])])])],-1),I=a(`<p>![image-20240706172743360](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240706172743360.png)</p><p>在 pytorch 中计算</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
w<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
o<span class="token operator">=</span>torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x@w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
o<span class="token punctuation">.</span>shape
loss<span class="token operator">=</span>F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>o<span class="token punctuation">)</span>
loss<span class="token punctuation">.</span>shape
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
w<span class="token punctuation">.</span>grad
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="单层多输出感知机模型" tabindex="-1"><a class="header-anchor" href="#单层多输出感知机模型" aria-hidden="true">#</a> 单层多输出感知机模型</h4><p>![image-20240706173822410](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240706173822410.png)</p><p>loss 对 w<sub>jk</sub> 求导</p>`,6),X=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mfrac",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("mi",null,"E")]),s("mrow",null,[s("mi",{mathvariant:"normal"},"∂"),s("msub",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"j"),s("mi",null,"k")])])])]),s("mo",null,"="),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"O"),s("mi",null,"k")]),s("mo",null,"−"),s("msub",null,[s("mi",null,"t"),s("mi",null,"k")]),s("mo",{stretchy:"false"},")"),s("msub",null,[s("mi",null,"O"),s("mi",null,"k")]),s("mo",{stretchy:"false"},"("),s("mn",null,"1"),s("mo",null,"−"),s("msub",null,[s("mi",null,"O"),s("mi",null,"k")]),s("mo",{stretchy:"false"},")"),s("msubsup",null,[s("mi",null,"x"),s("mi",null,"j"),s("mn",null,"0")])]),s("annotation",{encoding:"application/x-tex"}," \\frac{\\partial E}{\\partial w_{jk}} = (O_k - t_k)O_k(1-O_k)x^0_j ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.3435em","vertical-align":"-0.9721em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0269em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"jk")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord",style:{"margin-right":"0.05556em"}},"∂"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9721em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"t"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2472em","vertical-align":"-0.3831em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-2.453em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"0")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3831em"}},[s("span")])])])])])])])])])],-1),Y=a(`<p>![image-20240706174221996](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240706174221996.png)</p><p>在 pytorch 中计算</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
w<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
o<span class="token operator">=</span>torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x@w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
o<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([1,2])</span>
loss<span class="token operator">=</span>F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>o<span class="token punctuation">)</span> <span class="token comment"># 写成 (1,1) 有 boardcast 机制</span>
loss <span class="token comment">#tensor(0.2443，grad_fn=&lt;MeanBackward1&gt;)</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
w<span class="token punctuation">.</span>grad
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="链式法则" tabindex="-1"><a class="header-anchor" href="#链式法则" aria-hidden="true">#</a> 链式法则</h3><p>链式法则运用于多层感知机模型，输入层经过隐藏层、输出层、计算 loss</p><p>![image-20240707143212125](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240707143212125.png)</p><p>在 Pytoch 中链式法则的应用案例：</p>`,7),W=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,[s("mover",null,[s("mo",null,[s("mo",null,"⟶")]),s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mn",null,"1")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"b"),s("mn",null,"1")])])])]),s("msub",null,[s("mi",null,"y"),s("mn",null,"1")]),s("mo",null,[s("mover",null,[s("mo",null,[s("mo",null,"⟶")]),s("mrow",null,[s("msub",null,[s("mi",null,"w"),s("mn",null,"2")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"b"),s("mn",null,"2")])])])]),s("msub",null,[s("mi",null,"y"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"}," x\\stackrel{w_1,b_1}{\\longrightarrow}y_1\\stackrel{w_2,b_2}{\\longrightarrow}y_2 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.3552em","vertical-align":"-0.011em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},[s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3442em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",null,[s("span",{class:"mop"},"⟶")])]),s("span",{style:{top:"-3.7581em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3173em"}},[s("span",{style:{top:"-2.357em","margin-left":"-0.0269em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])]),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3173em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.011em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.5387em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},[s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3442em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",null,[s("span",{class:"mop"},"⟶")])]),s("span",{style:{top:"-3.7581em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3173em"}},[s("span",{style:{top:"-2.357em","margin-left":"-0.0269em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])]),s("span",{class:"mpunct mtight"},","),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3173em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.011em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])])])],-1),$=a(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">)</span>
w1<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b1<span class="token operator">=</span>torch <span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">)</span>
w2<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b2<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.</span><span class="token punctuation">)</span>

y1<span class="token operator">=</span>x<span class="token operator">*</span>w1<span class="token operator">+</span>b1
y2<span class="token operator">=</span>y1<span class="token operator">*</span>w2<span class="token operator">+</span>b2

dy2_dy1<span class="token operator">=</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>y2<span class="token punctuation">,</span><span class="token punctuation">[</span>y1<span class="token punctuation">]</span><span class="token punctuation">,</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># y2 对 y1 求导</span>
dy1_dw1<span class="token operator">=</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>y1<span class="token punctuation">,</span><span class="token punctuation">[</span>w1<span class="token punctuation">]</span><span class="token punctuation">,</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># y1 对 w1 求导</span>
dy2_dw1<span class="token operator">=</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>y2<span class="token punctuation">,</span><span class="token punctuation">[</span>w1<span class="token punctuation">]</span><span class="token punctuation">,</span>retain_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># y2 对 w1 求导（跳阶）</span>

dy2_dy1<span class="token operator">*</span>dy1_dw1 <span class="token comment"># 手动计算链式法则 tensor(2.)</span>

dy2_dw1 <span class="token comment"># pytorch 自动链式法则 tensor(2.)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="mlp-反向传播" tabindex="-1"><a class="header-anchor" href="#mlp-反向传播" aria-hidden="true">#</a> MLP 反向传播</h3><p>多层多输出感知机 loss 对 w<sub>ij</sub> 求导</p><p>![image-20240707144509431](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240707144509431.png)</p><h3 id="_2d-函数优化实例" tabindex="-1"><a class="header-anchor" href="#_2d-函数优化实例" aria-hidden="true">#</a> 2D 函数优化实例</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">def</span> <span class="token function">himmelblau</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">return</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">-</span> <span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>


x<span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;x,y range:&quot;&#39;</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
X<span class="token punctuation">,</span>Y <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span> <span class="token string">&#39;X,Y maps:&#39;</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
Z <span class="token operator">=</span> himmelblau<span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">]</span><span class="token punctuation">)</span>

fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token string">&#39;himmelblau&#39;</span> <span class="token punctuation">)</span>
ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>gca<span class="token punctuation">(</span>projection<span class="token operator">=</span><span class="token string">&#39;3d&#39;</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>plot_surface<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>Z<span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>view_init<span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">&#39;x&#39;</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">&#39;y&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># [1., 0.]，[-4，0.]，[4, 0.]</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span> <span class="token comment"># 优化器，完成 x1 = x - 0.001△x，y1 = y - 0.001△y</span>
<span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    pred <span class="token operator">=</span> himmelblau<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    pred<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 生成 x，y 的梯度信息</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 更新 x，y</span>
    <span class="token keyword">if</span> step <span class="token operator">%</span> <span class="token number">2000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">&#39;step {}: x = {}, f(x) = {}&#39;</span>
               <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>step<span class="token punctuation">,</span>x<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>pred<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="logistic-regression" tabindex="-1"><a class="header-anchor" href="#logistic-regression" aria-hidden="true">#</a> Logistic Regression</h3><p>多分类问题实战</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>w1<span class="token punctuation">,</span>b1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>，
torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span> <span class="token punctuation">)</span>
w2<span class="token punctuation">,</span>b2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span> <span class="token punctuation">)</span>
w3<span class="token punctuation">,</span>b3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
	x <span class="token operator">=</span> x@w1<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b1
	x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
	x <span class="token operator">=</span> x@w2<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b2
	x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
	x <span class="token operator">=</span> x@w3<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b3
	x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
	<span class="token keyword">return</span> x


optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">[</span>w1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span>w2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> w3<span class="token punctuation">,</span> b3<span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>
criteon <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
		data <span class="token operator">=</span> data<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span>
        
		logits <span class="token operator">=</span> forward<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
		loss <span class="token operator">=</span> criteon<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> target <span class="token punctuation">)</span>
        
		optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
		loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
		<span class="token comment"># print(w1 .grad.norm(), w2.grad.norm())</span>
		optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_5、gpu-加速" tabindex="-1"><a class="header-anchor" href="#_5、gpu-加速" aria-hidden="true">#</a> 5、GPU 加速</h2><p>to(device) 将放到 GPU 中计算</p><p>![image-20240708142344365](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240708142344365.png)</p><h2 id="_6、visdom-可视化" tabindex="-1"><a class="header-anchor" href="#_6、visdom-可视化" aria-hidden="true">#</a> 6、Visdom 可视化</h2><p>安装：<code>pip install visdom</code></p><p>run server：在 cmd 中 <code>python -m visdom.server</code></p><p>使用：建议看其他文档</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> visdom <span class="token keyword">import</span> Visdom
viz <span class="token operator">=</span> Visdom<span class="token punctuation">(</span><span class="token punctuation">)</span>
viz<span class="token punctuation">.</span>line<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>win<span class="token operator">=</span><span class="token string">&#39;train_loss&#39;</span><span class="token punctuation">,</span>opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">&#39;train loss&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
viz<span class="token punctuation">.</span>line<span class="token punctuation">(</span><span class="token punctuation">[</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span>global_step<span class="token punctuation">]</span><span class="token punctuation">,</span>win<span class="token operator">=</span><span class="token string">&#39;train_loss&#39;</span><span class="token punctuation">,</span>update<span class="token operator">=</span><span class="token string">&#39;append&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_7、过拟合、欠拟合、小技巧" tabindex="-1"><a class="header-anchor" href="#_7、过拟合、欠拟合、小技巧" aria-hidden="true">#</a> 7、过拟合、欠拟合、小技巧</h2><p>overfitting（过拟合） 现象</p><p>![image-20240708153205734](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240708153205734.png)</p><h3 id="检测-overfitting" tabindex="-1"><a class="header-anchor" href="#检测-overfitting" aria-hidden="true">#</a> 检测 overfitting</h3><h4 id="train-val-test-划分" tabindex="-1"><a class="header-anchor" href="#train-val-test-划分" aria-hidden="true">#</a> train-val-test 划分</h4><p>如何检测出现过拟合：将数据划分为训练集和测试集（验证集）</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 数据划分</span>
train_db<span class="token punctuation">,</span>val_db <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>train_db<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">50000</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;db1:&#39;</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>train_db<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&#39;db12:&#39;</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>val_db<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
	train_db<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
val_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>
	val_db<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="k-折交叉验证" tabindex="-1"><a class="header-anchor" href="#k-折交叉验证" aria-hidden="true">#</a> k 折交叉验证</h4><p>将 train 数据集划分为 k 份，每次取一份做 validation，其他 n-1 份做 training，执行 n 次</p><h3 id="防止、减轻-overfitting" tabindex="-1"><a class="header-anchor" href="#防止、减轻-overfitting" aria-hidden="true">#</a> 防止、减轻 overfitting</h3><p>regularization 正规化</p><p>在原来的 loss 上加一个一范数或二范数</p><p>![image-20240708162426917](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240708162426917.png)</p><p>![image-20240708163426406](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240708163426406.png)</p><p>![image-20240708163526410](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240708163526410.png)</p><h3 id="动量、学习率衰减" tabindex="-1"><a class="header-anchor" href="#动量、学习率衰减" aria-hidden="true">#</a> 动量、学习率衰减</h3><p>动量（momentum）即惯性，之前梯度更新的公式为 $w<sup>{k+1}=w</sup>k-\\alpha \\bigtriangledown f(w^k) $，添加动量后，梯度更新的方向增加融合上一次更新的方向，即</p>`,34),A=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"z"),s("mrow",null,[s("mi",null,"k"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"="),s("mi",null,"β"),s("msup",null,[s("mi",null,"z"),s("mi",null,"k")]),s("mo",null,"+"),s("mo",null,"▽"),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("msup",null,[s("mi",null,"w"),s("mi",null,"k")]),s("mo",{stretchy:"false"},")"),s("mspace",{linebreak:"newline"}),s("msup",null,[s("mi",null,"w"),s("mrow",null,[s("mi",null,"k"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"="),s("msup",null,[s("mi",null,"w"),s("mi",null,"k")]),s("mo",null,"−"),s("mi",null,"α"),s("msup",null,[s("mi",null,"z"),s("mrow",null,[s("mi",null,"k"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"}," z^{k+1}=\\beta z^k +\\bigtriangledown f(w^k) \\\\ w^{k+1} = w^k - \\alpha z^{k+1} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8991em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0935em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05278em"}},"β"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1491em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"▽"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mclose"},")")]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8991em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9824em","vertical-align":"-0.0833em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8991em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])])])])])])])])])])],-1),H=a(`<p>pytorch 中动量的使用：添加 momentum，weight_decay 参数</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>lr<span class="token punctuation">,</span>momentum<span class="token operator">=</span>args<span class="token punctuation">.</span>momentum<span class="token punctuation">,</span>weight_decay<span class="token operator">=</span>args<span class="token punctuation">.</span>weight_decay<span class="token punctuation">)</span>

scheduler <span class="token operator">=</span> ReduceLROnPlateau<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> <span class="token string">&#39;min&#39;</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">xrange</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>start_epoch<span class="token punctuation">,</span> args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
	train<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
	result_avg<span class="token punctuation">,</span> loss_val <span class="token operator">=</span> validate<span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>
	scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span>loss_val<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在设置学习率时，可以先设置大学习率，当 loss 变化不大时，调小学习率</p><h3 id="early-stopping、dropout" tabindex="-1"><a class="header-anchor" href="#early-stopping、dropout" aria-hidden="true">#</a> Early Stopping、Dropout</h3><ul><li><p>Early Stopping：当测试集准确度在最大值时，选择此时模型，测试集准确度下降时会有过拟合</p></li><li><p>Dropout：Dropout 可以减少过拟合，在前向传播时，部分有概率设置为 0，降低连接数量</p><p>dropout 在 pytorch 中的使用</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>net_dropped <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
	torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span>，<span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># drop 50% of the neuron</span>
	torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">200</span>，<span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># drop 50% of the neuron</span>
	torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">200</span>，<span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>torch.nn.Dropout(p=droup_prob)</li><li>Tensorflow：tf.nn.dropout(keep_prob)</li></ul><p>在 test 时必须把连接全部用上</p><p>![image-20240709142824096](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240709142824096.png)</p></li></ul><h3 id="数据增强" tabindex="-1"><a class="header-anchor" href="#数据增强" aria-hidden="true">#</a> 数据增强</h3><p>图片数量有限，为增加数据量，可以对原始数据做 flip，rotate，scale，resize，copy part，noise。nn 提供了对应的方法</p><h2 id="_8、卷积神经网络" tabindex="-1"><a class="header-anchor" href="#_8、卷积神经网络" aria-hidden="true">#</a> 8、卷积神经网络</h2>`,8),Q={href:"https://www.bilibili.com/video/BV1R5411w715/?spm_id_from=333.337.search-card.all.click&vd_source=93736dd4ac5c01d75d784e06d15a93ac",target:"_blank",rel:"noopener noreferrer"},Z=a(`<h3 id="使用-pytorch-实现简单二维卷积神经网络" tabindex="-1"><a class="header-anchor" href="#使用-pytorch-实现简单二维卷积神经网络" aria-hidden="true">#</a> 使用 pytorch 实现简单二维卷积神经网络</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># stride 为步长</span>
x<span class="token operator">=</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span>
out<span class="token operator">=</span>layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># torch.size([1,3,26,26])</span>

layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
out<span class="token operator">=</span>layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># torch.size([1,3,28,28])</span>

layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
out<span class="token operator">=</span>layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># torch.Size([1,3,14,14])</span>
out<span class="token operator">=</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># __call__ # torch.size([1,3,14,14])</span>

layer<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([3,1,3,3])</span>
layer<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([3])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>![image-20240709161746603](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240709161746603.png)</p><h3 id="池化层" tabindex="-1"><a class="header-anchor" href="#池化层" aria-hidden="true">#</a> 池化层</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x<span class="token operator">=</span>out <span class="token comment"># torch.Size([1，16，14，14])</span>
layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>MaxPoo12d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
out<span class="token operator">=</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># torch.Size([1，16，7，7])</span>
out<span class="token operator">=</span>F<span class="token punctuation">.</span>avg_poo12d<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># torch.Size([1，16，7，7])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="relu" tabindex="-1"><a class="header-anchor" href="#relu" aria-hidden="true">#</a> ReLU</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>x<span class="token punctuation">.</span>shape <span class="token comment"># torch.size([1，16，7，7])</span>
layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
out<span class="token operator">=</span>layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
out<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1，16，7，7])</span>
out<span class="token operator">=</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
out<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([1，16，7，7])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="batch-norm" tabindex="-1"><a class="header-anchor" href="#batch-norm" aria-hidden="true">#</a> Batch Norm</h3><p>因为 sigmod 函数在输入 -4 到 4 以外的数接近于 0，因此需要将输入的数据缩放在接近于 0 以便快速梯度下降</p>`,9),J={href:"https://www.bilibili.com/video/BV1L2421N7jQ/",target:"_blank",rel:"noopener noreferrer"},K=a(`<p>![image-20240709170855124](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240709170855124.png)</p><h3 id="经典卷积神经网络" tabindex="-1"><a class="header-anchor" href="#经典卷积神经网络" aria-hidden="true">#</a> 经典卷积神经网络</h3><p>LeNet-5：手写数组识别、VGG、GoogleNet，ResNet（重要）</p><h3 id="卷积神经网络实战" tabindex="-1"><a class="header-anchor" href="#卷积神经网络实战" aria-hidden="true">#</a> 卷积神经网络实战</h3><h2 id="_9、nn-module-模块" tabindex="-1"><a class="header-anchor" href="#_9、nn-module-模块" aria-hidden="true">#</a> 9、nn.Module 模块</h2><ul><li><p>nn 模块提供了大量神经网络现成的模块（Linear，ReLU，Sigmoid，Conv2d，ConvTransposed2d，Dropout，etc.），它通常也做为父类</p></li><li><p>Container</p><p>![image-20240710141949725](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710141949725.png)</p></li><li><p>parameters 返回 net 的所有参数</p><p>![image-20240710142300668](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710142300668.png)</p></li><li><p>modules</p><p>可以查看 net 下包含自己的所有 module，孩子 module</p><p>![image-20240710142636431](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710142636431.png)</p><p>![image-20240710142653405](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710142653405.png)</p></li><li><p>to(device)</p><p>将网络结构搬到 GPU 上</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&#39;cuda&#39;</span><span class="token punctuation">)</span>
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>save and load</p><p>用于保存训练时的中间状态</p><p>![image-20240710142913658](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710142913658.png)</p></li><li><p>train / test</p><p>完成所有 module train 状态 test 状态的切换</p><p>![image-20240710143222976](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710143222976.png)</p></li><li><p>implement own layer</p><p>自己实现 tensor 的打平类</p><p>![image-20240710143521116](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710143521116.png)</p></li><li><p>own linear layer</p><p>自定义 linear 类</p><p>![image-20240710143819537](E:\\Study=my repo\\vuepress-hope-bloc\\my-docs\\src\\code\\人工智能\\Pytorch\\assets\\image-20240710143819537.png)</p></li></ul>`,6);function ss(ns,as){const t=l("ExternalLinkIcon");return c(),o("div",null,[u,r,s("ul",null,[m,s("li",null,[s("p",null,[n("查看 Pytoch 安装指令 "),s("a",d,[n("https://pytorch.org/"),p(t)])]),k])]),h,s("ul",null,[g,s("li",null,[n("矩阵相乘 "),s("ul",null,[s("li",null,[s("a",v,[n("torch.mm"),p(t)]),n("(a,b)，该方法只适用于 2d 的 tensor")]),b,y])]),x]),w,f,z,_,M,S,L,T,q,E,P,F,j,O,D,N,R,B,U,C,V,G,I,X,Y,W,$,A,H,s("p",null,[s("a",Q,[n("https://www.bilibili.com/video/BV1R5411w715/?spm_id_from=333.337.search-card.all.click&vd_source=93736dd4ac5c01d75d784e06d15a93ac"),p(t)])]),Z,s("p",null,[s("a",J,[n("https://www.bilibili.com/video/BV1L2421N7jQ/"),p(t)])]),K])}const es=e(i,[["render",ss],["__file","Pytorch.html.vue"]]);export{es as default};
