import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as p,c as m,b as s,f as a,e as l,d as n}from"./app-6225af5c.js";const c={},o=s("h1",{id:"深度学习",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#深度学习","aria-hidden":"true"},"#"),a(" 深度学习")],-1),r=s("h2",{id:"_1、预备知识",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_1、预备知识","aria-hidden":"true"},"#"),a(" 1、预备知识")],-1),u={href:"https://zh.d2l.ai/chapter_preliminaries/index.html",target:"_blank",rel:"noopener noreferrer"},h=s("h3",{id:"基础概念",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#基础概念","aria-hidden":"true"},"#"),a(" 基础概念")],-1),g=s("p",null,"梯度下降、误差、k 折交叉验证、过拟合与欠拟合、损失函数、向前传播、反向传播、计算图、激活函数",-1),d=s("p",null,"权重衰退：",-1),k=s("ul",null,[s("li",null,[a("使用均方范数作为硬性限制，控制模型复杂度，减少过拟合"),s("br"),a(" 通过限制参数值 w 的选择范围来控制模型容量"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",{mathvariant:"normal"},"∣"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"w"),s("mi",{mathvariant:"normal"},"∣"),s("msup",null,[s("mi",{mathvariant:"normal"},"∣"),s("mn",null,"2")]),s("mo",null,"≤"),s("mi",null,"θ")]),s("annotation",{encoding:"application/x-tex"},"||w||^2 \\le \\theta")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0641em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"∣∣"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02691em"}},"w"),s("span",{class:"mord"},"∣"),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8141em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"≤"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"θ")])])]),a(" ，通常不限制 bias，小的 theta 意味着更强的正则项")])],-1),v=n('<p>dropout 丢弃法</p><p>动机：一个好的模型需要对输入数据的扰动鲁棒，减少过拟合</p><ul><li>使用有噪音的数据等价于 Tikhonov 正则</li><li>dropout：在层之间加入噪音，丢弃一部分前一层的输入、后一层的输出</li></ul><p>通常将 dropout 作用在 <strong>隐藏全连接层的输出</strong> 上，将其中的一些值随机设为 <strong>0</strong> 来控制模型复杂度，丢弃概率为 <strong>超参数</strong>，其他数会相应变大，保证均值方差一样</p><p>注意：dropout 用在训练模型上减少复杂性，在使用模型时一般不用 dropout</p><p>数值稳定性</p><p>数值稳定性常见的两个问题：</p><ul><li>梯度爆炸 <ul><li>值超出阈值</li><li>对学习率敏感</li></ul></li><li>梯度消失 <ul><li>梯度值变为 0</li><li>训练无进展</li><li>对于底部层尤为严重</li></ul></li></ul><p>因此，合理的权重初始值和激活函数的选取可以提升数值稳定性</p><h3 id="数据集操作" tabindex="-1"><a class="header-anchor" href="#数据集操作" aria-hidden="true">#</a> 数据集操作</h3><p>数据集可分为</p><ul><li>训练集</li><li>验证集</li><li>测试集</li></ul><h4 id="数据增广" tabindex="-1"><a class="header-anchor" href="#数据增广" aria-hidden="true">#</a> 数据增广</h4><p>数据增强：则国家已有数据集，使得有更多的多样性。如在语音中加入背景噪声、改变图片的颜色和形状（翻转、切割、改颜色）</p><p>数据增广一般使用 torchvision</p><h3 id="硬件、计算性能" tabindex="-1"><a class="header-anchor" href="#硬件、计算性能" aria-hidden="true">#</a> 硬件、计算性能</h3>',16),y={href:"https://zh.d2l.ai/chapter_computational-performance/index.html",target:"_blank",rel:"noopener noreferrer"},b=n(`<h3 id="微调" tabindex="-1"><a class="header-anchor" href="#微调" aria-hidden="true">#</a> 微调</h3><p>使用已训练好的模型的特征提取层与权重，调整自己崔侯的全连接层</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241018164921787.png" alt="image-20241018164921787" loading="lazy"></p><h3 id="困惑度-perplexity" tabindex="-1"><a class="header-anchor" href="#困惑度-perplexity" aria-hidden="true">#</a> 困惑度 perplexity</h3><ul><li><p>衡量一个语言模型的好坏可以用平均交叉熵</p><p>p 是语言模型的预测概率，x是真实词</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241026194955046.png" alt="image-20241026194955046" loading="lazy"></p></li><li><p>历史原因NLP使用困惑度 exp(a)来衡量，是平均每次可能选项。1表示完美，无穷大是最差情况</p></li></ul><h3 id="梯度剪裁" tabindex="-1"><a class="header-anchor" href="#梯度剪裁" aria-hidden="true">#</a> 梯度剪裁</h3><ul><li><p>迭代中计算这 T 个时间步上的梯度，在反向传播过程中产生长度为O(T)的矩阵乘法链，导致数值不稳定</p></li><li><p>梯度裁剪能有效预防梯度爆炸、</p><p>如果梯度长度超过 0，那么拖影回长度0</p></li></ul><h2 id="_2、线性神经网络" tabindex="-1"><a class="header-anchor" href="#_2、线性神经网络" aria-hidden="true">#</a> 2、线性神经网络</h2><blockquote><p>FNN（Feedforward Neural Network，前馈神经网络）：FNN 是一种神经网络架构，它按照层级顺序，将数据从输入层传递到输出层，每一层的节点连接到下一层的节点</p><p>MLP 是一种特定的 FNN，特点是包含至少一个隐藏层，且每一层的神经元是完全连接的</p></blockquote><h3 id="线性回归" tabindex="-1"><a class="header-anchor" href="#线性回归" aria-hidden="true">#</a> 线性回归</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># 生成示例数据</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">4</span> <span class="token operator">+</span> <span class="token number">3</span> <span class="token operator">*</span> X <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># y = 4 + 3 * X + 噪声</span>

<span class="token comment"># 将数据转换为 PyTorch 张量</span>
X_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
y_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 定义线性回归模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegressionModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LinearRegressionModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#（输入维度，输出维度）输入x，输出y</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 实例化模型</span>
model <span class="token operator">=</span> LinearRegressionModel<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 均方误差损失</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token comment"># 随机梯度下降优化器</span>

<span class="token comment"># 训练模型</span>
num_epochs <span class="token operator">=</span> <span class="token number">1000</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 前向传播</span>
    y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X_tensor<span class="token punctuation">)</span>
    
    <span class="token comment"># 计算损失</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y_tensor<span class="token punctuation">)</span>
    
    <span class="token comment"># 反向传播</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span>

<span class="token comment"># 绘制结果</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    predicted <span class="token operator">=</span> model<span class="token punctuation">(</span>X_tensor<span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">&#39;blue&#39;</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;实际数据&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> predicted<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">&#39;red&#39;</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;拟合直线&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">&#39;X&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">&#39;y&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">&#39;线性回归示例&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="softmax-分类" tabindex="-1"><a class="header-anchor" href="#softmax-分类" aria-hidden="true">#</a> Softmax 分类</h3><p>Softmax 是多分类任务，隐藏层为线性层，输出为多个。</p>`,13),f=s("p",null,[a("为了使输出为概率，使用 "),s("strong",null,"softmax"),a(),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"s"),s("mi",null,"i"),s("mi",null,"g"),s("mi",null,"m"),s("mi",null,"a"),s("mo",{stretchy:"false"},"("),s("mi",{mathvariant:"bold"},"z"),s("msub",null,[s("mo",{stretchy:"false"},")"),s("mi",null,"i")]),s("mo",null,"="),s("mfrac",null,[s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"z"),s("mi",null,"i")])]),s("mrow",null,[s("msubsup",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"j"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"K")]),s("msup",null,[s("mi",null,"e"),s("msub",null,[s("mi",null,"z"),s("mi",null,"j")])])])]),s("mspace",{width:"1em"}),s("mtext",null,"for "),s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1"),s("mo",{separator:"true"},","),s("mn",null,"2"),s("mo",{separator:"true"},","),s("mo",null,"…"),s("mo",{separator:"true"},","),s("mi",null,"K")]),s("annotation",{encoding:"application/x-tex"},"sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}} \\quad \\text{for } i = 1, 2, \\ldots, K")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),s("span",{class:"mord mathnormal"},"ma"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathbf"},"z"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.6629em","vertical-align":"-0.7519em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.911em"}},[s("span",{style:{top:"-2.5703em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mop mtight"},[s("span",{class:"mop op-symbol small-op mtight",style:{position:"relative",top:"0em"}},"∑"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8852em"}},[s("span",{style:{top:"-2.1786em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-2.8971em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"K")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4603em"}},[s("span")])])])])]),s("span",{class:"mspace mtight",style:{"margin-right":"0.1952em"}}),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.779em"}},[s("span",{style:{top:"-2.9714em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3448em"}},[s("span",{style:{top:"-2.3448em","margin-left":"-0.044em","margin-right":"0.1em"}},[s("span",{class:"pstrut",style:{height:"2.6595em"}}),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.5092em"}},[s("span")])])])])])])])])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7385em"}},[s("span",{style:{top:"-2.931em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.04398em"}},"z"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3448em"}},[s("span",{style:{top:"-2.3448em","margin-left":"-0.044em","margin-right":"0.1em"}},[s("span",{class:"pstrut",style:{height:"2.6595em"}}),s("span",{class:"mord mathnormal mtight"},"i")])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3147em"}},[s("span")])])])])])])])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7519em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"1em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"for ")]),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"2"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},"…"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K")])])]),a(" 函数，通过真实值与预测值的概率经过 "),s("strong",null,"交叉熵损失"),a(" 得到 0,1 值")],-1),x=n(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 1. 数据准备：下载MNIST数据集，并进行预处理</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

train_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./data&#39;</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># 2. 定义模型：一个简单的两层神经网络</span>
<span class="token keyword">class</span> <span class="token class-name">SimpleNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SimpleNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>  <span class="token comment"># 输入层 (28*28像素)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>     <span class="token comment"># 输出层 (10类)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span>            <span class="token comment"># 将输入展平</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token comment"># 第一个全连接层和ReLU激活函数</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                  <span class="token comment"># 第二个全连接层</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment"># 使用softmax函数生成概率分布</span>

<span class="token comment"># 3. 初始化模型、损失函数和优化器</span>
model <span class="token operator">=</span> SimpleNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 交叉熵损失函数 (softmax和损失结合)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 4. 训练模型</span>
num_epochs <span class="token operator">=</span> <span class="token number">5</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>          <span class="token comment"># 前向传播</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token comment"># 计算损失</span>

        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment"># 梯度清零</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                  <span class="token comment"># 反向传播</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment"># 更新模型参数</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Epoch [</span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>num_epochs<span class="token punctuation">}</span></span><span class="token string">], Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span>

<span class="token comment"># 5. 测试模型</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
correct <span class="token operator">=</span> <span class="token number">0</span>
total <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> predicted <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>data<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 预测最大概率的类</span>
        total <span class="token operator">+=</span> labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        correct <span class="token operator">+=</span> <span class="token punctuation">(</span>predicted <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Accuracy of the model on the 10000 test images: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token number">100</span> <span class="token operator">*</span> correct <span class="token operator">/</span> total<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">%&#39;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="多层感知机-mlp" tabindex="-1"><a class="header-anchor" href="#多层感知机-mlp" aria-hidden="true">#</a> 多层感知机 MLP</h3><p>感知机为二分类。给定输入 x，权重 w，偏移 b，感知机输出 0 或 1（有时为 -1 或 1）。它不能拟合 XOR 函数</p><p>多层感知机（MLP）的简单例子：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim

<span class="token comment"># 定义MLP模型</span>
<span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 定义第一层全连接层</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
        <span class="token comment"># 激活函数ReLU</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 定义第二层全连接层</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 第一层 + 激活函数</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token comment"># 输出层</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

<span class="token comment"># 模型实例化</span>
input_size <span class="token operator">=</span> <span class="token number">10</span>   <span class="token comment"># 输入特征数</span>
hidden_size <span class="token operator">=</span> <span class="token number">20</span>  <span class="token comment"># 隐藏层神经元数</span>
output_size <span class="token operator">=</span> <span class="token number">3</span>   <span class="token comment"># 输出类别数</span>

model <span class="token operator">=</span> MLP<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>

<span class="token comment"># 损失函数和优化器</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>

<span class="token comment"># 假设我们有一个大小为10的输入张量</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>  <span class="token comment"># 批次大小为5</span>
labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 随机生成5个类别标签</span>

<span class="token comment"># 前向传播</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment"># 计算损失</span>
loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

<span class="token comment"># 反向传播和优化</span>
optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 梯度清零</span>
loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 反向传播</span>
optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># 更新参数</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&#39;Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3、卷积神经网络-cnn" tabindex="-1"><a class="header-anchor" href="#_3、卷积神经网络-cnn" aria-hidden="true">#</a> 3、卷积神经网络 CNN</h2><h3 id="多输入输出通道" tabindex="-1"><a class="header-anchor" href="#多输入输出通道" aria-hidden="true">#</a> 多输入输出通道</h3><p>彩色图片由 RGB 三个通道，每个输入通道通常有独立的二维卷积核</p><p>可以使用多个三维卷积核（下图核函数粘贴复制），每个核生成一个输出通道</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241018160507227.png" alt="image-20241018160507227" loading="lazy"></p><ul><li>计算的结果为 <strong>特征图</strong></li><li>一次卷积可以有多个 Filter，卷积后的深度就为 Filter 的个数（上述 7*7*3 经过 2 个 3*3*3 的 filter 变为 3*3*2 的特征图）</li></ul><p>1 * 1 的卷积核不识别空间模式，只是融合通道，以 <strong>c<sub>i</sub> 个输入</strong> 值转换为 <strong>c<sub>o</sub> 个输出值</strong></p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241018160829623.png" alt="image-20241018160829623" loading="lazy"></p><h3 id="卷积层-conv-convolution" tabindex="-1"><a class="header-anchor" href="#卷积层-conv-convolution" aria-hidden="true">#</a> 卷积层 conv（convolution）</h3><p>卷积层中的 w 是卷积核，b 是偏置，w、b 是可学习参数</p><ul><li>卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出</li><li>核矩阵和偏移是可学习的参数</li></ul><p><strong>卷积层</strong> 涉及 <strong>超参数</strong>：</p><ul><li>滑动窗口步长</li><li>卷积核尺寸</li><li>是否边缘填充</li><li>卷积核个数</li></ul><p>卷积层的权重（w + b）参数：所有卷积核的像素数 + 卷积核个数（偏置）</p><p>感受野（Receptive Field）：神经元「看到的」输入区域，在卷积神经网络中，feature map 上某个元素的计算受输入图像上某个区域的影响，这个区域即该元素的感受野</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20240821222130729-1731830179875-1.png" alt="image-20240821222130729" loading="lazy"></p><p>卷积结果计算公式：</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20240822133826745-1731830179875-2.png" alt="image-20240822133826745" loading="lazy"></p><p>可以对一次卷积后的特征图再卷积再卷积</p><h3 id="池化层-pool" tabindex="-1"><a class="header-anchor" href="#池化层-pool" aria-hidden="true">#</a> 池化层 pool</h3><p>用于 <strong>压缩特征图</strong></p><p>例如： MAX POOLING 最大池化层： 2*2 的特征为一组，筛选最大的值。平均池化层，将最大操作替换为平均</p><ul><li>池化层与卷积层类似，都具有填充和步幅</li><li>池化层没有可学习的参数</li><li>在每个输入通道应用池化层以获得相应的输出通道</li><li>输出通道数 = 输入通道数</li></ul><h3 id="全连接层-fc" tabindex="-1"><a class="header-anchor" href="#全连接层-fc" aria-hidden="true">#</a> 全连接层 fc</h3><p>通过前面 conv 和 pool 得到最后的特征图（假设为 32*32*10），任务为 n 分类任务</p><p>将特征图拉成特征向量 [1,32*32*10] ，则全连接层参数为 [32*32*10,n]</p><h2 id="_4、经典卷积神经网络" tabindex="-1"><a class="header-anchor" href="#_4、经典卷积神经网络" aria-hidden="true">#</a> 4、经典卷积神经网络</h2><h3 id="lenet-1980s" tabindex="-1"><a class="header-anchor" href="#lenet-1980s" aria-hidden="true">#</a> LeNet （1980s）</h3><p>卷积、全连接</p><h3 id="alexnet-2012-年" tabindex="-1"><a class="header-anchor" href="#alexnet-2012-年" aria-hidden="true">#</a> AlexNet（2012 年）</h3><p>更大卷积，全连接</p><h3 id="vgg-2014-年" tabindex="-1"><a class="header-anchor" href="#vgg-2014-年" aria-hidden="true">#</a> Vgg（2014 年）</h3><p>提出 vgg 块，更大更深的 AlexNet，赋值粘贴 AlexNet</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241012111726737.png" alt="image-20241012111726737" loading="lazy"></p><h3 id="nin" tabindex="-1"><a class="header-anchor" href="#nin" aria-hidden="true">#</a> NiN</h3><p>提出 NiN 块，一个卷积层后跟两个全连接层（1*1 的卷积核）</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241012111744823.png" alt="image-20241012111744823" loading="lazy"></p><h3 id="googlenet" tabindex="-1"><a class="header-anchor" href="#googlenet" aria-hidden="true">#</a> GoogLeNet</h3><p>提出 Inception 块</p><h3 id="resnet-2015年" tabindex="-1"><a class="header-anchor" href="#resnet-2015年" aria-hidden="true">#</a> Resnet（2015年）</h3><p>vgg 在层数更多时，训练效果反而不好</p><p>resnet 将 <strong>好的层保留，不好的层跳过</strong>。做法是通过对层数堆叠的值与同等映射的值进行比较</p><ul><li><p>若果层数堆叠的值不好，将层数堆叠权重设为 0</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20240822141714082-1731830328749-5.png" alt="image-20240822141714082" loading="lazy"></p></li></ul><h3 id="densenet" tabindex="-1"><a class="header-anchor" href="#densenet" aria-hidden="true">#</a> DenseNet</h3><h2 id="_5、批量归一化层" tabindex="-1"><a class="header-anchor" href="#_5、批量归一化层" aria-hidden="true">#</a> 5、批量归一化层</h2><ul><li>损失在最后，后面的层训练比较快，前面的层训练比较慢。</li><li>前面的层一变化，所有层都得跟这边，最后的那些层需要重新学习多次，导致收敛边慢</li></ul>`,51),z=s("blockquote",null,[s("p",null,[a("归一化（Normalization）：将数据缩放到一个特定范围（通常是 [0, 1] 或 [-1, 1]）"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mtext",null,"normalized")]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"−"),s("msub",null,[s("mi",null,"x"),s("mi",null,"min"),s("mo",null,"⁡")])]),s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"max"),s("mo",null,"⁡")]),s("mo",null,"−"),s("msub",null,[s("mi",null,"x"),s("mi",null,"min"),s("mo",null,"⁡")])])])]),s("annotation",{encoding:"application/x-tex"},"x_{\\text{normalized}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"normalized")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2635em","vertical-align":"-0.4451em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8184em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1645em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mop mtight"},[s("span",{class:"mtight"},"m"),s("span",{class:"mtight"},"a"),s("span",{class:"mtight"},"x")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])]),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.334em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mop mtight"},[s("span",{class:"mtight"},"m"),s("span",{class:"mtight"},"i"),s("span",{class:"mtight"},"n")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.4101em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.334em"}},[s("span",{style:{top:"-2.357em","margin-left":"0em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mop mtight"},[s("span",{class:"mtight"},"m"),s("span",{class:"mtight"},"i"),s("span",{class:"mtight"},"n")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.143em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4451em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])]),s("p",null,[a("标准化（Standardization）：将数据转化为均值为 0，标准差为 1 的标准正态分布。"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mtext",null,"standardized")]),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("mi",null,"x"),s("mo",null,"−"),s("mi",null,"μ")]),s("mi",null,"σ")])]),s("annotation",{encoding:"application/x-tex"},"x_{\\text{standardized}} = \\frac{x - \\mu}{\\sigma}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord text mtight"},[s("span",{class:"mord mtight"},"standardized")])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1994em","vertical-align":"-0.345em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8544em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"σ")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.4461em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"x"),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"μ")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.345em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])]),s("hr"),s("p",null,[s("strong",null,"主要区别")]),s("table",null,[s("thead",null,[s("tr",null,[s("th",null,[s("strong",null,"特性")]),s("th",null,[s("strong",null,"归一化")]),s("th",null,[s("strong",null,"标准化")])])]),s("tbody",null,[s("tr",null,[s("td",null,[s("strong",null,"方法")]),s("td",null,"按最大值和最小值缩放"),s("td",null,"按均值和标准差缩放")]),s("tr",null,[s("td",null,[s("strong",null,"输出范围")]),s("td",null,"[0, 1] 或 [-1, 1]"),s("td",null,"平均值 0，标准差 1")]),s("tr",null,[s("td",null,[s("strong",null,"适用场景")]),s("td",null,"特征范围有界，非正态分布的情况"),s("td",null,"特征服从正态分布或算法对正态分布敏感")]),s("tr",null,[s("td",null,[s("strong",null,"对异常值的敏感性")]),s("td",null,"对异常值敏感"),s("td",null,"相对较稳健")])])])],-1),w=n('<p>方法：</p><ul><li><p>固定 <strong>小批量 batch</strong> 里的均值和方差，然后再做额外调整</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241016182432423.png" alt="image-20241016182432423" loading="lazy"></p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241016182512399.png" alt="image-20241016182512399" loading="lazy"></p><ul><li>批量归一化层可学习的参数为 γ 和 β</li><li>作用在 <ul><li>全连接层和卷积层输出上，激活函数前</li><li>全连接层和卷积层输入上</li></ul></li><li>对全连接层，作用在特征维</li><li>对于卷积层，作用在通道维</li></ul></li></ul><h2 id="_6、循环神经网络-rnn" tabindex="-1"><a class="header-anchor" href="#_6、循环神经网络-rnn" aria-hidden="true">#</a> 6、循环神经网络 RNN</h2>',3),_={href:"https://www.bilibili.com/video/BV1z5411f7Bm/",target:"_blank",rel:"noopener noreferrer"},X=n('<p>在时间序列上，隐藏层与隐藏层之间包含关系 W<sub>i</sub></p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241117162806199.png" alt="image-20241117162806199" loading="lazy"></p><p>RNN 在计算梯度时容易发生梯度爆炸‘</p><p>解决梯度爆炸的方法：</p><ul><li>梯度裁剪：梯度裁剪通过设定一个阈值来限制梯度的大小。如果梯度超过这个阈值，它们将被缩放至阈值以内，从而避免了大的权重更新。这样做有助于稳定训练过程</li></ul><h2 id="_7、经典循环神经网络" tabindex="-1"><a class="header-anchor" href="#_7、经典循环神经网络" aria-hidden="true">#</a> 7、经典循环神经网络</h2><h3 id="rgn" tabindex="-1"><a class="header-anchor" href="#rgn" aria-hidden="true">#</a> RGN</h3><h3 id="lstm" tabindex="-1"><a class="header-anchor" href="#lstm" aria-hidden="true">#</a> LSTM</h3><p>相较于 RNN，添加控制参数 c，决定什么样的信息会被保留，什么样的会被遗忘</p>',9),L={href:"https://www.bilibili.com/video/BV1Z34y1k7mc",target:"_blank",rel:"noopener noreferrer"},M=n('<h3 id="深度循环神经网络" tabindex="-1"><a class="header-anchor" href="#深度循环神经网络" aria-hidden="true">#</a> 深度循环神经网络</h3><h3 id="双向循环神经网络" tabindex="-1"><a class="header-anchor" href="#双向循环神经网络" aria-hidden="true">#</a> 双向循环神经网络</h3><h3 id="编码器-解码器架构" tabindex="-1"><a class="header-anchor" href="#编码器-解码器架构" aria-hidden="true">#</a> 编码器-解码器架构</h3><p>编码器、解码器架构：一个模型被分为两块：</p><ul><li>编码器 Encoder 处理输出（类似 CNN 提取特征）</li><li>解码器 Decoder 生成输出（类型 fc 进行预测）</li></ul><p>机器翻译是序列转换模型的一个核心问题， 其输入和输出都是长度可变的序列。 为了处理这种类型的输入和输出， 我们可以设计一个包含两个主要组件的架构：</p><ul><li>第一个组件是一个<em>编码器</em>（encoder）： 它接受一个长度可变的序列作为输入， 并将其转换为具有固定形状的编码状态。</li><li>第二个组件是<em>解码器</em>（decoder）： 它将固定形状的编码状态映射到长度可变的序列。 这被称为<em>编码器-解码器</em>（encoder-decoder）架构</li></ul><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241117171521366.png" alt="image-20241117171521366" loading="lazy"></p><ul><li>“编码器－解码器”架构可以将长度可变的序列作为输入和输出，因此适用于机器翻译等序列转换问题。</li><li>编码器将长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。</li><li>解码器将具有固定形状的编码状态映射为长度可变的序列。</li></ul><h3 id="seq2seq" tabindex="-1"><a class="header-anchor" href="#seq2seq" aria-hidden="true">#</a> seq2seq</h3><ul><li>根据“编码器-解码器”架构的设计， 我们可以使用两个循环神经网络来设计一个序列到序列学习的模型。</li><li>在实现编码器和解码器时，我们可以使用多层循环神经网络。</li><li>我们可以使用遮蔽来过滤不相关的计算，例如在计算损失时。</li><li>在“编码器－解码器”训练中，强制教学方法将原始输出序列（而非预测结果）输入解码器。</li><li>BLEU是一种常用的评估方法，它通过测量预测序列和标签序列之间的 n 元语法的匹配度来评估预测。</li></ul><h2 id="_8、注意力机制" tabindex="-1"><a class="header-anchor" href="#_8、注意力机制" aria-hidden="true">#</a> 8、注意力机制</h2><h3 id="注意力机制" tabindex="-1"><a class="header-anchor" href="#注意力机制" aria-hidden="true">#</a> 注意力机制</h3><ul><li>卷积、全连接、池化都只考虑「不随意线索」</li><li>注意力机制则显示的考虑随意线索 <ul><li>注意力 attention 即权重</li></ul></li></ul><p>非参注意力池化层</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241116142811717.png" alt="image-20241116142811717" loading="lazy"></p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241116143146048.png" alt="image-20241116143146048" loading="lazy"></p><h4 id="注意力分数" tabindex="-1"><a class="header-anchor" href="#注意力分数" aria-hidden="true">#</a> 注意力分数</h4><ul><li>注意力分时是 query 和 key 的相似度，注意力权重是分时的 sofrmax 结果</li><li>两种常见的分数计算： <ul><li>将 query 和 key 合并起来进入一个单输出单隐藏层的 MLP</li><li>直接将 query 和 key 做内积</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241116144152145.png" alt="image-20241116144152145" loading="lazy"></p><h3 id="自注意力机制-slef-attention" tabindex="-1"><a class="header-anchor" href="#自注意力机制-slef-attention" aria-hidden="true">#</a> 自注意力机制 slef-attention</h3>',21),N=s("ul",null,[s("li",null,[a("给定序列 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mn",null,"1")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"x"),s("mn",null,"2")]),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("msub",null,[s("mi",null,"x"),s("mi",null,"n")])]),s("annotation",{encoding:"application/x-tex"},"x_1,x_2,...x_n")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" ，"),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"x_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 为 向量")]),s("li",null,[a("自注意力机制池化层将 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"x"),s("mi",null,"i")])]),s("annotation",{encoding:"application/x-tex"},"x_i")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.5806em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a(" 当做 key，value，query 来对序列抽取特征得到 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"y"),s("mn",null,"1")]),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("msub",null,[s("mi",null,"y"),s("mi",null,"n")])]),s("annotation",{encoding:"application/x-tex"},"y_1,...y_n")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])])])]),a("，这里 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"y"),s("mi",null,"i")]),s("mo",null,"="),s("mi",null,"f"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"i")]),s("mo",{separator:"true"},","),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"x"),s("mn",null,"1")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"x"),s("mn",null,"1")]),s("mo",{stretchy:"false"},")"),s("mo",{separator:"true"},","),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mo",{separator:"true"},","),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"x"),s("mi",null,"n")]),s("mo",{separator:"true"},","),s("msub",null,[s("mi",null,"x"),s("mi",null,"n")]),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"},"y_i = f(x_i,(x_1,x_1),...,(x_n,x_n))")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"i")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},"))")])])])]),s("li",null,"self 即 key，value，query 都是自己取的"),s("li",null,"完全并行、最长序列为 1、但对长序列计算复杂度高"),s("li",null,"位置编码在输入中加入位置信息，使得自注意能够记忆位置信息")],-1),T=n('<h2 id="_9、transformer" tabindex="-1"><a class="header-anchor" href="#_9、transformer" aria-hidden="true">#</a> 9、Transformer</h2><p>LSTM 的训练是迭代的、串行的，必须要等当前字处理完，才可以处理下一个字</p><p><strong>Transformer</strong> 的训练时并行的，即所有字是同时训练的，这样大大增加了计算效率<br><strong>Transformer</strong> 使用了位置嵌入(Positional Encoding)来理解语言的顺序，使用自注意力机制（Self Attention Mechanism）和全连接层进行计算</p><p>Transformer **Encoder **负责把输入（语言序列）隐射成 <strong>隐藏层</strong>（下图中第2步用九宫格代表的部分），然后解码器 <strong>Decoder</strong> 再把隐藏层映射为自然语言序列。例如下图机器翻译的例子</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241120101441309.png" alt="image-20241120101441309" loading="lazy"></p><p><strong>Encoder</strong> Block 结构图：</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119170408502.png" alt="image-20241119170408502" loading="lazy"></p><h3 id="_1-positional-encoding" tabindex="-1"><a class="header-anchor" href="#_1-positional-encoding" aria-hidden="true">#</a> 1. Positional Encoding</h3><p>Transformer <strong>没有</strong> RNN 的迭代操作（在时间上递归）<br> 所以我们必须提供每个字的 <strong>位置信息</strong> 给 Transformer，这样它才能识别出语言中的顺序关系</p><h3 id="_2、自注意力机制-self-attention-mechanism" tabindex="-1"><a class="header-anchor" href="#_2、自注意力机制-self-attention-mechanism" aria-hidden="true">#</a> 2、自注意力机制 Self Attention Mechanism</h3><p>对于输入的句子 <strong>X</strong>：</p><ul><li>通过 WordEmbedding 得到字的 <strong>字向量</strong></li><li>通过 Positional Encoding 得到字的 <strong>位置向量</strong>，</li><li>两者相加（维度相同，可以直接相加），得到该 <strong>字真正的向量表示</strong>。第 <strong>t</strong> 个字的向量记作 <strong>x<sub>t</sub></strong></li></ul><p>定义三个矩阵（变量 w） <strong>W<sub>Q</sub>，W<sub>k</sub>，W<sub>v</sub></strong>，使用这三个矩阵分别对所有的 <strong>字向量</strong> 进行三次线性变换，得到新的向量 <strong>q<sub>t</sub>， k<sub>t</sub>，v<sub>t</sub></strong></p><ul><li>将所有 q<sub>t</sub> 拼接成一个大矩阵，记作 <strong>查询矩阵 Q</strong></li><li>将所有 k<sub>t</sub> 拼接成一个大矩阵，记作 <strong>键矩阵 K</strong></li><li>将所有 v<sub>t</sub> 拼接成一个大矩阵，记作 <strong>值矩阵 V</strong></li></ul><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119182619002.png" alt="image-20241119182619002" loading="lazy"></p><p>为获得第一个字的 <strong>注意力权重</strong>，需要用第一个字的查询向量 q<sub>1</sub> 乘以 键矩阵 K</p><blockquote><p>注意力权重：衡量输入序列中每个位置对其他位置的重要性。通过这些权重，模型可以动态地关注序列中不同部分的信息，从而更好地处理任务，如机器翻译、文本生成或图像处理</p></blockquote><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119182928754.png" alt="image-20241119182928754" loading="lazy"></p><p>将得到的值经过 softmax，使得它们的和为1 <code>softmax([2, 4, 4]) = [0.0, 0.5, 0.5]</code></p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119183529922.png" alt="image-20241119183529922" loading="lazy"></p><p>有了权重之后，将权重其分别乘以对应字的 <strong>值向量 v<sub>t</sub></strong></p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119183721028.png" alt="image-20241119183721028" loading="lazy"></p><p>将这些 <strong>权重化后的值向量求和</strong>，得到第一个字的输出</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119183743445.png" alt="image-20241119183743445" loading="lazy"></p><p>对其它的输入向量也执行相同的操作，即可得到通过 self-attention 后的所有输出</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119183854798.png" alt="image-20241119183854798" loading="lazy"></p><p>矩阵形式：</p><p><img src="https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241119184531165.png" alt="image-20241119184531165" loading="lazy"></p><h3 id="_3、multi-head-attention-多头注意力" tabindex="-1"><a class="header-anchor" href="#_3、multi-head-attention-多头注意力" aria-hidden="true">#</a> 3、Multi-Head Attention 多头注意力</h3><p>可以定义多组 Q，K，V，让它们分别关注不同的上下文。计算 Q，K，V 的过程还是一样。线性变换的矩阵从一组（W<sup>Q</sup>,W<sup>k</sup>,W<sup>v</sup>）变成了多组（W<sup>Q</sup><sub>0</sub>,W<sup>k</sup><sub>0</sub>,W<sup>v</sup><sub>0</sub>）,（W<sup>Q</sup><sub>1</sub>,W<sup>k</sup><sub>1</sub>,W<sup>v</sup><sub>1</sub>）</p><p>对于输入矩阵 X，每一组Q、K 和 V 都可以得到一个输出矩阵 Z</p><h3 id="_4、残差连接和-layer-normalization" tabindex="-1"><a class="header-anchor" href="#_4、残差连接和-layer-normalization" aria-hidden="true">#</a> 4、残差连接和 Layer Normalization</h3><h4 id="残差连接" tabindex="-1"><a class="header-anchor" href="#残差连接" aria-hidden="true">#</a> 残差连接</h4><p>在上一步得到经过 self-attention 加权输出（Attention(Q,K,V)）后，把他们加起来做残差连接</p>',34),B=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"e"),s("mi",null,"m"),s("mi",null,"b"),s("mi",null,"e"),s("mi",null,"d"),s("mi",null,"d"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"g")])]),s("mo",null,"+"),s("mi",null,"S"),s("mi",null,"e"),s("mi",null,"l"),s("mi",null,"f"),s("mi",null,"A"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n"),s("mo",{stretchy:"false"},"("),s("mi",null,"Q"),s("mo",{separator:"true"},","),s("mi",null,"K"),s("mo",{separator:"true"},","),s("mi",null,"V"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," X_{embedding} + Self Attention(Q,K,V) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"mb"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"dd"),s("span",{class:"mord mathnormal mtight"},"in"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"g")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal"},"tt"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mclose"},")")])])])])],-1),I=s("h4",{id:"layer-normalization",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#layer-normalization","aria-hidden":"true"},"#"),a(" Layer Normalization")],-1),j=s("p",null,"Layer Normalization 的作用是把神经网络中隐藏层归一为标准正态分布，以起到加快训练速度，加速收敛的作用",-1),E=s("p",null,"以矩阵的列(column)为单位求均值",-1),q=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"μ"),s("mi",null,"j")]),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mi",null,"m")]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"m")]),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")])])]),s("annotation",{encoding:"application/x-tex"}," \\mu _j = \\frac{1}{m}\\sum_{i=1}^{m}X_{ij} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7167em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"μ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9291em","vertical-align":"-1.2777em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"m")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"m")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])])])])])],-1),S=s("p",null,"以矩阵的列(column)为单位求方差",-1),V=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"σ"),s("mi",null,"j"),s("mn",null,"2")]),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mi",null,"m")]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"m")]),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")])]),s("mo",null,"−"),s("msub",null,[s("mi",null,"μ"),s("mi",null,"j")]),s("msup",null,[s("mo",{stretchy:"false"},")"),s("mn",null,"2")])]),s("annotation",{encoding:"application/x-tex"}," \\sigma _j^2 = \\frac{1}{m}\\sum_{i=1}^{m}(X_{ij}-\\mu_j)^2 ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.2472em","vertical-align":"-0.3831em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-2.453em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3831em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9291em","vertical-align":"-1.2777em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"m")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"m")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1502em","vertical-align":"-0.2861em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"μ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])])])])],-1),W=s("p",null,"用每一列的每一个元素减去这列的均值，再除以这列的方差，从而得到归一化后的数值，加 $\\xi $ 是为了防止分母为 0",-1),K=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"L"),s("mi",null,"a"),s("mi",null,"y"),s("mi",null,"e"),s("mi",null,"r"),s("mi",null,"N"),s("mi",null,"o"),s("mi",null,"r"),s("mi",null,"m"),s("mo",{stretchy:"false"},"("),s("mi",null,"x"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mfrac",null,[s("mrow",null,[s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")])]),s("mo",null,"−"),s("mi",null,"μ"),s("mi",null,"j")]),s("msqrt",null,[s("mrow",null,[s("msubsup",null,[s("mi",null,"σ"),s("mi",null,"j"),s("mn",null,"2")]),s("mo",null,"+"),s("mi",null,"ξ")])])])]),s("annotation",{encoding:"application/x-tex"}," LayerNorm(x) = \\frac{X_{ij}-\\mu{j}}{\\sqrt{\\sigma_j^2+\\xi}} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"yer"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.0903em","vertical-align":"-1.73em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3603em"}},[s("span",{style:{top:"-2.11em"}},[s("span",{class:"pstrut",style:{height:"3.1765em"}}),s("span",{class:"mord"},[s("span",{class:"mord sqrt"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1765em"}},[s("span",{class:"svg-align",style:{top:"-3.8em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"mord",style:{"padding-left":"1em"}},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7959em"}},[s("span",{style:{top:"-2.4231em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"j")])]),s("span",{style:{top:"-3.0448em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.413em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.04601em"}},"ξ")])]),s("span",{style:{top:"-3.1365em"}},[s("span",{class:"pstrut",style:{height:"3.8em"}}),s("span",{class:"hide-tail",style:{"min-width":"1.02em",height:"1.88em"}},[s("svg",{xmlns:"http://www.w3.org/2000/svg",width:"400em",height:"1.88em",viewBox:"0 0 400000 1944",preserveAspectRatio:"xMinYMin slice"},[s("path",{d:`M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z`})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6635em"}},[s("span")])])])])])]),s("span",{style:{top:"-3.4065em"}},[s("span",{class:"pstrut",style:{height:"3.1765em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.8535em"}},[s("span",{class:"pstrut",style:{height:"3.1765em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal"},"μ"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05724em"}},"j")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.73em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])])])],-1),R=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241120092929178.png",alt:"image-20241120092929178",loading:"lazy"})],-1),Q=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/T4mako/ImageBed/main/image-20241120093056505.png",alt:"image-20241120093056505",loading:"lazy"})],-1),A=s("h3",{id:"_5、transformer-encoder-整体结构",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_5、transformer-encoder-整体结构","aria-hidden":"true"},"#"),a(" 5、Transformer Encoder 整体结构")],-1),P=s("p",null,"用公式把一个 Encoder block 的计算过程整理一下：",-1),F=s("ol",null,[s("li",null,[s("p",null,"字向量与位置编码"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"X"),s("mo",null,"="),s("mi",null,"E"),s("mi",null,"m"),s("mi",null,"b"),s("mi",null,"e"),s("mi",null,"d"),s("mi",null,"d"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"g"),s("mi",null,"L"),s("mi",null,"o"),s("mi",null,"o"),s("mi",null,"k"),s("mi",null,"u"),s("mi",null,"p"),s("mo",{stretchy:"false"},"("),s("mi",null,"X"),s("mo",{stretchy:"false"},")"),s("mo",null,"+"),s("mi",null,"P"),s("mi",null,"o"),s("mi",null,"s"),s("mi",null,"i"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n"),s("mi",null,"E"),s("mi",null,"n"),s("mi",null,"c"),s("mi",null,"o"),s("mi",null,"d"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"g")]),s("annotation",{encoding:"application/x-tex"}," X = Embedding Lookup(X) + Position Encoding ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mord mathnormal"},"mb"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"dd"),s("span",{class:"mord mathnormal"},"in"),s("span",{class:"mord mathnormal"},"gL"),s("span",{class:"mord mathnormal"},"oo"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mord mathnormal"},"u"),s("span",{class:"mord mathnormal"},"p"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8889em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mord mathnormal"},"os"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord mathnormal"},"co"),s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mord mathnormal"},"in"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g")])])])])])]),s("li",null,[s("p",null,"自注意力机制"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"Q"),s("mo",null,"="),s("mi",null,"L"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"a"),s("mi",null,"r"),s("mo",{stretchy:"false"},"("),s("mi",null,"X"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"X"),s("msub",null,[s("mi",null,"W"),s("mi",null,"Q")]),s("mspace",{linebreak:"newline"}),s("mi",null,"K"),s("mo",null,"="),s("mi",null,"L"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"a"),s("mi",null,"r"),s("mo",{stretchy:"false"},"("),s("mi",null,"X"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"X"),s("msub",null,[s("mi",null,"W"),s("mi",null,"K")]),s("mspace",{linebreak:"newline"}),s("mi",null,"V"),s("mo",null,"="),s("mi",null,"L"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"a"),s("mi",null,"r"),s("mo",{stretchy:"false"},"("),s("mi",null,"X"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"X"),s("msub",null,[s("mi",null,"W"),s("mi",null,"V")]),s("mspace",{linebreak:"newline"}),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mo",null,"="),s("mi",null,"S"),s("mi",null,"e"),s("mi",null,"l"),s("mi",null,"f"),s("mi",null,"A"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"n"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," Q = Linear(X) = XW_Q \\\\ K = Linear(X) = XW_K \\\\ V = Linear(X) = XW_V \\\\ X_{attention} = SelfAttentnion(X_{attention}) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8778em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal"},"Q"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"in"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.9694em","vertical-align":"-0.2861em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"Q")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07153em"}},"K"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"in"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.07153em"}},"K")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.22222em"}},"V"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"in"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3283em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.1389em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.22222em"}},"V")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal"},"tt"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"ni"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])])])])]),s("li",null,[s("p",null,"self-attention 残差连接与 Layer Normalization"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mo",null,"="),s("mi",null,"X"),s("mo",null,"+"),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mspace",{linebreak:"newline"}),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mo",null,"="),s("mi",null,"L"),s("mi",null,"a"),s("mi",null,"y"),s("mi",null,"e"),s("mi",null,"r"),s("mi",null,"N"),s("mi",null,"o"),s("mi",null,"r"),s("mi",null,"m"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," X_{attention} = X + X_{attention} \\\\ X_{attention} = LayerNorm(X_{attention}) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7667em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"yer"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])])])])]),s("li",null,[s("p",null,"FeedForward，其实就是两层线性映射并用激活函数激活，比如说 ReLU"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"h"),s("mi",null,"i"),s("mi",null,"d"),s("mi",null,"d"),s("mi",null,"e"),s("mi",null,"n")])]),s("mo",null,"="),s("mi",null,"L"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"a"),s("mi",null,"r"),s("mo",{stretchy:"false"},"("),s("mi",null,"R"),s("mi",null,"e"),s("mi",null,"L"),s("mi",null,"U"),s("mo",{stretchy:"false"},"("),s("mi",null,"L"),s("mi",null,"i"),s("mi",null,"n"),s("mi",null,"e"),s("mi",null,"a"),s("mi",null,"r"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," X_{hidden} = Linear(ReLU(Linear(X_{attention}))) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"hi"),s("span",{class:"mord mathnormal mtight"},"dd"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"in"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"LU"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"in"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")))")])])])])])]),s("li",null,[s("p",null,"FeedForward残差连接与Layer Normalization"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"h"),s("mi",null,"i"),s("mi",null,"d"),s("mi",null,"d"),s("mi",null,"e"),s("mi",null,"n")])]),s("mo",null,"="),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"t"),s("mi",null,"e"),s("mi",null,"n"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"h"),s("mi",null,"i"),s("mi",null,"d"),s("mi",null,"d"),s("mi",null,"e"),s("mi",null,"n")])]),s("mspace",{linebreak:"newline"}),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"h"),s("mi",null,"i"),s("mi",null,"d"),s("mi",null,"d"),s("mi",null,"e"),s("mi",null,"n")])]),s("mo",null,"="),s("mi",null,"L"),s("mi",null,"a"),s("mi",null,"y"),s("mi",null,"e"),s("mi",null,"r"),s("mi",null,"N"),s("mi",null,"o"),s("mi",null,"r"),s("mi",null,"m"),s("mo",{stretchy:"false"},"("),s("msub",null,[s("mi",null,"X"),s("mrow",null,[s("mi",null,"h"),s("mi",null,"i"),s("mi",null,"d"),s("mi",null,"d"),s("mi",null,"e"),s("mi",null,"n")])]),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," X_{hidden} = X_{attention} + X_{hidden} \\\\ X_{hidden} = LayerNorm(X_{hidden}) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"hi"),s("span",{class:"mord mathnormal mtight"},"dd"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"a"),s("span",{class:"mord mathnormal mtight"},"tt"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n"),s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mord mathnormal mtight"},"o"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"hi"),s("span",{class:"mord mathnormal mtight"},"dd"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])])]),s("span",{class:"mspace newline"}),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8333em","vertical-align":"-0.15em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"hi"),s("span",{class:"mord mathnormal mtight"},"dd"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"yer"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"or"),s("span",{class:"mord mathnormal"},"m"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.07847em"}},"X"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0785em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"hi"),s("span",{class:"mord mathnormal mtight"},"dd"),s("span",{class:"mord mathnormal mtight"},"e"),s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose"},")")])])])])])])],-1);function D(U,C){const t=i("ExternalLinkIcon");return p(),m("div",null,[o,r,s("p",null,[s("a",u,[a("https://zh.d2l.ai/chapter_preliminaries/index.html"),l(t)])]),h,g,d,k,v,s("p",null,[s("a",y,[a("https://zh.d2l.ai/chapter_computational-performance/index.html"),l(t)])]),b,f,x,z,w,s("p",null,[s("a",_,[a("https://www.bilibili.com/video/BV1z5411f7Bm/"),l(t)])]),X,s("p",null,[s("a",L,[a("https://www.bilibili.com/video/BV1Z34y1k7mc"),l(t)])]),M,N,T,B,I,j,E,q,S,V,W,K,R,Q,A,P,F])}const H=e(c,[["render",D],["__file","index.html.vue"]]);export{H as default};
