<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.66" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://T4mako.github.io/code/python/Machine%20Learning/Pytorch/5%E3%80%81Pytorch%20%E4%BD%8E%E9%98%B6%20API.html"><meta property="og:site_name" content="T4mako"><meta property="og:title" content="5、Pytorch 低阶 API"><meta property="og:description" content="Pytorch 中 5 个不同的层次结构： 硬件层：Pytorch 支持 CPU、GPU 加入计算资源池 内核层：C++ 实现的内核 低阶 API：Python 实现的操作符，提供了封装 C++ 内核的低级 API 指令，主要包括各种张量操作算子、自动微分、变量管理 中阶 API：Python 实现的模型组件，对低级API进行了函数封装，主要包括各种模型层，损失函数，优化器，数据管道等等 高阶 API：Python 实现的模型接口。Pytorch 没有官方的高阶API。为了便于训练模型，作者仿照 keras 中的模型接口，封装了 pytorch 的高阶模型接口 torchkeras.KerasModel。此外，有一个非常流行的非官方 Pytorch 的高阶 API 库，叫做 pytorch_lightning，作者通过引用和借鉴它的一些能力，设计了一个和 torchkeras.KerasModel 功能类似的高阶模型接口 torchkeras.LightModel，功能更加强大。"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="T4mako"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"5、Pytorch 低阶 API","image":[""],"dateModified":null,"author":[{"@type":"Person","name":"T4mako","url":"https://github.com/T4mako/T4mako.github.io"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Zen+Maru+Gothic:wght@500&display=swap" rel="stylesheet"><link rel="alternate" type="application/rss+xml" href="https://T4mako.github.io/rss.xml" title="T4mako RSS Feed"><title>5、Pytorch 低阶 API | T4mako</title><meta name="description" content="Pytorch 中 5 个不同的层次结构： 硬件层：Pytorch 支持 CPU、GPU 加入计算资源池 内核层：C++ 实现的内核 低阶 API：Python 实现的操作符，提供了封装 C++ 内核的低级 API 指令，主要包括各种张量操作算子、自动微分、变量管理 中阶 API：Python 实现的模型组件，对低级API进行了函数封装，主要包括各种模型层，损失函数，优化器，数据管道等等 高阶 API：Python 实现的模型接口。Pytorch 没有官方的高阶API。为了便于训练模型，作者仿照 keras 中的模型接口，封装了 pytorch 的高阶模型接口 torchkeras.KerasModel。此外，有一个非常流行的非官方 Pytorch 的高阶 API 库，叫做 pytorch_lightning，作者通过引用和借鉴它的一些能力，设计了一个和 torchkeras.KerasModel 功能类似的高阶模型接口 torchkeras.LightModel，功能更加强大。">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-c43249a7.css" as="style"><link rel="stylesheet" href="/assets/style-c43249a7.css">
    <link rel="modulepreload" href="/assets/app-2ac1fdf0.js"><link rel="modulepreload" href="/assets/5、Pytorch 低阶 API.html-384aa62f.js"><link rel="modulepreload" href="/assets/5、Pytorch 低阶 API.html-dbf786fa.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="prefetch" href="/assets/index.html-28de6f14.js" as="script"><link rel="prefetch" href="/assets/index.html-f5f264d6.js" as="script"><link rel="prefetch" href="/assets/index.html-30a1b7c2.js" as="script"><link rel="prefetch" href="/assets/Elasticsearch.html-cdfa620a.js" as="script"><link rel="prefetch" href="/assets/MongoDB.html-26953f36.js" as="script"><link rel="prefetch" href="/assets/MySQL基础.html-142c566d.js" as="script"><link rel="prefetch" href="/assets/Redis.html-00ca8519.js" as="script"><link rel="prefetch" href="/assets/IDEA、Eclipse快捷键.html-15e3dc66.js" as="script"><link rel="prefetch" href="/assets/JDBC.html-8ec2fd12.js" as="script"><link rel="prefetch" href="/assets/JVM.html-fa0d3015.js" as="script"><link rel="prefetch" href="/assets/JVM入门.html-5f1781e4.js" as="script"><link rel="prefetch" href="/assets/JWT.html-7c0fd9d7.js" as="script"><link rel="prefetch" href="/assets/JavaWeb基础.html-af51d1ad.js" as="script"><link rel="prefetch" href="/assets/Maven基础.html-ad80dbfe.js" as="script"><link rel="prefetch" href="/assets/MyBatis.html-1642006c.js" as="script"><link rel="prefetch" href="/assets/MybatisPlus.html-07f9ea4d.js" as="script"><link rel="prefetch" href="/assets/RabbitMQ.html-5aae586f.js" as="script"><link rel="prefetch" href="/assets/Shiro.html-fafd6510.js" as="script"><link rel="prefetch" href="/assets/SpringBoot.html-6d206ed6.js" as="script"><link rel="prefetch" href="/assets/SpringBoot常用注解总结.html-c19e968e.js" as="script"><link rel="prefetch" href="/assets/SpringBoot自动装配原理.html-83356abe.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础.html-081659a3.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础2024.html-5c5733dc.js" as="script"><link rel="prefetch" href="/assets/SpringMVC.html-20c731bf.js" as="script"><link rel="prefetch" href="/assets/Spring基础.html-7fdff257.js" as="script"><link rel="prefetch" href="/assets/index.html-8b1856b4.js" as="script"><link rel="prefetch" href="/assets/Matplotlib.html-d2aba437.js" as="script"><link rel="prefetch" href="/assets/Numpy.html-ffba3c01.js" as="script"><link rel="prefetch" href="/assets/Pandas.html-febe9de7.js" as="script"><link rel="prefetch" href="/assets/python 基础语法.html-d33402d6.js" as="script"><link rel="prefetch" href="/assets/python 项目注意事项.html-f13637d7.js" as="script"><link rel="prefetch" href="/assets/Ajax.html-73e0d2ee.js" as="script"><link rel="prefetch" href="/assets/Axios.html-6a0f7031.js" as="script"><link rel="prefetch" href="/assets/CSS3.html-fbf9bd49.js" as="script"><link rel="prefetch" href="/assets/HTML.html-dba9796c.js" as="script"><link rel="prefetch" href="/assets/Node.js笔记.html-edd6db0d.js" as="script"><link rel="prefetch" href="/assets/Promise.html-83aba73d.js" as="script"><link rel="prefetch" href="/assets/Git.html-ef4b5f14.js" as="script"><link rel="prefetch" href="/assets/Markdown语法基础.html-2825f872.js" as="script"><link rel="prefetch" href="/assets/操作系统.html-8bed0f34.js" as="script"><link rel="prefetch" href="/assets/数据结构.html-6f1a0269.js" as="script"><link rel="prefetch" href="/assets/正则表达式.html-be164830.js" as="script"><link rel="prefetch" href="/assets/计算机组成原理.html-2668b30e.js" as="script"><link rel="prefetch" href="/assets/计算机网络.html-b11deb88.js" as="script"><link rel="prefetch" href="/assets/设计模式.html-35cadb50.js" as="script"><link rel="prefetch" href="/assets/面向对象设计基本原则.html-edb429fa.js" as="script"><link rel="prefetch" href="/assets/Docker.html-9f4e5ab9.js" as="script"><link rel="prefetch" href="/assets/GitHub Actions.html-bc1f64fb.js" as="script"><link rel="prefetch" href="/assets/基于centos部署java项目.html-b44ac3d3.js" as="script"><link rel="prefetch" href="/assets/一些插件.html-7333e5f0.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-c14413e6.js" as="script"><link rel="prefetch" href="/assets/CSGO饰品图.html-41566c4f.js" as="script"><link rel="prefetch" href="/assets/基础.html-376a9d53.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-ff145bec.js" as="script"><link rel="prefetch" href="/assets/Guitar.html-88bc41a7.js" as="script"><link rel="prefetch" href="/assets/hlae.html-5be4d809.js" as="script"><link rel="prefetch" href="/assets/settings.html-ed8baefd.js" as="script"><link rel="prefetch" href="/assets/index.html-71b38232.js" as="script"><link rel="prefetch" href="/assets/index.html-648f386b.js" as="script"><link rel="prefetch" href="/assets/30天JavaScript挑战.html-90b1a895.js" as="script"><link rel="prefetch" href="/assets/高频 SQL 50 题（基础版）.html-405179ee.js" as="script"><link rel="prefetch" href="/assets/多线程.html-46ffbab2.js" as="script"><link rel="prefetch" href="/assets/noob-Rg-better.html-cc14aa26.js" as="script"><link rel="prefetch" href="/assets/noob-Rg.html-3a2fdcc8.js" as="script"><link rel="prefetch" href="/assets/1、JavaScript基础语法笔记.html-69b3cd61.js" as="script"><link rel="prefetch" href="/assets/2、WebAPIs笔记.html-a8c50328.js" as="script"><link rel="prefetch" href="/assets/3、JavaScript进阶.html-180a19d8.js" as="script"><link rel="prefetch" href="/assets/1、TypeScript语言简介.html-ecee5a2a.js" as="script"><link rel="prefetch" href="/assets/2、基本用法.html-8e7f792b.js" as="script"><link rel="prefetch" href="/assets/3、any，unknown ，never 类型.html-92d935e7.js" as="script"><link rel="prefetch" href="/assets/4、系统类型.html-564a8c20.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-74cacfb8.js" as="script"><link rel="prefetch" href="/assets/6、元祖.html-df4609ec.js" as="script"><link rel="prefetch" href="/assets/7、symbol 类型.html-459544bf.js" as="script"><link rel="prefetch" href="/assets/8、函数.html-c5c268c2.js" as="script"><link rel="prefetch" href="/assets/index.html-9b0abc8d.js" as="script"><link rel="prefetch" href="/assets/leetcode228_汇总区间.html-cddb8f7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_001_两数之和.html-4d2935f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_002_两数相加.html-fe20f202.js" as="script"><link rel="prefetch" href="/assets/leetcode_003_无重复字符的最长子串.html-267e65ef.js" as="script"><link rel="prefetch" href="/assets/leetcode_004_寻找两个正序数组的中位数.html-9efd45da.js" as="script"><link rel="prefetch" href="/assets/leetcode_005_最长回文子串.html-39e1fea9.js" as="script"><link rel="prefetch" href="/assets/leetcode_006_N 字形变换.html-b4f920fe.js" as="script"><link rel="prefetch" href="/assets/leetcode_007_整数反转.html-4dd1c7a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_008_字符串转换整数 (atoi).html-fa0a27da.js" as="script"><link rel="prefetch" href="/assets/leetcode_009_回文数.html-55377a9f.js" as="script"><link rel="prefetch" href="/assets/leetcode_010_正则表达式匹配.html-674b100d.js" as="script"><link rel="prefetch" href="/assets/leetcode_011_盛最多水的容器.html-c8a38d1c.js" as="script"><link rel="prefetch" href="/assets/leetcode_012_整数转罗马数字.html-6b38adef.js" as="script"><link rel="prefetch" href="/assets/leetcode_013_罗马数字转整数.html-22c1adfb.js" as="script"><link rel="prefetch" href="/assets/leetcode_014_最长公共前缀.html-c172cec6.js" as="script"><link rel="prefetch" href="/assets/leetcode_015_三数之和.html-875a5ed0.js" as="script"><link rel="prefetch" href="/assets/leetcode_016_最接近的三数之和.html-b931e3c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_017_电话号码的字母组合.html-6d899101.js" as="script"><link rel="prefetch" href="/assets/leetcode_018_四数之和.html-087b71dc.js" as="script"><link rel="prefetch" href="/assets/leetcode_019_删除链表的倒数第 N 个结点.html-8241fe9c.js" as="script"><link rel="prefetch" href="/assets/leetcode_020_有效的括号.html-e07e2181.js" as="script"><link rel="prefetch" href="/assets/leetcode_021_合并两个有序链表.html-3e5fdc85.js" as="script"><link rel="prefetch" href="/assets/leetcode_022_括号生成.html-34027bae.js" as="script"><link rel="prefetch" href="/assets/leetcode_023_合并 K 个升序链表.html-2830aabf.js" as="script"><link rel="prefetch" href="/assets/leetcode_024_两两交换链表中的节点.html-aa44f045.js" as="script"><link rel="prefetch" href="/assets/leetcode_025_K 个一组翻转链表.html-1cb0de2d.js" as="script"><link rel="prefetch" href="/assets/leetcode_026_删除有序数组中的重复项.html-bf359f60.js" as="script"><link rel="prefetch" href="/assets/leetcode_027_移除元素.html-529831e9.js" as="script"><link rel="prefetch" href="/assets/leetcode_028_找出字符串中第一个匹配项的下标.html-dc2e4f17.js" as="script"><link rel="prefetch" href="/assets/leetcode_029_两数相除.html-03436b7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_030_串联所有单词的子串.html-faa41612.js" as="script"><link rel="prefetch" href="/assets/leetcode_031_下一个排列.html-1bf62ff0.js" as="script"><link rel="prefetch" href="/assets/leetcode_032_最长有效括号.html-dbd4329f.js" as="script"><link rel="prefetch" href="/assets/leetcode_033_搜索旋转排序数组.html-b3f9f227.js" as="script"><link rel="prefetch" href="/assets/leetcode_034_在排序数组中查找元素的第一个和最后一个位置.html-df6d34be.js" as="script"><link rel="prefetch" href="/assets/leetcode_035_搜索插入位置.html-f3871315.js" as="script"><link rel="prefetch" href="/assets/leetcode_036_有效的数独.html-5f2bc80d.js" as="script"><link rel="prefetch" href="/assets/leetcode_038_外观数列.html-6e3a5b1a.js" as="script"><link rel="prefetch" href="/assets/leetcode_039_ 组合总和.html-b0a7cd1a.js" as="script"><link rel="prefetch" href="/assets/leetcode_040_ 组合总和II.html-87cd31b2.js" as="script"><link rel="prefetch" href="/assets/leetcode_041_ 缺失的第一个正数.html-c08437a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_042_接雨水.html-4f929eb5.js" as="script"><link rel="prefetch" href="/assets/leetcode_043_字符串相乘.html-81486896.js" as="script"><link rel="prefetch" href="/assets/leetcode_045_跳跃游戏II.html-a0a07e13.js" as="script"><link rel="prefetch" href="/assets/leetcode_046_全排列.html-8e33255c.js" as="script"><link rel="prefetch" href="/assets/leetcode_047_全排列II.html-bc7cb387.js" as="script"><link rel="prefetch" href="/assets/leetcode_048_旋转图像.html-ec0a782c.js" as="script"><link rel="prefetch" href="/assets/leetcode_049_字母异位词分组.html-dc410cab.js" as="script"><link rel="prefetch" href="/assets/leetcode_050_Pow(x_n).html-29adea25.js" as="script"><link rel="prefetch" href="/assets/leetcode_051_N 皇后.html-54792019.js" as="script"><link rel="prefetch" href="/assets/leetcode_052_N 皇后 II.html-cae35ca8.js" as="script"><link rel="prefetch" href="/assets/leetcode_053_最大子数组和.html-f84751f2.js" as="script"><link rel="prefetch" href="/assets/leetcode_054_螺旋矩阵.html-7c2f26d1.js" as="script"><link rel="prefetch" href="/assets/leetcode_055_跳跃游戏.html-196b4f14.js" as="script"><link rel="prefetch" href="/assets/leetcode_056_合并区间.html-3c8d49b7.js" as="script"><link rel="prefetch" href="/assets/leetcode_058_最后一个单词的长度.html-c74c97db.js" as="script"><link rel="prefetch" href="/assets/leetcode_061_旋转链表.html-c1b9f0bb.js" as="script"><link rel="prefetch" href="/assets/leetcode_062_不同路径.html-5571caa7.js" as="script"><link rel="prefetch" href="/assets/leetcode_063_不同路径II.html-761d387b.js" as="script"><link rel="prefetch" href="/assets/leetcode_064_最小路径和.html-cecd8a72.js" as="script"><link rel="prefetch" href="/assets/leetcode_066_加一.html-12eefde8.js" as="script"><link rel="prefetch" href="/assets/leetcode_067_二进制求和.html-555cfc00.js" as="script"><link rel="prefetch" href="/assets/leetcode_068_文本左右对齐.html-7a5c575d.js" as="script"><link rel="prefetch" href="/assets/leetcode_069_x的平方根.html-b20ef54c.js" as="script"><link rel="prefetch" href="/assets/leetcode_070_爬楼梯.html-d52a7e95.js" as="script"><link rel="prefetch" href="/assets/leetcode_072_编辑距离.html-00a22365.js" as="script"><link rel="prefetch" href="/assets/leetcode_073_矩阵置零.html-2bf295e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_075_颜色分类.html-5d29d6eb.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串 copy.html-dba3ee02.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串.html-58de2813.js" as="script"><link rel="prefetch" href="/assets/leetcode_079_单词搜索.html-c3ecad05.js" as="script"><link rel="prefetch" href="/assets/leetcode_080_删除有序数组中的重复项.html-ad954572.js" as="script"><link rel="prefetch" href="/assets/leetcode_082_删除排序链表中的重复元素 II.html-ffc51573.js" as="script"><link rel="prefetch" href="/assets/leetcode_083_删除排序链表中的重复元素.html-70bf5bb7.js" as="script"><link rel="prefetch" href="/assets/leetcode_086_分隔链表.html-79aea5ef.js" as="script"><link rel="prefetch" href="/assets/leetcode_088_合并两个有序数组.html-ba540966.js" as="script"><link rel="prefetch" href="/assets/leetcode_092_反转链表 II.html-23caaca0.js" as="script"><link rel="prefetch" href="/assets/leetcode_094_二叉树的中序遍历.html-8288cdbe.js" as="script"><link rel="prefetch" href="/assets/leetcode_095_不同的二叉搜索树 II.html-47652036.js" as="script"><link rel="prefetch" href="/assets/leetcode_096_不同的二叉搜索树.html-ae75ff17.js" as="script"><link rel="prefetch" href="/assets/leetcode_098_验证二叉搜索树.html-03e5a7b1.js" as="script"><link rel="prefetch" href="/assets/leetcode_1004_最大连续1的个数 III.html-5533e255.js" as="script"><link rel="prefetch" href="/assets/leetcode_100_相同的树.html-b3027eaa.js" as="script"><link rel="prefetch" href="/assets/leetcode_101_对称二叉树.html-ce76548e.js" as="script"><link rel="prefetch" href="/assets/leetcode_102_二叉树的层序遍历.html-bf767249.js" as="script"><link rel="prefetch" href="/assets/leetcode_103_二叉树的锯齿形层序遍历.html-c877409c.js" as="script"><link rel="prefetch" href="/assets/leetcode_104_二叉树的最大深度.html-1b32579f.js" as="script"><link rel="prefetch" href="/assets/leetcode_105_从前序与中序遍历序列构造二叉树.html-d13a65a1.js" as="script"><link rel="prefetch" href="/assets/leetcode_106_从中序与后序遍历序列构造二叉树.html-a6327af2.js" as="script"><link rel="prefetch" href="/assets/leetcode_1071_字符串的最大公因子.html-5476c3fe.js" as="script"><link rel="prefetch" href="/assets/leetcode_107_二叉树的层序遍历 II.html-8d1b9daf.js" as="script"><link rel="prefetch" href="/assets/leetcode_108_将有序数组转换为二叉搜索树.html-56c9fcfb.js" as="script"><link rel="prefetch" href="/assets/leetcode_112_路径总和.html-bde85dfa.js" as="script"><link rel="prefetch" href="/assets/leetcode_113_路径总和II.html-8f74fe65.js" as="script"><link rel="prefetch" href="/assets/leetcode_1143_最长公共子序列.html-99c668c7.js" as="script"><link rel="prefetch" href="/assets/leetcode_114_二叉树展开为链表.html-bdd88a01.js" as="script"><link rel="prefetch" href="/assets/leetcode_1161_最大层内元素和.html-fcb209f5.js" as="script"><link rel="prefetch" href="/assets/leetcode_117_填充每个节点的下一个右侧节点指针 II.html-764ce2a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_118_杨辉三角.html-479e30a4.js" as="script"><link rel="prefetch" href="/assets/leetcode_119_杨辉三角 II.html-a59406df.js" as="script"><link rel="prefetch" href="/assets/leetcode_1207_独一无二的出现次数.html-16dda148.js" as="script"><link rel="prefetch" href="/assets/leetcode_120_三角形最小路径和.html-86703591.js" as="script"><link rel="prefetch" href="/assets/leetcode_121_买卖股票的最佳时机 I.html-13626864.js" as="script"><link rel="prefetch" href="/assets/leetcode_122_买卖股票的最佳时机 II.html-bb37bd6e.js" as="script"><link rel="prefetch" href="/assets/leetcode_124_二叉树中的最大路径和.html-8e211f55.js" as="script"><link rel="prefetch" href="/assets/leetcode_125_验证回文串.html-90dfd796.js" as="script"><link rel="prefetch" href="/assets/leetcode_128_最长连续序列.html-8b798fa6.js" as="script"><link rel="prefetch" href="/assets/leetcode_129_求根节点到叶节点数字之和.html-8758fc10.js" as="script"><link rel="prefetch" href="/assets/leetcode_130_被围绕的区域.html-31108440.js" as="script"><link rel="prefetch" href="/assets/leetcode_1318_或运算的最小翻转次数.html-b1d00d09.js" as="script"><link rel="prefetch" href="/assets/leetcode_134_加油站.html-aa290400.js" as="script"><link rel="prefetch" href="/assets/leetcode_135_分发糖果.html-169212a1.js" as="script"><link rel="prefetch" href="/assets/leetcode_136_只出现一次的数字.html-efac1a41.js" as="script"><link rel="prefetch" href="/assets/leetcode_1372_二叉树中的最长交错路径.html-1f702f8e.js" as="script"><link rel="prefetch" href="/assets/leetcode_139_单词拆分.html-60a3eec6.js" as="script"><link rel="prefetch" href="/assets/leetcode_141_环形链表.html-caf4560c.js" as="script"><link rel="prefetch" href="/assets/leetcode_1431_拥有最多糖果的孩子.html-c46bc216.js" as="script"><link rel="prefetch" href="/assets/leetcode_1448_统计二叉树中好节点的数目.html-badf2d7e.js" as="script"><link rel="prefetch" href="/assets/leetcode_144_二叉树的前序遍历.html-782a3002.js" as="script"><link rel="prefetch" href="/assets/leetcode_1456_定长子串中元音的最大数目.html-0bebd911.js" as="script"><link rel="prefetch" href="/assets/leetcode_145_二叉树的后序遍历.html-f423c8ea.js" as="script"><link rel="prefetch" href="/assets/leetcode_1466_重新规划路线.html-61eb288d.js" as="script"><link rel="prefetch" href="/assets/leetcode_146_LRU 缓存.html-ef476ae2.js" as="script"><link rel="prefetch" href="/assets/leetcode_148_排序链表.html-6835afd8.js" as="script"><link rel="prefetch" href="/assets/leetcode_1493_删掉一个元素以后全为 1 的最长子数组.html-1c9feb8e.js" as="script"><link rel="prefetch" href="/assets/leetcode_150_逆波兰表达式求值.html-8c4709cc.js" as="script"><link rel="prefetch" href="/assets/leetcode_151_反转字符串中的单词.html-f91b8216.js" as="script"><link rel="prefetch" href="/assets/leetcode_155_最小栈.html-20c00992.js" as="script"><link rel="prefetch" href="/assets/leetcode_160_相交链表.html-5627acf7.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值 copy.html-f24beb30.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值.html-42e7d40f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1657_确定两个字符串是否接近.html-8a42e6de.js" as="script"><link rel="prefetch" href="/assets/leetcode_1679_K 和数对的最大数目.html-75040006.js" as="script"><link rel="prefetch" href="/assets/leetcode_169_多数元素.html-b7c60141.js" as="script"><link rel="prefetch" href="/assets/leetcode_1732_找到最高海拔.html-7ecbb8c1.js" as="script"><link rel="prefetch" href="/assets/leetcode_173_二叉搜索树迭代器.html-5f9afb5f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1768_交替合并字符串.html-fa23ddd6.js" as="script"><link rel="prefetch" href="/assets/leetcode_189_轮转数组.html-c42a0832.js" as="script"><link rel="prefetch" href="/assets/leetcode_1926_迷宫中离入口最近的出口.html-ba13a452.js" as="script"><link rel="prefetch" href="/assets/leetcode_198_打家劫舍.html-01ddc8ed.js" as="script"><link rel="prefetch" href="/assets/leetcode_199. 二叉树的右视图.html-b4044b3b.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数 copy.html-4128158a.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数.html-df50f511.js" as="script"><link rel="prefetch" href="/assets/leetcode_203_移除链表元素.html-e917fc2e.js" as="script"><link rel="prefetch" href="/assets/leetcode_206_反转链表.html-c20741fc.js" as="script"><link rel="prefetch" href="/assets/leetcode_208_实现 Trie (前缀树).html-b62d7f4f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2095_删除链表的中间节点.html-deb3033e.js" as="script"><link rel="prefetch" href="/assets/leetcode_209_长度最小的子数组.html-b4fb933f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2130_链表最大孪生和.html-d152e296.js" as="script"><link rel="prefetch" href="/assets/leetcode_215_数组中的第K个最大元素.html-facb19af.js" as="script"><link rel="prefetch" href="/assets/leetcode_216_组合总和 III.html-449b0a0b.js" as="script"><link rel="prefetch" href="/assets/leetcode_219_存在重复元素 II.html-426b13a6.js" as="script"><link rel="prefetch" href="/assets/leetcode_2215_找出两数组的不同.html-8f3c9866.js" as="script"><link rel="prefetch" href="/assets/leetcode_222_完全二叉树的节点个数.html-e247e501.js" as="script"><link rel="prefetch" href="/assets/leetcode_226_翻转二叉树.html-a6fe8a1b.js" as="script"><link rel="prefetch" href="/assets/leetcode_2300. 咒语和药水的成功对数.html-451a870e.js" as="script"><link rel="prefetch" href="/assets/leetcode_230_二叉搜索树中第K小的元素.html-8f9aff36.js" as="script"><link rel="prefetch" href="/assets/leetcode_2336_无限集中的最小数字.html-0186d2f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_234_回文链表.html-5ffc51ac.js" as="script"><link rel="prefetch" href="/assets/leetcode_2352_相等行列对.html-aa32ea65.js" as="script"><link rel="prefetch" href="/assets/leetcode_236_二叉树的最近公共祖先.html-067dc510.js" as="script"><link rel="prefetch" href="/assets/leetcode_238_除自身以外数组的乘积.html-d416e8f0.js" as="script"><link rel="prefetch" href="/assets/leetcode_2390_从字符串中移除星号.html-f97fadc9.js" as="script"><link rel="prefetch" href="/assets/leetcode_242_有效的字母异位词.html-50564962.js" as="script"><link rel="prefetch" href="/assets/leetcode_2542_最大序列的分数.html-f5e8bf7d.js" as="script"><link rel="prefetch" href="/assets/leetcode_274_H指数.html-219397c4.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy 2.html-2ece538f.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy.html-b2dcfc16.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0.html-28326917.js" as="script"><link rel="prefetch" href="/assets/leetcode_300_最长递增子序列.html-7bc25e46.js" as="script"><link rel="prefetch" href="/assets/leetcode_322_零钱兑换.html-338820d0.js" as="script"><link rel="prefetch" href="/assets/leetcode_328_奇偶链表.html-c221c5e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_334_递增的三元子序列.html-eaa7359c.js" as="script"><link rel="prefetch" href="/assets/leetcode_338_比特位计数.html-1ca3e264.js" as="script"><link rel="prefetch" href="/assets/leetcode_345_反转字符串中的元音字母.html-a53a56ed.js" as="script"><link rel="prefetch" href="/assets/leetcode_374_猜数字大小.html-838e47cd.js" as="script"><link rel="prefetch" href="/assets/leetcode_380_O(1) 时间插入、删除和获取随机元素.html-809dfc48.js" as="script"><link rel="prefetch" href="/assets/leetcode_383_赎金信.html-b140905d.js" as="script"><link rel="prefetch" href="/assets/leetcode_392_判断子序列.html-0f679959.js" as="script"><link rel="prefetch" href="/assets/leetcode_394_字符串解码.html-34dbf0a9.js" as="script"><link rel="prefetch" href="/assets/leetcode_435_无重叠区间.html-a86bed80.js" as="script"><link rel="prefetch" href="/assets/leetcode_437_路径总和 III.html-03d25af8.js" as="script"><link rel="prefetch" href="/assets/leetcode_443_压缩字符串.html-04e19523.js" as="script"><link rel="prefetch" href="/assets/leetcode_450_删除二叉搜索树中的节点.html-b96c20de.js" as="script"><link rel="prefetch" href="/assets/leetcode_452_用最少数量的箭引爆气球.html-38e27162.js" as="script"><link rel="prefetch" href="/assets/leetcode_530_二叉搜索树的最小绝对差.html-67141eeb.js" as="script"><link rel="prefetch" href="/assets/leetcode_547_省份数量.html-b3b6bac4.js" as="script"><link rel="prefetch" href="/assets/leetcode_605_种花问题.html-031d3116.js" as="script"><link rel="prefetch" href="/assets/leetcode_637_二叉树的层平均值.html-a7a36db9.js" as="script"><link rel="prefetch" href="/assets/leetcode_643_子数组最大平均数 I.html-a8f43e75.js" as="script"><link rel="prefetch" href="/assets/leetcode_649_Dota2 参议院.html-57e2951e.js" as="script"><link rel="prefetch" href="/assets/leetcode_700_二叉搜索树中的搜索.html-023dc167.js" as="script"><link rel="prefetch" href="/assets/leetcode_714_买卖股票的最佳时机含手续费.html-7ad01ab6.js" as="script"><link rel="prefetch" href="/assets/leetcode_724_寻找数组的中心下标.html-71388c1f.js" as="script"><link rel="prefetch" href="/assets/leetcode_735_行星碰撞.html-79670bf6.js" as="script"><link rel="prefetch" href="/assets/leetcode_739_每日温度.html-00bbc948.js" as="script"><link rel="prefetch" href="/assets/leetcode_746_使用最小花费爬楼梯.html-568fe2b8.js" as="script"><link rel="prefetch" href="/assets/leetcode_790_多米诺和托米诺平铺.html-e3681c3f.js" as="script"><link rel="prefetch" href="/assets/leetcode_841_钥匙和房间.html-75e3c562.js" as="script"><link rel="prefetch" href="/assets/leetcode_872_叶子相似的树.html-4ff19ccc.js" as="script"><link rel="prefetch" href="/assets/leetcode_875_爱吃香蕉的珂珂.html-c23d801c.js" as="script"><link rel="prefetch" href="/assets/leetcode_876_链表的中间结点.html-e827b29b.js" as="script"><link rel="prefetch" href="/assets/leetcode_901_股票价格跨度.html-6195f435.js" as="script"><link rel="prefetch" href="/assets/leetcode_933_最近的请求次数.html-b601ebe2.js" as="script"><link rel="prefetch" href="/assets/leetcode_994_腐烂的橘子.html-c9fcbc99.js" as="script"><link rel="prefetch" href="/assets/leetcode_LCP68_美丽的花束.html-bea99396.js" as="script"><link rel="prefetch" href="/assets/Arrays类.html-5cff467d.js" as="script"><link rel="prefetch" href="/assets/BigInteger和BigDecimal.html-b00a56b8.js" as="script"><link rel="prefetch" href="/assets/Collections类.html-6e3e4ec0.js" as="script"><link rel="prefetch" href="/assets/Java比较器.html-f75c5cab.js" as="script"><link rel="prefetch" href="/assets/Math类.html-66218b19.js" as="script"><link rel="prefetch" href="/assets/Object类.html-43eeba34.js" as="script"><link rel="prefetch" href="/assets/Pattern 与 Matcher 类.html-ee7d45a1.js" as="script"><link rel="prefetch" href="/assets/Stream API.html-9b418bda.js" as="script"><link rel="prefetch" href="/assets/String、Scanner相关类.html-ab539520.js" as="script"><link rel="prefetch" href="/assets/System类.html-0388d0ad.js" as="script"><link rel="prefetch" href="/assets/日期时间API.html-abcd5dc6.js" as="script"><link rel="prefetch" href="/assets/10、多线程.html-35e659db.js" as="script"><link rel="prefetch" href="/assets/11、枚举类.html-0bf87ec6.js" as="script"><link rel="prefetch" href="/assets/12、注解.html-50944a71.js" as="script"><link rel="prefetch" href="/assets/13、集合.html-9439bdbe.js" as="script"><link rel="prefetch" href="/assets/14、泛型.html-d7592650.js" as="script"><link rel="prefetch" href="/assets/15、IO流.html-515b20a8.js" as="script"><link rel="prefetch" href="/assets/16、网络编程.html-d4102567.js" as="script"><link rel="prefetch" href="/assets/17、反射.html-539859f0.js" as="script"><link rel="prefetch" href="/assets/18、新特性.html-ef7a4719.js" as="script"><link rel="prefetch" href="/assets/19、格式化输入输出.html-9690fc0f.js" as="script"><link rel="prefetch" href="/assets/1、基础概念.html-8e40e2f0.js" as="script"><link rel="prefetch" href="/assets/2、数据类型.html-7994f88b.js" as="script"><link rel="prefetch" href="/assets/3、运算符.html-457a2f56.js" as="script"><link rel="prefetch" href="/assets/4、程序流程控制.html-7c29dc6c.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-a4c355fe.js" as="script"><link rel="prefetch" href="/assets/6、面向对象.html-ad3a75f9.js" as="script"><link rel="prefetch" href="/assets/7、单元测试Junit.html-6c06e896.js" as="script"><link rel="prefetch" href="/assets/8、包装类.html-91494c0b.js" as="script"><link rel="prefetch" href="/assets/9、异常处理.html-efeedf1f.js" as="script"><link rel="prefetch" href="/assets/基础概念.html-93cece09.js" as="script"><link rel="prefetch" href="/assets/网络架构.html-4e813cd4.js" as="script"><link rel="prefetch" href="/assets/1、Pytorch 建模流程.html-bc26fc1e.js" as="script"><link rel="prefetch" href="/assets/2、张量数据结构.html-369a6bfb.js" as="script"><link rel="prefetch" href="/assets/3、自动微分机制、优化器.html-a51e51d3.js" as="script"><link rel="prefetch" href="/assets/4、动态计算图.html-6751486b.js" as="script"><link rel="prefetch" href="/assets/6、Pytorch 中阶 API.html-12d00ec0.js" as="script"><link rel="prefetch" href="/assets/7、构建、训练模型.html-d518af36.js" as="script"><link rel="prefetch" href="/assets/Pytorch-20.html-26d96f13.js" as="script"><link rel="prefetch" href="/assets/Pytorch.html-d1d2957f.js" as="script"><link rel="prefetch" href="/assets/强化学习.html-936d4c17.js" as="script"><link rel="prefetch" href="/assets/Vue笔记1-核心.html-e989c925.js" as="script"><link rel="prefetch" href="/assets/Vue笔记2-组件.html-8621d7cf.js" as="script"><link rel="prefetch" href="/assets/Vue笔记3-脚手架.html-de68fd83.js" as="script"><link rel="prefetch" href="/assets/Vue笔记4-Vue中的ajax.html-df24fe68.js" as="script"><link rel="prefetch" href="/assets/Vue笔记5-插槽.html-3155ce14.js" as="script"><link rel="prefetch" href="/assets/Vue笔记6-vuex.html-90ee75fa.js" as="script"><link rel="prefetch" href="/assets/Vue笔记7-路由.html-9023e075.js" as="script"><link rel="prefetch" href="/assets/Vue笔记8-element-ui.html-a3b54a99.js" as="script"><link rel="prefetch" href="/assets/Vue3快速上手.html-943296f4.js" as="script"><link rel="prefetch" href="/assets/markdown扩展.html-1b4673b3.js" as="script"><link rel="prefetch" href="/assets/404.html-cc91ab3d.js" as="script"><link rel="prefetch" href="/assets/index.html-4d071ae6.js" as="script"><link rel="prefetch" href="/assets/index.html-a6b9d739.js" as="script"><link rel="prefetch" href="/assets/index.html-673bc96c.js" as="script"><link rel="prefetch" href="/assets/index.html-a7a29c4c.js" as="script"><link rel="prefetch" href="/assets/index.html-194b0620.js" as="script"><link rel="prefetch" href="/assets/index.html-a899c6cf.js" as="script"><link rel="prefetch" href="/assets/index.html-e2494c9f.js" as="script"><link rel="prefetch" href="/assets/index.html-61c0a09c.js" as="script"><link rel="prefetch" href="/assets/index.html-be2636ab.js" as="script"><link rel="prefetch" href="/assets/index.html-67b37d25.js" as="script"><link rel="prefetch" href="/assets/index.html-2f703168.js" as="script"><link rel="prefetch" href="/assets/index.html-49eef8d8.js" as="script"><link rel="prefetch" href="/assets/index.html-2d0de498.js" as="script"><link rel="prefetch" href="/assets/index.html-2fa96ec7.js" as="script"><link rel="prefetch" href="/assets/index.html-d9cf3019.js" as="script"><link rel="prefetch" href="/assets/index.html-6d51d871.js" as="script"><link rel="prefetch" href="/assets/index.html-d782a376.js" as="script"><link rel="prefetch" href="/assets/index.html-848ebbe8.js" as="script"><link rel="prefetch" href="/assets/index.html-1ba1d180.js" as="script"><link rel="prefetch" href="/assets/index.html-9e55ee4d.js" as="script"><link rel="prefetch" href="/assets/index.html-106d954c.js" as="script"><link rel="prefetch" href="/assets/index.html-5fbc2a0d.js" as="script"><link rel="prefetch" href="/assets/index.html-c03d1584.js" as="script"><link rel="prefetch" href="/assets/index.html-9c648683.js" as="script"><link rel="prefetch" href="/assets/index.html-1c24935a.js" as="script"><link rel="prefetch" href="/assets/index.html-99af66e2.js" as="script"><link rel="prefetch" href="/assets/index.html-ee02ddf0.js" as="script"><link rel="prefetch" href="/assets/index.html-20b834a5.js" as="script"><link rel="prefetch" href="/assets/index.html-3a4d6e36.js" as="script"><link rel="prefetch" href="/assets/index.html-139f2f06.js" as="script"><link rel="prefetch" href="/assets/index.html-a935f094.js" as="script"><link rel="prefetch" href="/assets/index.html-e92ce08c.js" as="script"><link rel="prefetch" href="/assets/index.html-63bc6b2b.js" as="script"><link rel="prefetch" href="/assets/index.html-94957f61.js" as="script"><link rel="prefetch" href="/assets/index.html-91bcd141.js" as="script"><link rel="prefetch" href="/assets/index.html-e5933818.js" as="script"><link rel="prefetch" href="/assets/index.html-abd11527.js" as="script"><link rel="prefetch" href="/assets/index.html-d6c5a433.js" as="script"><link rel="prefetch" href="/assets/index.html-ec18a7df.js" as="script"><link rel="prefetch" href="/assets/index.html-d3624e38.js" as="script"><link rel="prefetch" href="/assets/index.html-13f98761.js" as="script"><link rel="prefetch" href="/assets/index.html-0cce8e2d.js" as="script"><link rel="prefetch" href="/assets/index.html-7193a535.js" as="script"><link rel="prefetch" href="/assets/index.html-0e85c606.js" as="script"><link rel="prefetch" href="/assets/index.html-41fd6d63.js" as="script"><link rel="prefetch" href="/assets/index.html-faa3c911.js" as="script"><link rel="prefetch" href="/assets/index.html-bfb66f86.js" as="script"><link rel="prefetch" href="/assets/index.html-f5020150.js" as="script"><link rel="prefetch" href="/assets/index.html-5c2c76d5.js" as="script"><link rel="prefetch" href="/assets/index.html-a2feaac9.js" as="script"><link rel="prefetch" href="/assets/index.html-b7b8c4b6.js" as="script"><link rel="prefetch" href="/assets/index.html-ff6eb04f.js" as="script"><link rel="prefetch" href="/assets/index.html-a3550230.js" as="script"><link rel="prefetch" href="/assets/index.html-7a3254b0.js" as="script"><link rel="prefetch" href="/assets/index.html-c5715831.js" as="script"><link rel="prefetch" href="/assets/index.html-e9a4a4e1.js" as="script"><link rel="prefetch" href="/assets/index.html-9d2fd3be.js" as="script"><link rel="prefetch" href="/assets/index.html-8af2a3d1.js" as="script"><link rel="prefetch" href="/assets/index.html-cc614db6.js" as="script"><link rel="prefetch" href="/assets/index.html-b772e465.js" as="script"><link rel="prefetch" href="/assets/index.html-b1a752fe.js" as="script"><link rel="prefetch" href="/assets/index.html-4209efbb.js" as="script"><link rel="prefetch" href="/assets/index.html-4ff744ba.js" as="script"><link rel="prefetch" href="/assets/index.html-c424e42c.js" as="script"><link rel="prefetch" href="/assets/index.html-7f168d0f.js" as="script"><link rel="prefetch" href="/assets/index.html-56de2f95.js" as="script"><link rel="prefetch" href="/assets/index.html-f7cb97d3.js" as="script"><link rel="prefetch" href="/assets/index.html-c546e8a1.js" as="script"><link rel="prefetch" href="/assets/index.html-0009964a.js" as="script"><link rel="prefetch" href="/assets/index.html-00b637a2.js" as="script"><link rel="prefetch" href="/assets/index.html-fb5f6e90.js" as="script"><link rel="prefetch" href="/assets/index.html-ac4d56df.js" as="script"><link rel="prefetch" href="/assets/index.html-6aa2d78e.js" as="script"><link rel="prefetch" href="/assets/index.html-d462cdeb.js" as="script"><link rel="prefetch" href="/assets/index.html-6b698fb1.js" as="script"><link rel="prefetch" href="/assets/index.html-acbfbf53.js" as="script"><link rel="prefetch" href="/assets/index.html-905f1804.js" as="script"><link rel="prefetch" href="/assets/index.html-16d7d340.js" as="script"><link rel="prefetch" href="/assets/index.html-46271911.js" as="script"><link rel="prefetch" href="/assets/index.html-b604d4ee.js" as="script"><link rel="prefetch" href="/assets/index.html-14c05c19.js" as="script"><link rel="prefetch" href="/assets/index.html-f310c092.js" as="script"><link rel="prefetch" href="/assets/index.html-ccaf9ee9.js" as="script"><link rel="prefetch" href="/assets/index.html-e22bc441.js" as="script"><link rel="prefetch" href="/assets/index.html-1c66cf59.js" as="script"><link rel="prefetch" href="/assets/index.html-8208559f.js" as="script"><link rel="prefetch" href="/assets/index.html-2aea38ab.js" as="script"><link rel="prefetch" href="/assets/index.html-9c6eba41.js" as="script"><link rel="prefetch" href="/assets/index.html-38a7a2af.js" as="script"><link rel="prefetch" href="/assets/index.html-c8b179d7.js" as="script"><link rel="prefetch" href="/assets/index.html-7e1863fb.js" as="script"><link rel="prefetch" href="/assets/index.html-8968a188.js" as="script"><link rel="prefetch" href="/assets/index.html-64ee687b.js" as="script"><link rel="prefetch" href="/assets/index.html-80fe2383.js" as="script"><link rel="prefetch" href="/assets/index.html-fea946c3.js" as="script"><link rel="prefetch" href="/assets/index.html-f17f8ab5.js" as="script"><link rel="prefetch" href="/assets/index.html-1a5be529.js" as="script"><link rel="prefetch" href="/assets/index.html-0e767346.js" as="script"><link rel="prefetch" href="/assets/index.html-3ca31bd8.js" as="script"><link rel="prefetch" href="/assets/index.html-b133f8c8.js" as="script"><link rel="prefetch" href="/assets/index.html-7195b3a2.js" as="script"><link rel="prefetch" href="/assets/index.html-1beacc22.js" as="script"><link rel="prefetch" href="/assets/index.html-88e5e4ce.js" as="script"><link rel="prefetch" href="/assets/index.html-210be80e.js" as="script"><link rel="prefetch" href="/assets/index.html-f33d538b.js" as="script"><link rel="prefetch" href="/assets/index.html-4941c0fe.js" as="script"><link rel="prefetch" href="/assets/index.html-c736be09.js" as="script"><link rel="prefetch" href="/assets/index.html-03c9f91d.js" as="script"><link rel="prefetch" href="/assets/index.html-0b4b9ae3.js" as="script"><link rel="prefetch" href="/assets/index.html-229119d0.js" as="script"><link rel="prefetch" href="/assets/index.html-bc2fb4cf.js" as="script"><link rel="prefetch" href="/assets/index.html-1c4a3288.js" as="script"><link rel="prefetch" href="/assets/index.html-842d27e2.js" as="script"><link rel="prefetch" href="/assets/index.html-b4206ac4.js" as="script"><link rel="prefetch" href="/assets/index.html-73e0d1d2.js" as="script"><link rel="prefetch" href="/assets/index.html-72b69436.js" as="script"><link rel="prefetch" href="/assets/index.html-3477f208.js" as="script"><link rel="prefetch" href="/assets/index.html-7c416790.js" as="script"><link rel="prefetch" href="/assets/index.html-2fa8126d.js" as="script"><link rel="prefetch" href="/assets/index.html-c4278da5.js" as="script"><link rel="prefetch" href="/assets/index.html-97b358be.js" as="script"><link rel="prefetch" href="/assets/index.html-a3c429a2.js" as="script"><link rel="prefetch" href="/assets/index.html-e28d3b12.js" as="script"><link rel="prefetch" href="/assets/index.html-e18dcbc2.js" as="script"><link rel="prefetch" href="/assets/index.html-9cbad9b7.js" as="script"><link rel="prefetch" href="/assets/index.html-c02de52a.js" as="script"><link rel="prefetch" href="/assets/index.html-375eef32.js" as="script"><link rel="prefetch" href="/assets/index.html-3b8fb7db.js" as="script"><link rel="prefetch" href="/assets/index.html-2b8d0809.js" as="script"><link rel="prefetch" href="/assets/index.html-186dd8fe.js" as="script"><link rel="prefetch" href="/assets/index.html-62cabbed.js" as="script"><link rel="prefetch" href="/assets/index.html-ae035267.js" as="script"><link rel="prefetch" href="/assets/index.html-b65e140a.js" as="script"><link rel="prefetch" href="/assets/index.html-28f7ff5c.js" as="script"><link rel="prefetch" href="/assets/Elasticsearch.html-23aec010.js" as="script"><link rel="prefetch" href="/assets/MongoDB.html-19cd7c20.js" as="script"><link rel="prefetch" href="/assets/MySQL基础.html-5b96b105.js" as="script"><link rel="prefetch" href="/assets/Redis.html-eee233cb.js" as="script"><link rel="prefetch" href="/assets/IDEA、Eclipse快捷键.html-2352972d.js" as="script"><link rel="prefetch" href="/assets/JDBC.html-b55f354c.js" as="script"><link rel="prefetch" href="/assets/JVM.html-788c2c8a.js" as="script"><link rel="prefetch" href="/assets/JVM入门.html-d0465f17.js" as="script"><link rel="prefetch" href="/assets/JWT.html-68fb59dd.js" as="script"><link rel="prefetch" href="/assets/JavaWeb基础.html-c65dcd09.js" as="script"><link rel="prefetch" href="/assets/Maven基础.html-b91baa0e.js" as="script"><link rel="prefetch" href="/assets/MyBatis.html-8833cdeb.js" as="script"><link rel="prefetch" href="/assets/MybatisPlus.html-13a90b5c.js" as="script"><link rel="prefetch" href="/assets/RabbitMQ.html-486dd38e.js" as="script"><link rel="prefetch" href="/assets/Shiro.html-dfb16d34.js" as="script"><link rel="prefetch" href="/assets/SpringBoot.html-b557b100.js" as="script"><link rel="prefetch" href="/assets/SpringBoot常用注解总结.html-b7716e19.js" as="script"><link rel="prefetch" href="/assets/SpringBoot自动装配原理.html-1fdf2345.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础.html-4d2fddf2.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础2024.html-d09810b2.js" as="script"><link rel="prefetch" href="/assets/SpringMVC.html-778599e7.js" as="script"><link rel="prefetch" href="/assets/Spring基础.html-32cd4cc5.js" as="script"><link rel="prefetch" href="/assets/index.html-e54c2da0.js" as="script"><link rel="prefetch" href="/assets/Matplotlib.html-d80f2a99.js" as="script"><link rel="prefetch" href="/assets/Numpy.html-1443193f.js" as="script"><link rel="prefetch" href="/assets/Pandas.html-dd77ebdc.js" as="script"><link rel="prefetch" href="/assets/python 基础语法.html-bb9b504e.js" as="script"><link rel="prefetch" href="/assets/python 项目注意事项.html-19c34e35.js" as="script"><link rel="prefetch" href="/assets/Ajax.html-57dbd7de.js" as="script"><link rel="prefetch" href="/assets/Axios.html-6d40401d.js" as="script"><link rel="prefetch" href="/assets/CSS3.html-a5386498.js" as="script"><link rel="prefetch" href="/assets/HTML.html-b6980682.js" as="script"><link rel="prefetch" href="/assets/Node.js笔记.html-982c2fd3.js" as="script"><link rel="prefetch" href="/assets/Promise.html-e16873e1.js" as="script"><link rel="prefetch" href="/assets/Git.html-13d43750.js" as="script"><link rel="prefetch" href="/assets/Markdown语法基础.html-8955ecf4.js" as="script"><link rel="prefetch" href="/assets/操作系统.html-7b04dc09.js" as="script"><link rel="prefetch" href="/assets/数据结构.html-16c8eca2.js" as="script"><link rel="prefetch" href="/assets/正则表达式.html-9ca7d155.js" as="script"><link rel="prefetch" href="/assets/计算机组成原理.html-72ebe676.js" as="script"><link rel="prefetch" href="/assets/计算机网络.html-cf64b569.js" as="script"><link rel="prefetch" href="/assets/设计模式.html-3b3be76a.js" as="script"><link rel="prefetch" href="/assets/面向对象设计基本原则.html-2a822bd3.js" as="script"><link rel="prefetch" href="/assets/Docker.html-272433b6.js" as="script"><link rel="prefetch" href="/assets/GitHub Actions.html-8687adf3.js" as="script"><link rel="prefetch" href="/assets/基于centos部署java项目.html-1bb17c1e.js" as="script"><link rel="prefetch" href="/assets/一些插件.html-537d6300.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-c01d0a41.js" as="script"><link rel="prefetch" href="/assets/CSGO饰品图.html-3045aa02.js" as="script"><link rel="prefetch" href="/assets/基础.html-770f17a0.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-3d14a8ce.js" as="script"><link rel="prefetch" href="/assets/Guitar.html-48e6307f.js" as="script"><link rel="prefetch" href="/assets/hlae.html-5aa65566.js" as="script"><link rel="prefetch" href="/assets/settings.html-f05dc22d.js" as="script"><link rel="prefetch" href="/assets/index.html-5b2e54c5.js" as="script"><link rel="prefetch" href="/assets/index.html-d726af06.js" as="script"><link rel="prefetch" href="/assets/30天JavaScript挑战.html-61ce8184.js" as="script"><link rel="prefetch" href="/assets/高频 SQL 50 题（基础版）.html-d86bf7ad.js" as="script"><link rel="prefetch" href="/assets/多线程.html-131b6d43.js" as="script"><link rel="prefetch" href="/assets/noob-Rg-better.html-463d7599.js" as="script"><link rel="prefetch" href="/assets/noob-Rg.html-146cef3d.js" as="script"><link rel="prefetch" href="/assets/1、JavaScript基础语法笔记.html-924285eb.js" as="script"><link rel="prefetch" href="/assets/2、WebAPIs笔记.html-405195e8.js" as="script"><link rel="prefetch" href="/assets/3、JavaScript进阶.html-a5761b02.js" as="script"><link rel="prefetch" href="/assets/1、TypeScript语言简介.html-39f93efc.js" as="script"><link rel="prefetch" href="/assets/2、基本用法.html-49665184.js" as="script"><link rel="prefetch" href="/assets/3、any，unknown ，never 类型.html-95f6497a.js" as="script"><link rel="prefetch" href="/assets/4、系统类型.html-cb456222.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-815b7193.js" as="script"><link rel="prefetch" href="/assets/6、元祖.html-6856b43d.js" as="script"><link rel="prefetch" href="/assets/7、symbol 类型.html-bd002696.js" as="script"><link rel="prefetch" href="/assets/8、函数.html-750f4ee3.js" as="script"><link rel="prefetch" href="/assets/index.html-43d4e42e.js" as="script"><link rel="prefetch" href="/assets/leetcode228_汇总区间.html-66394a10.js" as="script"><link rel="prefetch" href="/assets/leetcode_001_两数之和.html-48404e5e.js" as="script"><link rel="prefetch" href="/assets/leetcode_002_两数相加.html-95ff4c23.js" as="script"><link rel="prefetch" href="/assets/leetcode_003_无重复字符的最长子串.html-633f5e0e.js" as="script"><link rel="prefetch" href="/assets/leetcode_004_寻找两个正序数组的中位数.html-a6ea3f37.js" as="script"><link rel="prefetch" href="/assets/leetcode_005_最长回文子串.html-fcc3d542.js" as="script"><link rel="prefetch" href="/assets/leetcode_006_N 字形变换.html-364361f9.js" as="script"><link rel="prefetch" href="/assets/leetcode_007_整数反转.html-8bf81e83.js" as="script"><link rel="prefetch" href="/assets/leetcode_008_字符串转换整数 (atoi).html-7e48cb7c.js" as="script"><link rel="prefetch" href="/assets/leetcode_009_回文数.html-44ba7c2f.js" as="script"><link rel="prefetch" href="/assets/leetcode_010_正则表达式匹配.html-fa407a28.js" as="script"><link rel="prefetch" href="/assets/leetcode_011_盛最多水的容器.html-00d79d31.js" as="script"><link rel="prefetch" href="/assets/leetcode_012_整数转罗马数字.html-9df490b3.js" as="script"><link rel="prefetch" href="/assets/leetcode_013_罗马数字转整数.html-2a68181f.js" as="script"><link rel="prefetch" href="/assets/leetcode_014_最长公共前缀.html-bd8e562b.js" as="script"><link rel="prefetch" href="/assets/leetcode_015_三数之和.html-8df72d61.js" as="script"><link rel="prefetch" href="/assets/leetcode_016_最接近的三数之和.html-bb7f4321.js" as="script"><link rel="prefetch" href="/assets/leetcode_017_电话号码的字母组合.html-7bc2c3f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_018_四数之和.html-9686cda5.js" as="script"><link rel="prefetch" href="/assets/leetcode_019_删除链表的倒数第 N 个结点.html-5c32b510.js" as="script"><link rel="prefetch" href="/assets/leetcode_020_有效的括号.html-c9fe6590.js" as="script"><link rel="prefetch" href="/assets/leetcode_021_合并两个有序链表.html-6480cc33.js" as="script"><link rel="prefetch" href="/assets/leetcode_022_括号生成.html-9b945e78.js" as="script"><link rel="prefetch" href="/assets/leetcode_023_合并 K 个升序链表.html-d542ebc5.js" as="script"><link rel="prefetch" href="/assets/leetcode_024_两两交换链表中的节点.html-b2e7f2c5.js" as="script"><link rel="prefetch" href="/assets/leetcode_025_K 个一组翻转链表.html-a8cdc92d.js" as="script"><link rel="prefetch" href="/assets/leetcode_026_删除有序数组中的重复项.html-54a94b56.js" as="script"><link rel="prefetch" href="/assets/leetcode_027_移除元素.html-f02eb811.js" as="script"><link rel="prefetch" href="/assets/leetcode_028_找出字符串中第一个匹配项的下标.html-c0253673.js" as="script"><link rel="prefetch" href="/assets/leetcode_029_两数相除.html-2aec5784.js" as="script"><link rel="prefetch" href="/assets/leetcode_030_串联所有单词的子串.html-ef8515f2.js" as="script"><link rel="prefetch" href="/assets/leetcode_031_下一个排列.html-7cd7370d.js" as="script"><link rel="prefetch" href="/assets/leetcode_032_最长有效括号.html-ebcff32e.js" as="script"><link rel="prefetch" href="/assets/leetcode_033_搜索旋转排序数组.html-d79d1e43.js" as="script"><link rel="prefetch" href="/assets/leetcode_034_在排序数组中查找元素的第一个和最后一个位置.html-128635f5.js" as="script"><link rel="prefetch" href="/assets/leetcode_035_搜索插入位置.html-61bd38cd.js" as="script"><link rel="prefetch" href="/assets/leetcode_036_有效的数独.html-8fc9f2d4.js" as="script"><link rel="prefetch" href="/assets/leetcode_038_外观数列.html-a61876c6.js" as="script"><link rel="prefetch" href="/assets/leetcode_039_ 组合总和.html-b4c17a87.js" as="script"><link rel="prefetch" href="/assets/leetcode_040_ 组合总和II.html-a654e5ef.js" as="script"><link rel="prefetch" href="/assets/leetcode_041_ 缺失的第一个正数.html-35d49a1d.js" as="script"><link rel="prefetch" href="/assets/leetcode_042_接雨水.html-28819d8d.js" as="script"><link rel="prefetch" href="/assets/leetcode_043_字符串相乘.html-b7978b1b.js" as="script"><link rel="prefetch" href="/assets/leetcode_045_跳跃游戏II.html-4e75ed43.js" as="script"><link rel="prefetch" href="/assets/leetcode_046_全排列.html-a7876cbf.js" as="script"><link rel="prefetch" href="/assets/leetcode_047_全排列II.html-6e366c4b.js" as="script"><link rel="prefetch" href="/assets/leetcode_048_旋转图像.html-1f5e48e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_049_字母异位词分组.html-bf51ef32.js" as="script"><link rel="prefetch" href="/assets/leetcode_050_Pow(x_n).html-ac988b7b.js" as="script"><link rel="prefetch" href="/assets/leetcode_051_N 皇后.html-868b000c.js" as="script"><link rel="prefetch" href="/assets/leetcode_052_N 皇后 II.html-fcc6cfda.js" as="script"><link rel="prefetch" href="/assets/leetcode_053_最大子数组和.html-80fab97f.js" as="script"><link rel="prefetch" href="/assets/leetcode_054_螺旋矩阵.html-3bb6e2b2.js" as="script"><link rel="prefetch" href="/assets/leetcode_055_跳跃游戏.html-cda0eba4.js" as="script"><link rel="prefetch" href="/assets/leetcode_056_合并区间.html-d3ea265b.js" as="script"><link rel="prefetch" href="/assets/leetcode_058_最后一个单词的长度.html-f5af5367.js" as="script"><link rel="prefetch" href="/assets/leetcode_061_旋转链表.html-5e5d84b0.js" as="script"><link rel="prefetch" href="/assets/leetcode_062_不同路径.html-c08cc1a7.js" as="script"><link rel="prefetch" href="/assets/leetcode_063_不同路径II.html-d231e78c.js" as="script"><link rel="prefetch" href="/assets/leetcode_064_最小路径和.html-c75ac4bf.js" as="script"><link rel="prefetch" href="/assets/leetcode_066_加一.html-8534992e.js" as="script"><link rel="prefetch" href="/assets/leetcode_067_二进制求和.html-22dda40a.js" as="script"><link rel="prefetch" href="/assets/leetcode_068_文本左右对齐.html-05162dfc.js" as="script"><link rel="prefetch" href="/assets/leetcode_069_x的平方根.html-015a94a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_070_爬楼梯.html-a9375479.js" as="script"><link rel="prefetch" href="/assets/leetcode_072_编辑距离.html-f76810b4.js" as="script"><link rel="prefetch" href="/assets/leetcode_073_矩阵置零.html-5dbf8859.js" as="script"><link rel="prefetch" href="/assets/leetcode_075_颜色分类.html-35e36b6f.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串 copy.html-5d254c72.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串.html-5b41c4f8.js" as="script"><link rel="prefetch" href="/assets/leetcode_079_单词搜索.html-08d44ac9.js" as="script"><link rel="prefetch" href="/assets/leetcode_080_删除有序数组中的重复项.html-895fa371.js" as="script"><link rel="prefetch" href="/assets/leetcode_082_删除排序链表中的重复元素 II.html-ad4f0ee4.js" as="script"><link rel="prefetch" href="/assets/leetcode_083_删除排序链表中的重复元素.html-a90d7c1b.js" as="script"><link rel="prefetch" href="/assets/leetcode_086_分隔链表.html-f66f0eae.js" as="script"><link rel="prefetch" href="/assets/leetcode_088_合并两个有序数组.html-51c7bb12.js" as="script"><link rel="prefetch" href="/assets/leetcode_092_反转链表 II.html-125b4f3b.js" as="script"><link rel="prefetch" href="/assets/leetcode_094_二叉树的中序遍历.html-dd8a38f4.js" as="script"><link rel="prefetch" href="/assets/leetcode_095_不同的二叉搜索树 II.html-2514fbf1.js" as="script"><link rel="prefetch" href="/assets/leetcode_096_不同的二叉搜索树.html-ed5f33ee.js" as="script"><link rel="prefetch" href="/assets/leetcode_098_验证二叉搜索树.html-ae0d38d7.js" as="script"><link rel="prefetch" href="/assets/leetcode_1004_最大连续1的个数 III.html-ddd9c192.js" as="script"><link rel="prefetch" href="/assets/leetcode_100_相同的树.html-beb23327.js" as="script"><link rel="prefetch" href="/assets/leetcode_101_对称二叉树.html-8acb36c7.js" as="script"><link rel="prefetch" href="/assets/leetcode_102_二叉树的层序遍历.html-cf96560a.js" as="script"><link rel="prefetch" href="/assets/leetcode_103_二叉树的锯齿形层序遍历.html-e70780f4.js" as="script"><link rel="prefetch" href="/assets/leetcode_104_二叉树的最大深度.html-5b55b4e2.js" as="script"><link rel="prefetch" href="/assets/leetcode_105_从前序与中序遍历序列构造二叉树.html-36c34bdc.js" as="script"><link rel="prefetch" href="/assets/leetcode_106_从中序与后序遍历序列构造二叉树.html-f590a44e.js" as="script"><link rel="prefetch" href="/assets/leetcode_1071_字符串的最大公因子.html-c163ffad.js" as="script"><link rel="prefetch" href="/assets/leetcode_107_二叉树的层序遍历 II.html-489cec97.js" as="script"><link rel="prefetch" href="/assets/leetcode_108_将有序数组转换为二叉搜索树.html-73ab8883.js" as="script"><link rel="prefetch" href="/assets/leetcode_112_路径总和.html-2862905a.js" as="script"><link rel="prefetch" href="/assets/leetcode_113_路径总和II.html-f54905d9.js" as="script"><link rel="prefetch" href="/assets/leetcode_1143_最长公共子序列.html-1b57b9c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_114_二叉树展开为链表.html-2af2ada8.js" as="script"><link rel="prefetch" href="/assets/leetcode_1161_最大层内元素和.html-30a821c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_117_填充每个节点的下一个右侧节点指针 II.html-0e3f06c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_118_杨辉三角.html-224e1f20.js" as="script"><link rel="prefetch" href="/assets/leetcode_119_杨辉三角 II.html-20d9298d.js" as="script"><link rel="prefetch" href="/assets/leetcode_1207_独一无二的出现次数.html-def48656.js" as="script"><link rel="prefetch" href="/assets/leetcode_120_三角形最小路径和.html-587b51e4.js" as="script"><link rel="prefetch" href="/assets/leetcode_121_买卖股票的最佳时机 I.html-d07511c6.js" as="script"><link rel="prefetch" href="/assets/leetcode_122_买卖股票的最佳时机 II.html-3833b73f.js" as="script"><link rel="prefetch" href="/assets/leetcode_124_二叉树中的最大路径和.html-b56b0558.js" as="script"><link rel="prefetch" href="/assets/leetcode_125_验证回文串.html-46a65a01.js" as="script"><link rel="prefetch" href="/assets/leetcode_128_最长连续序列.html-55dcba78.js" as="script"><link rel="prefetch" href="/assets/leetcode_129_求根节点到叶节点数字之和.html-df04c9aa.js" as="script"><link rel="prefetch" href="/assets/leetcode_130_被围绕的区域.html-dd27f5c5.js" as="script"><link rel="prefetch" href="/assets/leetcode_1318_或运算的最小翻转次数.html-d5056c96.js" as="script"><link rel="prefetch" href="/assets/leetcode_134_加油站.html-9bb902c6.js" as="script"><link rel="prefetch" href="/assets/leetcode_135_分发糖果.html-e238205a.js" as="script"><link rel="prefetch" href="/assets/leetcode_136_只出现一次的数字.html-f19726bd.js" as="script"><link rel="prefetch" href="/assets/leetcode_1372_二叉树中的最长交错路径.html-fff488a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_139_单词拆分.html-56cf2f82.js" as="script"><link rel="prefetch" href="/assets/leetcode_141_环形链表.html-6d4c217c.js" as="script"><link rel="prefetch" href="/assets/leetcode_1431_拥有最多糖果的孩子.html-4ade469a.js" as="script"><link rel="prefetch" href="/assets/leetcode_1448_统计二叉树中好节点的数目.html-5fa541c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_144_二叉树的前序遍历.html-7e6ff5da.js" as="script"><link rel="prefetch" href="/assets/leetcode_1456_定长子串中元音的最大数目.html-cb7f23da.js" as="script"><link rel="prefetch" href="/assets/leetcode_145_二叉树的后序遍历.html-f41b923c.js" as="script"><link rel="prefetch" href="/assets/leetcode_1466_重新规划路线.html-b2b153e6.js" as="script"><link rel="prefetch" href="/assets/leetcode_146_LRU 缓存.html-bfddcc71.js" as="script"><link rel="prefetch" href="/assets/leetcode_148_排序链表.html-565073a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_1493_删掉一个元素以后全为 1 的最长子数组.html-156978d0.js" as="script"><link rel="prefetch" href="/assets/leetcode_150_逆波兰表达式求值.html-e9a5f16a.js" as="script"><link rel="prefetch" href="/assets/leetcode_151_反转字符串中的单词.html-79049ebd.js" as="script"><link rel="prefetch" href="/assets/leetcode_155_最小栈.html-879a220d.js" as="script"><link rel="prefetch" href="/assets/leetcode_160_相交链表.html-ee41b4cf.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值 copy.html-c723a195.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值.html-30d05b93.js" as="script"><link rel="prefetch" href="/assets/leetcode_1657_确定两个字符串是否接近.html-94644a38.js" as="script"><link rel="prefetch" href="/assets/leetcode_1679_K 和数对的最大数目.html-914474f7.js" as="script"><link rel="prefetch" href="/assets/leetcode_169_多数元素.html-35851fb7.js" as="script"><link rel="prefetch" href="/assets/leetcode_1732_找到最高海拔.html-060877e4.js" as="script"><link rel="prefetch" href="/assets/leetcode_173_二叉搜索树迭代器.html-b3a81ea3.js" as="script"><link rel="prefetch" href="/assets/leetcode_1768_交替合并字符串.html-2c30425a.js" as="script"><link rel="prefetch" href="/assets/leetcode_189_轮转数组.html-093f1936.js" as="script"><link rel="prefetch" href="/assets/leetcode_1926_迷宫中离入口最近的出口.html-62bc2992.js" as="script"><link rel="prefetch" href="/assets/leetcode_198_打家劫舍.html-d0b975c5.js" as="script"><link rel="prefetch" href="/assets/leetcode_199. 二叉树的右视图.html-e2daf034.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数 copy.html-10882c27.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数.html-3b0dd525.js" as="script"><link rel="prefetch" href="/assets/leetcode_203_移除链表元素.html-085398a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_206_反转链表.html-ce33f43e.js" as="script"><link rel="prefetch" href="/assets/leetcode_208_实现 Trie (前缀树).html-fd4b730b.js" as="script"><link rel="prefetch" href="/assets/leetcode_2095_删除链表的中间节点.html-c3c6b779.js" as="script"><link rel="prefetch" href="/assets/leetcode_209_长度最小的子数组.html-e0811028.js" as="script"><link rel="prefetch" href="/assets/leetcode_2130_链表最大孪生和.html-e819b34c.js" as="script"><link rel="prefetch" href="/assets/leetcode_215_数组中的第K个最大元素.html-87f4dd79.js" as="script"><link rel="prefetch" href="/assets/leetcode_216_组合总和 III.html-f45ae1a4.js" as="script"><link rel="prefetch" href="/assets/leetcode_219_存在重复元素 II.html-ad817c6f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2215_找出两数组的不同.html-4eb1f478.js" as="script"><link rel="prefetch" href="/assets/leetcode_222_完全二叉树的节点个数.html-00036712.js" as="script"><link rel="prefetch" href="/assets/leetcode_226_翻转二叉树.html-690d6292.js" as="script"><link rel="prefetch" href="/assets/leetcode_2300. 咒语和药水的成功对数.html-bfcb78cf.js" as="script"><link rel="prefetch" href="/assets/leetcode_230_二叉搜索树中第K小的元素.html-d38e72cd.js" as="script"><link rel="prefetch" href="/assets/leetcode_2336_无限集中的最小数字.html-f376b605.js" as="script"><link rel="prefetch" href="/assets/leetcode_234_回文链表.html-04f8e6d8.js" as="script"><link rel="prefetch" href="/assets/leetcode_2352_相等行列对.html-a9d3a058.js" as="script"><link rel="prefetch" href="/assets/leetcode_236_二叉树的最近公共祖先.html-78ed1707.js" as="script"><link rel="prefetch" href="/assets/leetcode_238_除自身以外数组的乘积.html-7aff9648.js" as="script"><link rel="prefetch" href="/assets/leetcode_2390_从字符串中移除星号.html-a664a62e.js" as="script"><link rel="prefetch" href="/assets/leetcode_242_有效的字母异位词.html-32af036c.js" as="script"><link rel="prefetch" href="/assets/leetcode_2542_最大序列的分数.html-39781fae.js" as="script"><link rel="prefetch" href="/assets/leetcode_274_H指数.html-7aaf6330.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy 2.html-afd1d7ce.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy.html-caf55dc2.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0.html-c5813f89.js" as="script"><link rel="prefetch" href="/assets/leetcode_300_最长递增子序列.html-a3ecf3bc.js" as="script"><link rel="prefetch" href="/assets/leetcode_322_零钱兑换.html-da284817.js" as="script"><link rel="prefetch" href="/assets/leetcode_328_奇偶链表.html-7bbd8e80.js" as="script"><link rel="prefetch" href="/assets/leetcode_334_递增的三元子序列.html-376bf6cc.js" as="script"><link rel="prefetch" href="/assets/leetcode_338_比特位计数.html-24e87682.js" as="script"><link rel="prefetch" href="/assets/leetcode_345_反转字符串中的元音字母.html-9563bde8.js" as="script"><link rel="prefetch" href="/assets/leetcode_374_猜数字大小.html-b6214fa2.js" as="script"><link rel="prefetch" href="/assets/leetcode_380_O(1) 时间插入、删除和获取随机元素.html-a086bd83.js" as="script"><link rel="prefetch" href="/assets/leetcode_383_赎金信.html-86e241f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_392_判断子序列.html-492b75fd.js" as="script"><link rel="prefetch" href="/assets/leetcode_394_字符串解码.html-15440c68.js" as="script"><link rel="prefetch" href="/assets/leetcode_435_无重叠区间.html-a3b6cc3f.js" as="script"><link rel="prefetch" href="/assets/leetcode_437_路径总和 III.html-52582e53.js" as="script"><link rel="prefetch" href="/assets/leetcode_443_压缩字符串.html-ccd6fcce.js" as="script"><link rel="prefetch" href="/assets/leetcode_450_删除二叉搜索树中的节点.html-5f6f2f55.js" as="script"><link rel="prefetch" href="/assets/leetcode_452_用最少数量的箭引爆气球.html-7dcb9245.js" as="script"><link rel="prefetch" href="/assets/leetcode_530_二叉搜索树的最小绝对差.html-cddb0b14.js" as="script"><link rel="prefetch" href="/assets/leetcode_547_省份数量.html-b599ab26.js" as="script"><link rel="prefetch" href="/assets/leetcode_605_种花问题.html-461d6d87.js" as="script"><link rel="prefetch" href="/assets/leetcode_637_二叉树的层平均值.html-ace1b559.js" as="script"><link rel="prefetch" href="/assets/leetcode_643_子数组最大平均数 I.html-04596c38.js" as="script"><link rel="prefetch" href="/assets/leetcode_649_Dota2 参议院.html-510ae6d5.js" as="script"><link rel="prefetch" href="/assets/leetcode_700_二叉搜索树中的搜索.html-ef0eee80.js" as="script"><link rel="prefetch" href="/assets/leetcode_714_买卖股票的最佳时机含手续费.html-1509368d.js" as="script"><link rel="prefetch" href="/assets/leetcode_724_寻找数组的中心下标.html-c2a6f9d1.js" as="script"><link rel="prefetch" href="/assets/leetcode_735_行星碰撞.html-771b95ae.js" as="script"><link rel="prefetch" href="/assets/leetcode_739_每日温度.html-31a58e33.js" as="script"><link rel="prefetch" href="/assets/leetcode_746_使用最小花费爬楼梯.html-9cfbd9a4.js" as="script"><link rel="prefetch" href="/assets/leetcode_790_多米诺和托米诺平铺.html-056ba1e5.js" as="script"><link rel="prefetch" href="/assets/leetcode_841_钥匙和房间.html-7200b4ca.js" as="script"><link rel="prefetch" href="/assets/leetcode_872_叶子相似的树.html-c93385ee.js" as="script"><link rel="prefetch" href="/assets/leetcode_875_爱吃香蕉的珂珂.html-4e207b3d.js" as="script"><link rel="prefetch" href="/assets/leetcode_876_链表的中间结点.html-6c23f74b.js" as="script"><link rel="prefetch" href="/assets/leetcode_901_股票价格跨度.html-402bd83e.js" as="script"><link rel="prefetch" href="/assets/leetcode_933_最近的请求次数.html-09ad0253.js" as="script"><link rel="prefetch" href="/assets/leetcode_994_腐烂的橘子.html-2050566c.js" as="script"><link rel="prefetch" href="/assets/leetcode_LCP68_美丽的花束.html-61dc8a04.js" as="script"><link rel="prefetch" href="/assets/Arrays类.html-ae9691b8.js" as="script"><link rel="prefetch" href="/assets/BigInteger和BigDecimal.html-9b31a391.js" as="script"><link rel="prefetch" href="/assets/Collections类.html-9fee2836.js" as="script"><link rel="prefetch" href="/assets/Java比较器.html-d6a4d221.js" as="script"><link rel="prefetch" href="/assets/Math类.html-2855eafa.js" as="script"><link rel="prefetch" href="/assets/Object类.html-a7d03712.js" as="script"><link rel="prefetch" href="/assets/Pattern 与 Matcher 类.html-37814861.js" as="script"><link rel="prefetch" href="/assets/Stream API.html-35ccb8dc.js" as="script"><link rel="prefetch" href="/assets/String、Scanner相关类.html-4d693496.js" as="script"><link rel="prefetch" href="/assets/System类.html-51f6191b.js" as="script"><link rel="prefetch" href="/assets/日期时间API.html-5c1f7ef9.js" as="script"><link rel="prefetch" href="/assets/10、多线程.html-eef55822.js" as="script"><link rel="prefetch" href="/assets/11、枚举类.html-99a2fe3d.js" as="script"><link rel="prefetch" href="/assets/12、注解.html-c59491b8.js" as="script"><link rel="prefetch" href="/assets/13、集合.html-1712ac67.js" as="script"><link rel="prefetch" href="/assets/14、泛型.html-cbbd926c.js" as="script"><link rel="prefetch" href="/assets/15、IO流.html-dbfaa3c2.js" as="script"><link rel="prefetch" href="/assets/16、网络编程.html-9dd9ddff.js" as="script"><link rel="prefetch" href="/assets/17、反射.html-64a46bb2.js" as="script"><link rel="prefetch" href="/assets/18、新特性.html-0c93caa6.js" as="script"><link rel="prefetch" href="/assets/19、格式化输入输出.html-d44b93b5.js" as="script"><link rel="prefetch" href="/assets/1、基础概念.html-4641c1ea.js" as="script"><link rel="prefetch" href="/assets/2、数据类型.html-20dc9690.js" as="script"><link rel="prefetch" href="/assets/3、运算符.html-5af0f3ea.js" as="script"><link rel="prefetch" href="/assets/4、程序流程控制.html-87f0f722.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-a3bcaa99.js" as="script"><link rel="prefetch" href="/assets/6、面向对象.html-ad49f67e.js" as="script"><link rel="prefetch" href="/assets/7、单元测试Junit.html-01b0b9db.js" as="script"><link rel="prefetch" href="/assets/8、包装类.html-05b71076.js" as="script"><link rel="prefetch" href="/assets/9、异常处理.html-8a8cecc1.js" as="script"><link rel="prefetch" href="/assets/基础概念.html-d7030e6a.js" as="script"><link rel="prefetch" href="/assets/网络架构.html-dcbbce0d.js" as="script"><link rel="prefetch" href="/assets/1、Pytorch 建模流程.html-00513ead.js" as="script"><link rel="prefetch" href="/assets/2、张量数据结构.html-a16924f5.js" as="script"><link rel="prefetch" href="/assets/3、自动微分机制、优化器.html-b9f89f8a.js" as="script"><link rel="prefetch" href="/assets/4、动态计算图.html-cdc33c40.js" as="script"><link rel="prefetch" href="/assets/6、Pytorch 中阶 API.html-896b54f3.js" as="script"><link rel="prefetch" href="/assets/7、构建、训练模型.html-ae72333c.js" as="script"><link rel="prefetch" href="/assets/Pytorch-20.html-2b71ba9d.js" as="script"><link rel="prefetch" href="/assets/Pytorch.html-b67f958f.js" as="script"><link rel="prefetch" href="/assets/强化学习.html-ef934022.js" as="script"><link rel="prefetch" href="/assets/Vue笔记1-核心.html-5fbf018b.js" as="script"><link rel="prefetch" href="/assets/Vue笔记2-组件.html-ae7f8c06.js" as="script"><link rel="prefetch" href="/assets/Vue笔记3-脚手架.html-bd6e160d.js" as="script"><link rel="prefetch" href="/assets/Vue笔记4-Vue中的ajax.html-5c8ce5c6.js" as="script"><link rel="prefetch" href="/assets/Vue笔记5-插槽.html-695c0422.js" as="script"><link rel="prefetch" href="/assets/Vue笔记6-vuex.html-cfa6a9b6.js" as="script"><link rel="prefetch" href="/assets/Vue笔记7-路由.html-fc00a814.js" as="script"><link rel="prefetch" href="/assets/Vue笔记8-element-ui.html-77e3364e.js" as="script"><link rel="prefetch" href="/assets/Vue3快速上手.html-b930def9.js" as="script"><link rel="prefetch" href="/assets/markdown扩展.html-040d3a78.js" as="script"><link rel="prefetch" href="/assets/404.html-e72ff613.js" as="script"><link rel="prefetch" href="/assets/index.html-39ac5b04.js" as="script"><link rel="prefetch" href="/assets/index.html-4b12afd1.js" as="script"><link rel="prefetch" href="/assets/index.html-f05769db.js" as="script"><link rel="prefetch" href="/assets/index.html-f947c8aa.js" as="script"><link rel="prefetch" href="/assets/index.html-808528c9.js" as="script"><link rel="prefetch" href="/assets/index.html-1ad24cb2.js" as="script"><link rel="prefetch" href="/assets/index.html-4ee32850.js" as="script"><link rel="prefetch" href="/assets/index.html-5335d11e.js" as="script"><link rel="prefetch" href="/assets/index.html-bdd56496.js" as="script"><link rel="prefetch" href="/assets/index.html-51440889.js" as="script"><link rel="prefetch" href="/assets/index.html-c753d9f8.js" as="script"><link rel="prefetch" href="/assets/index.html-9b07556a.js" as="script"><link rel="prefetch" href="/assets/index.html-dd60f182.js" as="script"><link rel="prefetch" href="/assets/index.html-051103f1.js" as="script"><link rel="prefetch" href="/assets/index.html-10e42db5.js" as="script"><link rel="prefetch" href="/assets/index.html-a9a0bd1c.js" as="script"><link rel="prefetch" href="/assets/index.html-31a53ef7.js" as="script"><link rel="prefetch" href="/assets/index.html-9a60f301.js" as="script"><link rel="prefetch" href="/assets/index.html-847b2220.js" as="script"><link rel="prefetch" href="/assets/index.html-dd1cc5e9.js" as="script"><link rel="prefetch" href="/assets/index.html-a5ef9756.js" as="script"><link rel="prefetch" href="/assets/index.html-42e72e3a.js" as="script"><link rel="prefetch" href="/assets/index.html-2e89081c.js" as="script"><link rel="prefetch" href="/assets/index.html-306247b1.js" as="script"><link rel="prefetch" href="/assets/index.html-3a23dfa4.js" as="script"><link rel="prefetch" href="/assets/index.html-ea24e8bd.js" as="script"><link rel="prefetch" href="/assets/index.html-ef17f585.js" as="script"><link rel="prefetch" href="/assets/index.html-ec75aa68.js" as="script"><link rel="prefetch" href="/assets/index.html-cdb6eb60.js" as="script"><link rel="prefetch" href="/assets/index.html-91cab678.js" as="script"><link rel="prefetch" href="/assets/index.html-f1722250.js" as="script"><link rel="prefetch" href="/assets/index.html-d3c17317.js" as="script"><link rel="prefetch" href="/assets/index.html-b8563d2f.js" as="script"><link rel="prefetch" href="/assets/index.html-59fd8c5f.js" as="script"><link rel="prefetch" href="/assets/index.html-2908448f.js" as="script"><link rel="prefetch" href="/assets/index.html-16292735.js" as="script"><link rel="prefetch" href="/assets/index.html-8bcff455.js" as="script"><link rel="prefetch" href="/assets/index.html-e9f5d087.js" as="script"><link rel="prefetch" href="/assets/index.html-392fd808.js" as="script"><link rel="prefetch" href="/assets/index.html-b62f5d79.js" as="script"><link rel="prefetch" href="/assets/index.html-c97e8a45.js" as="script"><link rel="prefetch" href="/assets/index.html-d3a90d74.js" as="script"><link rel="prefetch" href="/assets/index.html-fe8c4855.js" as="script"><link rel="prefetch" href="/assets/index.html-6aa2e4be.js" as="script"><link rel="prefetch" href="/assets/index.html-351e885f.js" as="script"><link rel="prefetch" href="/assets/index.html-684d61b8.js" as="script"><link rel="prefetch" href="/assets/index.html-22a20da7.js" as="script"><link rel="prefetch" href="/assets/index.html-20149c8a.js" as="script"><link rel="prefetch" href="/assets/index.html-e343046f.js" as="script"><link rel="prefetch" href="/assets/index.html-877918c0.js" as="script"><link rel="prefetch" href="/assets/index.html-3f9d6faa.js" as="script"><link rel="prefetch" href="/assets/index.html-ad015098.js" as="script"><link rel="prefetch" href="/assets/index.html-85189601.js" as="script"><link rel="prefetch" href="/assets/index.html-d93c21b0.js" as="script"><link rel="prefetch" href="/assets/index.html-41af28cc.js" as="script"><link rel="prefetch" href="/assets/index.html-8c38427c.js" as="script"><link rel="prefetch" href="/assets/index.html-4bce7daa.js" as="script"><link rel="prefetch" href="/assets/index.html-512bdbb0.js" as="script"><link rel="prefetch" href="/assets/index.html-1174807d.js" as="script"><link rel="prefetch" href="/assets/index.html-bd0e4c1a.js" as="script"><link rel="prefetch" href="/assets/index.html-a6c5c0fc.js" as="script"><link rel="prefetch" href="/assets/index.html-c65f5841.js" as="script"><link rel="prefetch" href="/assets/index.html-58b7f06d.js" as="script"><link rel="prefetch" href="/assets/index.html-77ef193b.js" as="script"><link rel="prefetch" href="/assets/index.html-fa9501c3.js" as="script"><link rel="prefetch" href="/assets/index.html-0b478f3a.js" as="script"><link rel="prefetch" href="/assets/index.html-2fe7ad9b.js" as="script"><link rel="prefetch" href="/assets/index.html-1e25faf2.js" as="script"><link rel="prefetch" href="/assets/index.html-2cb44102.js" as="script"><link rel="prefetch" href="/assets/index.html-f2c56083.js" as="script"><link rel="prefetch" href="/assets/index.html-a603d472.js" as="script"><link rel="prefetch" href="/assets/index.html-92561212.js" as="script"><link rel="prefetch" href="/assets/index.html-2ea2ea2a.js" as="script"><link rel="prefetch" href="/assets/index.html-87dad788.js" as="script"><link rel="prefetch" href="/assets/index.html-39c2f030.js" as="script"><link rel="prefetch" href="/assets/index.html-a0d808ac.js" as="script"><link rel="prefetch" href="/assets/index.html-5437471b.js" as="script"><link rel="prefetch" href="/assets/index.html-da95ec6d.js" as="script"><link rel="prefetch" href="/assets/index.html-beadacd6.js" as="script"><link rel="prefetch" href="/assets/index.html-9648b47e.js" as="script"><link rel="prefetch" href="/assets/index.html-25b7cf6a.js" as="script"><link rel="prefetch" href="/assets/index.html-f211084f.js" as="script"><link rel="prefetch" href="/assets/index.html-e5cfba46.js" as="script"><link rel="prefetch" href="/assets/index.html-c08b7928.js" as="script"><link rel="prefetch" href="/assets/index.html-a35d36e0.js" as="script"><link rel="prefetch" href="/assets/index.html-3f26aa21.js" as="script"><link rel="prefetch" href="/assets/index.html-83261843.js" as="script"><link rel="prefetch" href="/assets/index.html-87b64486.js" as="script"><link rel="prefetch" href="/assets/index.html-d630ae7c.js" as="script"><link rel="prefetch" href="/assets/index.html-ee4d89ed.js" as="script"><link rel="prefetch" href="/assets/index.html-0ed80e28.js" as="script"><link rel="prefetch" href="/assets/index.html-b6d9b6ef.js" as="script"><link rel="prefetch" href="/assets/index.html-6bf50dc0.js" as="script"><link rel="prefetch" href="/assets/index.html-e0fcc17a.js" as="script"><link rel="prefetch" href="/assets/index.html-b4e04be3.js" as="script"><link rel="prefetch" href="/assets/index.html-ab30bc31.js" as="script"><link rel="prefetch" href="/assets/index.html-42d07447.js" as="script"><link rel="prefetch" href="/assets/index.html-7dac0150.js" as="script"><link rel="prefetch" href="/assets/index.html-54eaf23a.js" as="script"><link rel="prefetch" href="/assets/index.html-b72796ee.js" as="script"><link rel="prefetch" href="/assets/index.html-04376901.js" as="script"><link rel="prefetch" href="/assets/index.html-a14777f6.js" as="script"><link rel="prefetch" href="/assets/index.html-0bc1078d.js" as="script"><link rel="prefetch" href="/assets/index.html-32ea41c5.js" as="script"><link rel="prefetch" href="/assets/index.html-3a145eee.js" as="script"><link rel="prefetch" href="/assets/index.html-06d8d3f3.js" as="script"><link rel="prefetch" href="/assets/index.html-5ecb607d.js" as="script"><link rel="prefetch" href="/assets/index.html-2fcfb2ba.js" as="script"><link rel="prefetch" href="/assets/index.html-fe9c9f64.js" as="script"><link rel="prefetch" href="/assets/index.html-36d1511b.js" as="script"><link rel="prefetch" href="/assets/index.html-5eb24f9b.js" as="script"><link rel="prefetch" href="/assets/index.html-44fde3ae.js" as="script"><link rel="prefetch" href="/assets/index.html-b42153ba.js" as="script"><link rel="prefetch" href="/assets/index.html-042f5e43.js" as="script"><link rel="prefetch" href="/assets/index.html-d68921a9.js" as="script"><link rel="prefetch" href="/assets/index.html-a3ca8e28.js" as="script"><link rel="prefetch" href="/assets/index.html-6fa6264f.js" as="script"><link rel="prefetch" href="/assets/index.html-1095429f.js" as="script"><link rel="prefetch" href="/assets/index.html-9bcefb64.js" as="script"><link rel="prefetch" href="/assets/index.html-7cdee798.js" as="script"><link rel="prefetch" href="/assets/index.html-ab7ca388.js" as="script"><link rel="prefetch" href="/assets/index.html-7116bce1.js" as="script"><link rel="prefetch" href="/assets/index.html-8ebb914f.js" as="script"><link rel="prefetch" href="/assets/index.html-3eaa970f.js" as="script"><link rel="prefetch" href="/assets/index.html-926e2109.js" as="script"><link rel="prefetch" href="/assets/index.html-365ce0b9.js" as="script"><link rel="prefetch" href="/assets/index.html-738e2508.js" as="script"><link rel="prefetch" href="/assets/index.html-276cc368.js" as="script"><link rel="prefetch" href="/assets/index.html-5558d5c3.js" as="script"><link rel="prefetch" href="/assets/index.html-7f4eb100.js" as="script"><link rel="prefetch" href="/assets/index.html-52a447fa.js" as="script"><link rel="prefetch" href="/assets/waline-meta-56fbc549.js" as="script"><link rel="prefetch" href="/assets/component-ab817c58.js" as="script"><link rel="prefetch" href="/assets/auto-fa8841cf.js" as="script"><link rel="prefetch" href="/assets/index-a7d1ee58.js" as="script"><link rel="prefetch" href="/assets/flowchart-c441f34d.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-2cc6e90f.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-abe06b83.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-ec5549c1.js" as="script"><link rel="prefetch" href="/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-d69f552f.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-5794cde2.js" as="script"><link rel="prefetch" href="/assets/pageview-45b07261.js" as="script"><link rel="prefetch" href="/assets/style-e9220a04.js" as="script"><link rel="prefetch" href="/assets/docsearch-1d421ddb.js" as="script"><link rel="prefetch" href="/assets/index-5161ad19.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand" href="/"><img class="vp-nav-logo" src="/favicon.ico" alt="T4mako"><!----><span class="vp-site-name hide-in-pad">T4mako</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a class="vp-link nav-link" href="/"><span class="font-icon icon iconfont icon-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="代码笔记"><span class="title"><span class="font-icon icon iconfont icon-code" style=""></span>代码笔记</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html"><!---->基础知识<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/java.html"><!---->Java<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91.html"><!---->前端开发<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/数据库.html"><!---->数据库<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E8%BF%90%E7%BB%B4%E4%B8%8E%E9%83%A8%E7%BD%B2.html"><!---->运维与部署<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link active" href="/code/python.html"><!---->Python<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/leetcode.html"><!---->Leetcode<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/project.html"><!---->项目笔记<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/其他.html"><!---->其他<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="兴趣使然"><span class="title"><span class="font-icon icon iconfont icon-view" style=""></span>兴趣使然</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/AE.html"><!---->AE<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/Blender.html"><!---->Blender<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/HLAE.html"><!---->HLAE<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/cook.html"><!---->吃饭糊弄学<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="生活碎片"><span class="title"><span class="font-icon icon iconfont icon-note" style=""></span>生活碎片</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/life/随笔.html"><!---->随笔<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/life/%E8%A7%82%E5%BD%B1%E5%8C%BA.html"><!---->观影区<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><a class="vp-link nav-link" href="/friends.html"><span class="font-icon icon iconfont icon-group" style=""></span>友链<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/T4mako/T4mako.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->5、Pytorch 低阶 API</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/T4mako/T4mako.github.io" target="_blank" rel="noopener noreferrer">T4mako</a></span><span property="author" content="T4mako"></span></span><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 26 分钟</span><meta property="timeRequired" content="PT26M"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_5-1、张量结构操作">5.1、张量结构操作</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#创建张量">创建张量</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#索引切片">索引切片</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#维度变换">维度变换</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#合并分割">合并分割</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_5-2、数学运算">5.2、数学运算</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#标量运算">标量运算</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#向量运算">向量运算</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#矩阵运算">矩阵运算</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#广播机制">广播机制</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_5-3、nn-functional-和-nn-module">5.3、nn.functional 和 nn.Module</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#简介">简介</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#使用-nn-module-来管理参数-配合-nn-parameter-使用">使用 nn.Module 来管理参数(配合 nn.Parameter 使用)</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#使用-nn-module-来管理子模块">使用 nn.Module 来管理子模块</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><p>Pytorch 中 5 个不同的层次结构：</p><ul><li>硬件层：Pytorch 支持 CPU、GPU 加入计算资源池</li><li>内核层：C++ 实现的内核</li><li>低阶 API：Python 实现的操作符，提供了封装 C++ 内核的低级 API 指令，主要包括各种张量操作算子、自动微分、变量管理</li><li>中阶 API：Python 实现的模型组件，对低级API进行了函数封装，主要包括各种模型层，损失函数，优化器，数据管道等等</li><li>高阶 API：Python 实现的模型接口。Pytorch 没有官方的高阶API。为了便于训练模型，作者仿照 keras 中的模型接口，封装了 pytorch 的高阶模型接口 torchkeras.KerasModel。此外，有一个非常流行的非官方 Pytorch 的高阶 API 库，叫做 pytorch_lightning，作者通过引用和借鉴它的一些能力，设计了一个和 torchkeras.KerasModel 功能类似的高阶模型接口 torchkeras.LightModel，功能更加强大。</li></ul><h1 id="_5、pytorch-低阶-api" tabindex="-1"><a class="header-anchor" href="#_5、pytorch-低阶-api" aria-hidden="true">#</a> 5、Pytorch 低阶 API</h1><p>低阶 API 主要包括 <strong>张量操作</strong>，<strong>计算图</strong> 和 <strong>自动微分</strong></p><h2 id="_5-1、张量结构操作" tabindex="-1"><a class="header-anchor" href="#_5-1、张量结构操作" aria-hidden="true">#</a> 5.1、张量结构操作</h2><p>张量结构操作主要包括：张量创建，索引切片，维度变换，合并分割。</p><h3 id="创建张量" tabindex="-1"><a class="header-anchor" href="#创建张量" aria-hidden="true">#</a> 创建张量</h3><p>张量创建的许多方法和 numpy 中创建 array 的方法很像</p><table><thead><tr><th>方法签名</th><th>方法解释</th></tr></thead><tbody><tr><td><code>torch.tensor(data)</code></td><td>直接从数据（如列表、numpy数组等）创建张量，数据类型由传入数据推断。</td></tr><tr><td><code>torch.empty(size)</code></td><td>创建一个未初始化的张量。仅分配内存，不进行初始化。</td></tr><tr><td><code>torch.zeros(size)</code></td><td>创建一个全为0的张量。</td></tr><tr><td><code>torch.ones(size)</code></td><td>创建一个全为1的张量。</td></tr><tr><td><code>torch.full(size, fill_value)</code></td><td>创建一个填充指定值的张量。</td></tr><tr><td><code>torch.arange(start, end, step)</code></td><td>创建一个从start到end（不包含end），步长为step的1维张量。</td></tr><tr><td><code>torch.linspace(start, end, steps)</code></td><td>创建一个从start到end（包含end），包含steps个等间隔值的1维张量。</td></tr><tr><td><code>torch.eye(n)</code></td><td>创建一个n x n的单位矩阵（对角线为1，其余为0）。</td></tr><tr><td><code>torch.rand(size)</code></td><td>创建一个在区间[0, 1)上均匀分布的随机值张量。</td></tr><tr><td><code>torch.randn(size)</code></td><td>创建一个从标准正态分布中抽取的随机值张量。</td></tr><tr><td><code>torch.randint(low, high, size)</code></td><td>创建一个在区间[low, high)上均匀分布的随机整数张量。</td></tr><tr><td><code>torch.randperm(n)</code></td><td>生成一个0到n-1的随机排列。</td></tr><tr><td><code>torch.from_numpy(ndarray)</code></td><td>从一个numpy数组创建张量。张量和数组共享内存，修改一个会改变另一个。</td></tr><tr><td><code>torch.as_tensor(data)</code></td><td>将数据转换为张量，如果数据已经是张量或numpy数组则不会进行复制。</td></tr><tr><td><code>torch.clone(tensor)</code></td><td>复制一个张量，并创建一个新张量。</td></tr><tr><td><code>torch.zeros_like(tensor)</code></td><td>创建一个形状和dtype与给定张量相同，但全为0的张量。</td></tr><tr><td><code>torch.ones_like(tensor)</code></td><td>创建一个形状和dtype与给定张量相同，但全为1的张量。</td></tr><tr><td><code>torch.full_like(tensor, fill_value)</code></td><td>创建一个形状和dtype与给定张量相同，但填充指定值的张量。</td></tr></tbody></table><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch 

a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span> <span class="token comment"># tensor([1., 2., 3.])</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># tensor([1, 3, 5, 7, 9])</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">3.14</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># tensor([0.0000, 0.6978, 1.3956, 2.0933, 2.7911, 3.4889, 4.1867, 4.8844, 5.5822,6.2800])</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
&#39;&#39;&#39;</span>
d <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[1, 1, 1],
        [1, 1, 1],
        [1, 1, 1]], dtype=torch.int32)
&#39;&#39;&#39;</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
&#39;&#39;&#39;</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>a<span class="token punctuation">,</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[5., 5., 5.],
        [5., 5., 5.],
        [5., 5., 5.]])
&#39;&#39;&#39;</span>
torch<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># 均匀随机分布</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
minval<span class="token punctuation">,</span>maxval <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span>
a <span class="token operator">=</span> minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># tensor([4.9626, 7.6822, 0.8848, 1.3203, 3.0742])</span>

<span class="token comment"># 正态分布随机</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[ 0.5507,  0.2704,  0.6472],
        [ 0.2490, -0.3354,  0.4564],
        [-0.6255,  0.4539, -1.3740]])
&#39;&#39;&#39;</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 正态分布随机</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[16.2371, -1.6612,  3.9163],
        [ 7.4999,  1.5616,  4.0768],
        [ 5.2128, -8.9407,  6.4601]])
&#39;&#39;&#39;</span>
mean<span class="token punctuation">,</span>std <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span>
c <span class="token operator">=</span> std <span class="token operator">*</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> mean

<span class="token comment"># 整数随机排列</span>
d <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span> <span class="token comment"># tensor([ 3, 17,  9, 19,  1, 18,  4, 13, 15, 12,  0, 16,  7, 11,  2,  5,  8, 10, 6, 14])</span>

<span class="token comment"># 特殊矩阵</span>
I <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment">#单位矩阵</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>I<span class="token punctuation">)</span>
t <span class="token operator">=</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#对角矩阵</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="索引切片" tabindex="-1"><a class="header-anchor" href="#索引切片" aria-hidden="true">#</a> 索引切片</h3><p>张量的索引切片方式和 numpy 几乎是一样的。切片时支持缺省参数和省略号</p><p>可以通过索引和切片对部分元素进行修改。</p><p>此外，对于不规则的切片提取,可以使用 <code>torch.index_select</code>, <code>torch.masked_select</code>, <code>torch.take</code></p><p>如果要通过修改张量的某些元素得到新的张量，可以使用 <code>torch.where</code>，<code>torch.masked_fill</code>，<code>torch.index_fill</code></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 均匀随机分布</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
minval<span class="token punctuation">,</span>maxval <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span>
t <span class="token operator">=</span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[4, 7, 0, 1, 3],
        [6, 4, 8, 4, 6],
        [3, 4, 0, 1, 2],
        [5, 6, 8, 1, 2],
        [6, 9, 3, 8, 4]], dtype=torch.int32)
&#39;&#39;&#39;</span>
<span class="token comment"># 第 0 行</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># tensor([4, 7, 0, 1, 3], dtype=torch.int32)</span>
<span class="token comment"># 第 1 行第 3 列</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># tensor(4, dtype=torch.int32)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># tensor(4, dtype=torch.int32)</span>
<span class="token comment"># 第 1 行至第 3 行</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 第 1 行至最后一行，第0列到最后一列每隔两列取一列</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#可以使用索引和切片修改部分元素</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[1., 2.],[0., 0.]])</span>
<span class="token comment"># 省略号可以表示多个冒号</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上切片方式相对规则，对于不规则的切片提取,可以使用 torch.index_select, torch.take, torch.gather, torch.masked_select.</p><p>考虑班级成绩册的例子，有 4 个班级，每个班级 5 个学生，每个学生 7 门科目成绩。可以用一个 4×5×7 的张量来表示。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>minval<span class="token operator">=</span><span class="token number">0</span>
maxval<span class="token operator">=</span><span class="token number">100</span>
scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 抽取每个班级第 0 个学生，第2个学生，第 4 个学生的全部成绩</span>
torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#抽取每个班级第 0 个学生，第 2 个学生，第 4 个学生的第 1 门课程，第 3 门课程，第 6 门课程成绩</span>
q <span class="token operator">=</span> torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                   <span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 抽取第 0 个班级第 0 个学生的第 0 门课程，第 2 个班级的第 3 个学生的第 1 门课程，第 3 个班级的第 4 个学生第 6 门课程成绩</span>
<span class="token comment"># take 将输入看成一维数组，输出和 index 同形状</span>
s <span class="token operator">=</span> torch<span class="token punctuation">.</span>take<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">5</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 抽取分数大于等于 80 分的分数（布尔索引）</span>
<span class="token comment"># 结果是 1 维张量</span>
g <span class="token operator">=</span> torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>scores<span class="token operator">&gt;=</span><span class="token number">80</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。</p><p>如果要通过修改张量的部分元素值得到新的张量，可以使用 torch.where,torch.index_fill 和 torch.masked_fill</p><ul><li>torch.where 可以理解为 if 的张量版本</li><li>torch.index_fill 的选取元素逻辑和 torch.index_select 相同</li><li>torch.masked_fill 的选取元素逻辑和 torch.masked_select 相同。</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 如果分数大于60分，赋值成1，否则赋值成0</span>
ifpass <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>scores<span class="token operator">&gt;</span><span class="token number">60</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 将每个班级第 0 个学生，第 2 个学生，第 4 个学生的全部成绩赋值成满分</span>
torch<span class="token punctuation">.</span>index_fill<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>value <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span>
<span class="token comment"># 等价于 scores.index_fill(dim = 1,index = torch.tensor([0,2,4]),value = 100)</span>

<span class="token comment"># 将分数小于 60 分的分数赋值成 60 分</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>scores<span class="token operator">&lt;</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token number">60</span><span class="token punctuation">)</span>
<span class="token comment"># 等价于 b = scores.masked_fill(scores&lt;60,60)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="维度变换" tabindex="-1"><a class="header-anchor" href="#维度变换" aria-hidden="true">#</a> 维度变换</h3><p>维度变换相关函数主要有 torch.reshape(或者调用张量的 view 方法), torch.squeeze, torch.unsqueeze, torch.transpose</p><ul><li>torch.reshape 可以改变张量的形状</li><li>torch.reshape 可以改变张量的形状</li><li>torch.unsqueeze 可以增加维度</li><li>torch.transpose/torch.permute 可以交换维度</li></ul><table><thead><tr><th>方法签名</th><th>方法解释</th></tr></thead><tbody><tr><td><code>tensor.view(*shape)</code></td><td>返回一个新张量，具有相同数据但不同形状。</td></tr><tr><td><code>tensor.reshape(*shape)</code></td><td>返回一个新张量，具有相同数据但不同形状。与 <code>view</code> 类似，但更灵活</td></tr><tr><td><code>tensor.unsqueeze(dim)</code></td><td>在指定位置插入一个大小为1的新维度。</td></tr><tr><td><code>tensor.squeeze(dim=None)</code></td><td>删除大小为1的维度。如果 <code>dim</code> 指定，则只删除指定维度，否则删除所有大小为1的维度。</td></tr><tr><td><code>tensor.transpose(dim0, dim1)</code></td><td>交换两个维度。</td></tr><tr><td><code>tensor.permute(*dims)</code></td><td>根据指定顺序重新排列所有维度。</td></tr><tr><td><code>tensor.expand(*sizes)</code></td><td>返回一个新张量，将原张量的尺寸扩展到指定的尺寸。</td></tr><tr><td><code>tensor.expand_as(tensor)</code></td><td>返回一个新张量，将原张量的尺寸扩展到与指定张量相同的尺寸。</td></tr><tr><td><code>tensor.repeat(*sizes)</code></td><td>返回一个新张量，按指定次数重复原张量的数据。</td></tr></tbody></table><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 张量的 view 方法有时候会调用失败，可以使用reshape方法。</span>
torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
minval<span class="token punctuation">,</span>maxval <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span>
a <span class="token operator">=</span> <span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 原 tensor 改成 （3,6）形状的张量</span>
b <span class="token operator">=</span> a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># torch.reshape(a,[3,6])</span>
<span class="token comment"># 改回成 [1,3,3,2] 形状的张量</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># b.view([1,3,3,2]) </span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果张量在某个维度上只有一个元素，利用 torch.squeeze 可以消除这个维度</p><p>torch.unsqueeze 的作用和 torch.squeeze 的作用相反</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
s <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token comment"># tensor([[1., 2.]])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token comment"># tensor([1., 2.])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([1, 2])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([2])</span>

<span class="token comment">#在第 0 维插入长度为1的一个维度</span>
d <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>s<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token comment"># tensor([1., 2.])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span> <span class="token comment"># tensor([[1., 2.]])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([2])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([1, 2])</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>torch.transpose 可以交换张量的维度，torch.transpose 常用于图片存储格式的变换上。permute 可以对维度顺序做重新编排</p><p>如果是二维的矩阵，通常会调用矩阵的转置方法 matrix.t()，等价于 torch.transpose(matrix,0,1)。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>minval<span class="token operator">=</span><span class="token number">0</span>
maxval<span class="token operator">=</span><span class="token number">255</span>
<span class="token comment"># Batch,Height,Width,Channel</span>
data <span class="token operator">=</span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([100, 256, 256, 4])</span>

<span class="token comment"># 转换成 Pytorch 默认的图片格式 Batch,Channel,Height,Width </span>
<span class="token comment"># 需要交换两次</span>
data_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data_t<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([100, 4, 256, 256])</span>
data_p <span class="token operator">=</span> torch<span class="token punctuation">.</span>permute<span class="token punctuation">(</span>data<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#对维度的顺序做重新编排</span>
data_p<span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([100, 4, 256, 256])</span>

matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">)</span> <span class="token comment"># tensor([[1, 2, 3],[4, 5, 6]])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#等价于torch.transpose(matrix,0,1) # tensor([[1, 4],[2, 5],[3, 6]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="合并分割" tabindex="-1"><a class="header-anchor" href="#合并分割" aria-hidden="true">#</a> 合并分割</h3><table><thead><tr><th>方法签名</th><th>方法解释</th></tr></thead><tbody><tr><td><code>torch.cat(tensors, dim=0)</code></td><td>在指定维度上连接一系列张量。</td></tr><tr><td><code>torch.stack(tensors, dim=0)</code></td><td>在指定维度上堆叠一系列张量，创建一个新的维度。</td></tr><tr><td><code>torch.chunk(tensor, chunks, dim=0)</code></td><td>将张量沿指定维度分割成多个块。</td></tr><tr><td><code>torch.split(tensor, split_size, dim=0)</code></td><td>将张量沿指定维度按块大小分割。</td></tr><tr><td><code>torch.unbind(tensor, dim=0)</code></td><td>沿指定维度拆分张量，每个输出张量都会减少一个维度。</td></tr><tr><td><code>tensor.flatten(start_dim=0, end_dim=-1)</code></td><td>返回一个新张量，将输入张量从 <code>start_dim</code> 到 <code>end_dim</code> 展平。</td></tr><tr><td><code>tensor.T</code></td><td>返回转置张量，只适用于二维张量。</td></tr></tbody></table><p>以用 torch.cat 方法和 torch.stack 方法将多个张量合并，可以用 torch.split 方法把一个张量分割成多个张量。</p><p>torch.cat 和 torch.stack 有略微的区别，torch.cat 是连接，不会增加维度，而 torch.stack 是堆叠，会增加维度。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">7.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9.0</span><span class="token punctuation">,</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">11.0</span><span class="token punctuation">,</span><span class="token number">12.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

abc_cat <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>abc_cat<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([6, 2])</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[ 1.,  2.],
        [ 3.,  4.],
        [ 5.,  6.],
        [ 7.,  8.],
        [ 9., 10.],
        [11., 12.]])
&#39;&#39;&#39;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>abc_cat<span class="token punctuation">)</span>

abc_stack <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># torch 中 dim 和 axis 参数名可以混用</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>abc_stack<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># torch.Size([3, 2, 2])</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[[ 1.,  2.],
         [ 3.,  4.]],
        [[ 5.,  6.],
         [ 7.,  8.]],
        [[ 9., 10.],
         [11., 12.]]])
&#39;&#39;&#39;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>abc_stack<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[ 1.,  2.,  5.,  6.,  9., 10.],
        [ 3.,  4.,  7.,  8., 11., 12.]])
&#39;&#39;&#39;</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[[ 1.,  2.],
         [ 5.,  6.],
         [ 9., 10.]],
         
        [[ 3.,  4.],
         [ 7.,  8.],
         [11., 12.]]])
&#39;&#39;&#39;</span>
torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>torch.split 是 torch.cat 的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[ 1.,  2.],
        [ 3.,  4.],
        [ 5.,  6.],
        [ 7.,  8.],
        [ 9., 10.],
        [11., 12.]])
&#39;&#39;&#39;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>abc_cat<span class="token punctuation">)</span>
a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>abc_cat<span class="token punctuation">,</span>split_size_or_sections <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment">#每份2个进行分割</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token comment"># tensor([[1., 2.],[3., 4.]])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span> <span class="token comment"># tensor([[5., 6.],[7., 8.]])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token comment"># tensor([[ 9., 10.],[11., 12.]])</span>


p<span class="token punctuation">,</span>q<span class="token punctuation">,</span>r <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>abc_cat<span class="token punctuation">,</span>split_size_or_sections <span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment">#每份分别为[4,1,1]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token comment"># tensor([[1., 2.],[3., 4.],[5., 6.],[7., 8.]])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>q<span class="token punctuation">)</span> <span class="token comment"># tensor([[ 9., 10.]]) </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span> <span class="token comment"># tensor([[11., 12.]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_5-2、数学运算" tabindex="-1"><a class="header-anchor" href="#_5-2、数学运算" aria-hidden="true">#</a> 5.2、数学运算</h2><p>张量数学运算主要有：标量运算，向量运算，矩阵运算，以及使用非常强大而灵活的爱因斯坦求和函数 torch.einsum 进行任意维的张量运算</p><h3 id="标量运算" tabindex="-1"><a class="header-anchor" href="#标量运算" aria-hidden="true">#</a> 标量运算</h3><p>张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。</p><p>加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。</p><p>标量运算符的特点是对张量实施 <strong>逐元素</strong> 运算。</p><p>有些标量运算符对常用的数学运算符进行了重载。并且支持类似 numpy 的广播特性。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np 

a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">)</span>
a <span class="token operator">+</span> b <span class="token comment"># tensor(3.)</span>

a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">7.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a<span class="token operator">+</span>b  <span class="token comment"># 运算符重载 tensor([[ 6.,  8.],[ 4., 12.]])</span>
a<span class="token operator">-</span>b 
a<span class="token operator">*</span>b 
a<span class="token operator">/</span>b
a<span class="token operator">**</span><span class="token number">2</span>
a<span class="token operator">**</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span>
a<span class="token operator">%</span><span class="token number">3</span> <span class="token comment">#求模 # tensor([[1., 2.],[-0., 1.]])</span>
torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> rounding_mode<span class="token operator">=</span><span class="token string">&#39;floor&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 地板除法 tensor([[ 0.,  0.],[-1.,  0.]])</span>
a <span class="token operator">&gt;=</span> <span class="token number">2</span> <span class="token comment"># torch.ge(a,2)  #ge: greater_equal 缩写 tensor([[False,  True],[False,  True]])</span>
<span class="token punctuation">(</span>a<span class="token operator">&gt;=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>a<span class="token operator">&lt;=</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[False,  True],[False, False]])</span>
<span class="token punctuation">(</span>a<span class="token operator">&gt;=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">|</span><span class="token punctuation">(</span>a<span class="token operator">&lt;=</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[True, True],[True, True]])</span>
a<span class="token operator">==</span><span class="token number">5</span> <span class="token comment">#　torch.eq(a,5)　tensor([[False, False],[False, False]])</span>
torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token comment"># tensor([[1.0000, 1.4142],[nan, 2.0000]])</span>


a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">,</span><span class="token number">7.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token comment"># tensor([5., 8.])</span>
torch<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token comment"># tensor([1., 6.])</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.6</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#保留整数部分，四舍五入</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#保留整数部分，向下归整</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#保留整数部分，向上归整</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>trunc<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#保留整数部分，向0归整</span>

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.6</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>fmod<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 作除法取余数  tensor([ 0.6000, -0.7000])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>remainder<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 作除法取剩余的部分，结果恒正  tensor([0.6000, 1.3000])</span>

<span class="token comment"># 幅值裁剪</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.8</span><span class="token punctuation">,</span><span class="token number">100.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">20.0</span><span class="token punctuation">,</span><span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token builtin">max</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
z <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token builtin">max</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment"># tensor([ 0.9000, -0.8000,  1.0000, -1.0000,  0.7000])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span> <span class="token comment"># tensor([  0.9000,  -0.8000,   1.0000, -20.0000,   0.7000])</span>

relu <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
relu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">5.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor(5.)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="向量运算" tabindex="-1"><a class="header-anchor" href="#向量运算" aria-hidden="true">#</a> 向量运算</h3><p>原则上操作的张量至少是一维张量</p><p>向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 统计值</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[1., 2., 3.],[4., 5., 6.],[7., 8., 9.]])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor(45.)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 平均数 tensor(5.)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#累乘 tensor(362880.)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#标准差 tensor(2.7386)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#方差 tensor(7.5000)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#中位数 tensor(5.)</span>

<span class="token comment"># 指定维度计算统计值</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># torch.return_types.max(values=tensor([ 9., 10., 11., 12.]),indices=tensor([2, 2, 2, 2]))</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># torch.return_types.max(values=tensor([ 4.,  8., 12.]),indices=tensor([3, 3, 3]))</span>

<span class="token comment"># cum 扫描 </span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor([ 1, 3,  6, 10, 15, 21, 28, 36, 45])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cumprod<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor([ 1,  2,  6, 24, 120, 720, 5040,  40320, 362880])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cummax<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span> <span class="token comment"># tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cummax<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>indices<span class="token punctuation">)</span> <span class="token comment"># tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cummin<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># torch.return_types.cummin(values=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1]),indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0]))</span>

<span class="token comment"># torch.sort 和 torch.topk 可以对张量排序</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span> <span class="token comment"># torch.return_types.topk(values=tensor([[9., 7., 8.],[5., 6., 4.]]),indices=tensor([[0, 0, 0],[2, 2, 2]])) </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span> <span class="token comment"># torch.return_types.topk(values=tensor([[9., 8.],[3., 2.],[6., 5.]]),indices=tensor([[0, 2],[1, 2],[1, 0]])) </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>a<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span> <span class="token comment"># torch.return_types.sort(values=tensor([[7., 8., 9.],[1., 2., 3.],[4., 5., 6.]]),indices=tensor([[1, 2, 0],[0, 2, 1],[2, 0, 1]])) </span>

<span class="token comment"># 利用 torch.topk 可以在 Pytorch 中实现 KNN 算法</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="矩阵运算" tabindex="-1"><a class="header-anchor" href="#矩阵运算" aria-hidden="true">#</a> 矩阵运算</h3><p>矩阵必须是 <strong>二维</strong> 的</p><p>矩阵运算包括：矩阵乘法，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 矩阵乘法</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a@b<span class="token punctuation">)</span>  <span class="token comment">#等价于 torch.matmul(a,b) 或 torch.mm(a,b) tensor([[2, 4],[6, 8]])</span>

<span class="token comment"># 高维张量的矩阵乘法在后面的维度上进行</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>a@b<span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment"># torch.Size([5, 5, 4])</span>

<span class="token comment"># 矩阵转置</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[1., 3.],[2., 4.]])</span>

<span class="token comment"># 矩阵逆（逆矩阵），必须为浮点类型</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>inverse<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[-2.0000,  1.0000],[ 1.5000, -0.5000]])</span>

<span class="token comment"># 矩阵求 trace 秩</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>trace<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor(5.)</span>

<span class="token comment"># 矩阵求范数</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor(5.4772)</span>

<span class="token comment"># 矩阵行列式</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>det<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor(-2.)</span>

<span class="token comment"># 矩阵特征值和特征向量</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>eig<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token triple-quoted-string string">&#39;&#39;&#39;
两个特征值分别是 -2.5+2.7839j, 2.5-2.7839j 
torch.return_types.linalg_eig(
eigenvalues=tensor([2.5000+2.7839j, 2.5000-2.7839j]),
eigenvectors=tensor([[0.2535-0.4706j, 0.2535+0.4706j],
        [0.8452+0.0000j, 0.8452-0.0000j]]))
&#39;&#39;&#39;</span>

<span class="token comment"># 矩阵 svd 分解</span>
<span class="token comment"># svd 分解可以将任意一个矩阵分解为一个正交矩阵 u,一个对角阵 s 和一个正交矩阵 v.t() 的乘积</span>
<span class="token comment"># svd 常用于矩阵压缩和降维</span>
a<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
u<span class="token punctuation">,</span>s<span class="token punctuation">,</span>v <span class="token operator">=</span> torch<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>svd<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F 
<span class="token keyword">print</span><span class="token punctuation">(</span>u@F<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>@v<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#利用 svd 分解可以在Pytorch中实现主成分分析降维</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
tensor([[-0.2298,  0.8835,  0.4082],
        [-0.5247,  0.2408, -0.8165],
        [-0.8196, -0.4019,  0.4082]]) 

tensor([9.5255, 0.5143]) 

tensor([[-0.6196, -0.7849],
        [-0.7849,  0.6196]]) 

tensor([[1.0000, 2.0000],
        [3.0000, 4.0000],
        [5.0000, 6.0000]])
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>任意维张量运算</p><p>torch.einsum：爱因斯坦求和函数。torch.einsum 支持求导和反向传播，并且计算效率非常高</p><p>einsum 提供了一套既简洁又优雅的规则，可实现包括但不限于：内积，外积，矩阵乘法，转置和张量收缩（tensor contraction）等张量操作，熟练掌握 einsum 可以很方便的实现复杂的张量操作，而且不容易出错。</p><ul><li><p><strong>einsum 规则原理</strong></p><p>einsum 函数的思想起源于爱因斯坦，求和导致维度收缩，因此求和符号操作的指标总是只出现在公式的一边，例如在我们熟悉的矩阵乘法中</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><munder><mo>∑</mo><mi>k</mi></munder><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>B</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></mrow><annotation encoding="application/x-tex"> C_{ij} = \sum_{k}{A_{ik}B_{kj}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3521em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">kj</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>k 这个下标被求和了，求和导致了这个维度的消失，所以它只出现在右边而不出现在左边</p><p>这种只出现在张量公式的一边的下标被称之为哑指标，反之为自由指标</p><p>这种只出现在一边的哑指标一定是被求和求掉的，干脆把对应的∑∑求和符号省略</p><p>这就是爱因斯坦求和约定：</p><p><strong>只出现在公式一边的指标叫做哑指标，针对哑指标的 ∑ 求和符号可以省略</strong></p></li></ul><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>B</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow></mrow><annotation encoding="application/x-tex"> C_{ij} = {A_{ik}B_{kj}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">kj</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>这个公式表达的含义如下:</p><ul><li><p>C 这个张量的第 i 行第j列由 𝐴 这个张量的第i行第 k 列和 𝐵 这个张量的第 k 行第j列相乘，这样得到的是一个三维张量 𝐷, 其元素为 𝐷<sub>𝑖𝑘𝑗</sub>，然后对 𝐷 在维度 k 上求和得到</p></li><li><p>公式展现形式中除了省去了求和符号，还省去了乘法符号</p></li><li><p>借鉴爱因斯坦求和约定表达张量运算的清爽整洁，numpy、tensorflow 和 torch 等库中都引入了 einsum 这个函数</p></li><li><p>上述矩阵乘法可以被einsum这个函数表述成</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>C <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ik,kj-&gt;ij&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>这个函数的规则原理非常简洁</p><ol><li>用元素计算公式来表达张量运算</li><li>只出现在元素计算公式箭头左边的指标叫做哑指标</li><li>省略元素计算公式中对哑指标的求和符号</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 

A <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

C1 <span class="token operator">=</span> A@B
<span class="token keyword">print</span><span class="token punctuation">(</span>C1<span class="token punctuation">)</span> <span class="token comment"># tensor([[19., 22.],[43., 50.]])</span>

C2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ik,kj-&gt;ij&quot;</span><span class="token punctuation">,</span><span class="token punctuation">[</span>A<span class="token punctuation">,</span>B<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>C2<span class="token punctuation">)</span> <span class="token comment"># tensor([[19., 22.],[43., 50.]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>einsum 基础范例</strong></p><p>einsum 这个函数的精髓实际上是第一条:</p><ul><li>用元素计算公式来表达张量运算</li><li>绝大部分张量运算都可以用元素计算公式很方便地来表达，这也是它为什么会那么神通广大</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 例1，张量转置</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># B = torch.permute(A,[0,2,1])</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ijk-&gt;ikj&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([3, 4, 5])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([3, 5, 4])</span>

<span class="token comment"># 例2，取对角元</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment"># B = torch.diagonal(A)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ii-&gt;i&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([5, 5])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([5])</span>

<span class="token comment"># 例3，求和降维</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment"># B = torch.sum(A,1)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ij-&gt;i&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([4, 5])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([4])</span>

<span class="token comment"># 例4，哈达玛积</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment"># C=A*B</span>
C <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ij,ij-&gt;ij&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([5, 5]) torch.Size([5, 5])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>C<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([5, 5])</span>

<span class="token comment"># 例5，向量内积</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token comment"># C=torch.dot(A,B)</span>
C <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;i,i-&gt;&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([10]) torch.Size([10])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>C<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([])</span>

<span class="token comment"># 例6，向量外积(类似笛卡尔积)</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment"># C = torch.outer(A,B)</span>
C <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;i,j-&gt;ij&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([10]) torch.Size([5])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>C<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([10, 5])</span>

<span class="token comment"># 例7，矩阵乘法</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>
<span class="token comment"># C = torch.matmul(A,B)</span>
C <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ik,kj-&gt;ij&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([5, 4]) torch.Size([4, 6])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>C<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([5, 6])</span>


<span class="token comment">#例8，张量缩并</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span>
<span class="token comment"># C = torch.tensordot(A,B,dims=[(0,1),(1,0)])</span>
C <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;ijk,jih-&gt;kh&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;before:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> B<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># before: torch.Size([3, 4, 5]) torch.Size([4, 3, 6])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;after:&quot;</span><span class="token punctuation">,</span>C<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># after: torch.Size([5, 6])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>einsum 高级范例</strong></p><p>einsum 可用于超过两个张量的计算</p><p>例如：双线性变换。这是向量内积的一种扩展，一种常用的注意力机制实现方式</p><p>不考虑 batch 维度时，双线性变换的公式：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mi>q</mi><mi>W</mi><msup><mi>k</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A=qWk^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></p><p>考虑 batch 维度时，无法用矩阵乘法表示，可以用元素计算公式表达：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><mrow><msub><mi>Q</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>W</mi><mrow><mi>j</mi><mi>k</mi><mi>l</mi></mrow></msub><msub><mi>K</mi><mrow><mi>i</mi><mi>l</mi></mrow></msub></mrow><mo>=</mo><msub><mi>Q</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>W</mi><mrow><mi>j</mi><mi>k</mi><mi>l</mi></mrow></msub><msub><mi>K</mi><mrow><mi>i</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}=\sum_{k}\sum_{l}{Q_{ik}W_{jkl}K_{il}}=Q_{ik}W_{jkl}K_{il}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">jk</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">jk</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 例9，bilinear 注意力机制</span>

<span class="token comment">#====不考虑 batch 维度====</span>
q <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># query_features</span>
k <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># key_features</span>
W <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># out_features,query_features,key_features</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token comment"># out_features</span>

<span class="token comment"># a = q@W@k.t()+b  </span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>bilinear<span class="token punctuation">(</span>q<span class="token punctuation">,</span>k<span class="token punctuation">,</span>W<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;a.shape:&quot;</span><span class="token punctuation">,</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># a.shape: torch.Size([5])</span>


<span class="token comment">#=====考虑 batch 维度====</span>
Q <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment">#batch_size,query_features</span>
K <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>    <span class="token comment">#batch_size,key_features</span>
W <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment">#out_features,query_features,key_features</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>       <span class="token comment">#out_features</span>

<span class="token comment">#A = torch.bilinear(Q,K,W,b)</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&#39;bq,oqk,bk-&gt;bo&#39;</span><span class="token punctuation">,</span>Q<span class="token punctuation">,</span>W<span class="token punctuation">,</span>K<span class="token punctuation">)</span> <span class="token operator">+</span> b
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;A.shape:&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># A.shape: torch.Size([8, 5])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>也可以用 einsum 来实现更常见的 scaled-dot-product 形式的 Attention</p><p>不考虑 batch 维度时，scaled-dot-product 形式的 Attention 用矩阵乘法公式表示：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>a</mi><msup><mi>k</mi><mi>T</mi></msup></mrow><msub><mi>d</mi><mi>k</mi></msub></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a=softmax(\frac{ak^{T}}{d_k} )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4882em;vertical-align:-0.4509em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0374em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4509em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></p><p>考虑 batch 维度时，无法用矩阵乘法表示，可以用元素计算公式表达 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><msub><mi>Q</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><msub><mi>K</mi><mrow><mi>i</mi><mi>j</mi><mi>n</mi></mrow></msub></mrow><msub><mi>d</mi><mi>k</mi></msub></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">A_{ij}=softmax(\frac{Q_{in}K_{ijn}}{d_k})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4365em;vertical-align:-0.4509em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9857em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5073em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0715em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ijn</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4509em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 例10，scaled-dot-product 注意力机制</span>

<span class="token comment">#====不考虑 batch 维度====</span>
q <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment"># query_features</span>
k <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment"># key_size, key_features</span>

d_k <span class="token operator">=</span> k<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>q@k<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>d_k<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;a.shape=&quot;</span><span class="token punctuation">,</span>a<span class="token punctuation">.</span>shape <span class="token punctuation">)</span>

<span class="token comment">#====考虑 batch 维度====</span>
Q <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>  <span class="token comment">#batch_size,query_features</span>
K <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment">#batch_size,key_size,key_features</span>

d_k <span class="token operator">=</span> K<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&quot;in,ijn-&gt;ij&quot;</span><span class="token punctuation">,</span>Q<span class="token punctuation">,</span>K<span class="token punctuation">)</span><span class="token operator">/</span>d_k<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;A.shape=&quot;</span><span class="token punctuation">,</span>A<span class="token punctuation">.</span>shape <span class="token punctuation">)</span>

<span class="token comment">#性能测试</span>

<span class="token comment">#=====考虑 batch 维度====</span>
Q <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span>    <span class="token comment">#batch_size,query_features</span>
K <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span>    <span class="token comment">#batch_size,key_features</span>
W <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span> <span class="token comment">#out_features,query_features,key_features</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span>       <span class="token comment">#out_features</span>

<span class="token operator">%</span><span class="token operator">%</span>timeit 
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>bilinear<span class="token punctuation">(</span>Q<span class="token punctuation">,</span>K<span class="token punctuation">,</span>W<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
<span class="token comment"># 1.83 ms ± 78.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</span>

<span class="token operator">%</span><span class="token operator">%</span>timeit 
A <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">&#39;bq,oqk,bk-&gt;bo&#39;</span><span class="token punctuation">,</span>Q<span class="token punctuation">,</span>W<span class="token punctuation">,</span>K<span class="token punctuation">)</span> <span class="token operator">+</span> b
<span class="token comment"># 636 µs ± 27.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)、</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h3 id="广播机制" tabindex="-1"><a class="header-anchor" href="#广播机制" aria-hidden="true">#</a> 广播机制</h3><p>Pytorch 的广播规则和 numpy 是一样的:</p><ol><li>张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样</li><li>两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的</li><li>两个张量在所有维度上都是相容的，它们就能使用广播</li><li>广播之后，每个维度的长度将取两个张量在该维度长度的较大值</li><li>在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了 <strong>复制</strong></li></ol><p>torch.broadcast_tensors 可以将多个张量根据广播规则转换成相同的维度</p><p>维度扩展允许的操作有两种：</p><ol><li>增加一个维度</li><li>对长度为 1 的维度进行复制扩展</li></ol><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b <span class="token operator">+</span> a<span class="token punctuation">)</span>  <span class="token comment"># tensor([[1, 2, 3],[2, 3, 4],[3, 4, 5]])</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">3</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> b  <span class="token comment"># tensor([[1, 2, 3],[2, 3, 4],[3, 4, 5]])</span>
a_broad<span class="token punctuation">,</span>b_broad <span class="token operator">=</span> torch<span class="token punctuation">.</span>broadcast_tensors<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a_broad<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[1, 2, 3],[1, 2, 3],[1, 2, 3]]) </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b_broad<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[0, 0, 0],[1, 1, 1],[2, 2, 2]]) </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a_broad <span class="token operator">+</span> b_broad<span class="token punctuation">)</span> <span class="token comment"># tensor([[1, 2, 3],[2, 3, 4],[3, 4, 5]])</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_5-3、nn-functional-和-nn-module" tabindex="-1"><a class="header-anchor" href="#_5-3、nn-functional-和-nn-module" aria-hidden="true">#</a> 5.3、nn.functional 和 nn.Module</h2><h3 id="简介" tabindex="-1"><a class="header-anchor" href="#简介" aria-hidden="true">#</a> 简介</h3><p>Pytorch 和神经网络相关的功能组件大多都封装在 <strong>torch.nn</strong> 模块下</p><p>这些功能组件的绝大部分既有函数形式实现，也有类形式实现。</p><p>其中nn.functional（一般引入后改名为 <strong>F</strong>）有各种功能组件的函数实现</p><ul><li>激活函数 <ul><li>F.relu</li><li>F.sigmoid</li><li>F.tanh</li><li>F.softmax</li></ul></li><li>模型层 <ul><li>F.linear</li><li>F.conv2d</li><li>F.max_pool2d</li><li>F.dropout2d</li><li>F.embedding</li></ul></li><li>损失函数 <ul><li>F.binary_cross_entropy</li><li>F.mse_loss</li><li>F.cross_entropy</li></ul></li></ul><p>为了便于对参数进行管理，一般通过继承 nn.Module 转换成为类的实现形式，并直接封装在 nn 模块下。例如：</p><ul><li>激活函数 <ul><li>nn.ReLU</li><li>nn.Sigmoid</li><li>nn.Tanh</li><li>nn.Softmax</li></ul></li><li>模型层 <ul><li>nn.Linear</li><li>nn.Conv2d</li><li>nn.MaxPool2d</li><li>nn.Dropout2d</li><li>nn.Embedding</li></ul></li><li>损失函数 <ul><li>nn.BCELoss</li><li>nn.MSELoss</li><li>nn.CrossEntropyLoss</li></ul></li></ul><p>实际上 nn.Module 除了可以管理其引用的各种参数，还可以管理其引用的子模块，功能十分强大</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F 
torch<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># tensor(0.)</span>
F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># tensor(0.)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="使用-nn-module-来管理参数-配合-nn-parameter-使用" tabindex="-1"><a class="header-anchor" href="#使用-nn-module-来管理参数-配合-nn-parameter-使用" aria-hidden="true">#</a> 使用 nn.Module 来管理参数(配合 nn.Parameter 使用)</h3><p>在 Pytorch 中，模型的参数是需要被优化器训练的，因此，通常要设置参数为 requires_grad = True 的张量。</p><p>同时，在一个模型中，往往有许多的参数，要手动管理这些参数并不是一件容易的事情。</p><p>Pytorch 一般将参数用 nn.Parameter 来表示，并且用 nn.Module 来管理其结构下的所有参数。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional  <span class="token keyword">as</span> F

torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># tensor([[0.1829, 0.0693],[0.0767, 1.2441]], requires_grad=True)</span>

<span class="token comment"># nn.Parameter 具有 requires_grad = True 属性</span>
w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token comment"># Parameter containing:tensor([[-0.8092, -0.8830],[ 1.6357, -0.1740]], requires_grad=True)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># True</span>

<span class="token comment"># nn.ParameterList 可以将多个 nn.Parameter 组成一个列表</span>
params_list <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
ParameterList(
    (0): Parameter containing: [torch.float32 of size 8x1]
    (1): Parameter containing: [torch.float32 of size 8x2]
)
&#39;&#39;&#39;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>params_list<span class="token punctuation">)</span> 
<span class="token keyword">print</span><span class="token punctuation">(</span>params_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># True</span>

<span class="token comment"># nn.ParameterDict 可以将多个 nn.Parameter 组成一个字典</span>
params_dict <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterDict<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               <span class="token string">&quot;b&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
ParameterDict(
    (a): Parameter containing: [torch.FloatTensor of size 2x2]
    (b): Parameter containing: [torch.FloatTensor of size 2]
)
&#39;&#39;&#39;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>params_dict<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>params_dict<span class="token punctuation">[</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># True</span>

<span class="token comment"># 可以用 Module 将它们管理起来</span>
<span class="token comment"># module.parameters() 返回一个生成器，包括其结构下的所有 parameters</span>
module <span class="token operator">=</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">(</span><span class="token punctuation">)</span>
module<span class="token punctuation">.</span>w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
module<span class="token punctuation">.</span>params_list <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
module<span class="token punctuation">.</span>params_dict <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterDict<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;a&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               <span class="token string">&quot;b&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

num_param <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> module<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
    num_param <span class="token operator">=</span> num_param <span class="token operator">+</span> <span class="token number">1</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;number of Parameters =&quot;</span><span class="token punctuation">,</span>num_param<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
(&#39;w&#39;, Parameter containing:
tensor([[-1.2390,  0.3316],
        [-0.4232, -0.0090]], requires_grad=True)) 

(&#39;params_list.0&#39;, Parameter containing:
tensor([[0.8785],
        [0.6456],
        [0.4697],
        [0.8962],
        [0.1122],
        [0.4837],
        [0.8089],
        [0.0515]], requires_grad=True)) 

(&#39;params_list.1&#39;, Parameter containing:
tensor([[0.7440, 0.5626],
        [0.2430, 0.0113],
        [0.5884, 0.0815],
        [0.7125, 0.4120],
        [0.7275, 0.1608],
        [0.4658, 0.0085],
        [0.8578, 0.7290],
        [0.0327, 0.2239]], requires_grad=True)) 

(&#39;params_dict.a&#39;, Parameter containing:
tensor([[0.6698, 0.5646],
        [0.2482, 0.8258]], requires_grad=True)) 

(&#39;params_dict.b&#39;, Parameter containing:
tensor([0., 0.], requires_grad=True)) 

number of Parameters = 5
&#39;&#39;&#39;</span>


<span class="token comment"># 实践当中，一般通过继承 nn.Module 来构建模块类，并将所有含有需要学习的参数的部分放在 **构造函数** 中。</span>
<span class="token comment"># 以下范例为 Pytorch 中 nn.Linear 的源码的简化版本</span>
<span class="token comment"># 可以看到它将需要学习的参数放在了 __init__ 构造函数中，并在 forward 中调用 F.linear 函数来实现计算逻辑。</span>

<span class="token keyword">class</span> <span class="token class-name">Linear</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    __constants__ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&#39;in_features&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;out_features&#39;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Linear<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>in_features <span class="token operator">=</span> in_features
        self<span class="token punctuation">.</span>out_features <span class="token operator">=</span> out_features
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>out_features<span class="token punctuation">,</span> in_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> bias<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>out_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>register_parameter<span class="token punctuation">(</span><span class="token string">&#39;bias&#39;</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>
   
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="使用-nn-module-来管理子模块" tabindex="-1"><a class="header-anchor" href="#使用-nn-module-来管理子模块" aria-hidden="true">#</a> 使用 nn.Module 来管理子模块</h3><p>一般情况下，我们都很少直接使用 nn.Parameter 来定义参数构建模型，而是通过一些拼装一些常用的模型层来构造模型</p><p>这些模型层也是继承自 nn.Module 的对象，本身也包括参数，属于我们要定义的模块的子模块</p><p>nn.Module 提供了一些方法可以管理这些子模块</p><ul><li>children() 方法: 返回生成器，包括模块下的所有子模块。</li><li>named_children() 方法：返回一个生成器，包括模块下的所有子模块，以及它们的名字。</li><li>modules() 方法：返回一个生成器，包括模块下的所有各个层级的模块，包括模块本身。</li><li>named_modules() 方法：返回一个生成器，包括模块下的所有各个层级的模块以及它们的名字，包括模块本身。</li></ul><p>其中 chidren() 方法和 named_children() 方法较多使用。</p><p>modules() 方法和 named_modules() 方法较少使用，其功能可以通过多个 named_children() 的嵌套使用实现。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">,</span>embedding_dim <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>padding_idx <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv_1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>in_channels <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>out_channels <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool_1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool1d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu_1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv_2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>in_channels <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span>out_channels <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool_2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool1d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu_2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6144</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y
    
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>

i <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> child <span class="token keyword">in</span> net<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    i<span class="token operator">+=</span><span class="token number">1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>child<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;child number&quot;</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Embedding(10000, 3, padding_idx=1) 

Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
) 

Sequential(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear): Linear(in_features=6144, out_features=1, bias=True)
) 

child number 3
&#39;&#39;&#39;</span>

i <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> name<span class="token punctuation">,</span>child <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    i<span class="token operator">+=</span><span class="token number">1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span><span class="token string">&quot;:&quot;</span><span class="token punctuation">,</span>child<span class="token punctuation">,</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;child number&quot;</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
embedding : Embedding(10000, 3, padding_idx=1) 

conv : Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
) 

dense : Sequential(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear): Linear(in_features=6144, out_features=1, bias=True)
) 

child number 3
&#39;&#39;&#39;</span>

i <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> module <span class="token keyword">in</span> net<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    i<span class="token operator">+=</span><span class="token number">1</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>module<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;module number:&quot;</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (embedding): Embedding(10000, 3, padding_idx=1)
  (conv): Sequential(
    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_1): ReLU()
    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (relu_2): ReLU()
  )
  (dense): Sequential(
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (linear): Linear(in_features=6144, out_features=1, bias=True)
  )
)
Embedding(10000, 3, padding_idx=1)
Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
)
Conv1d(3, 16, kernel_size=(5,), stride=(1,))
MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
ReLU()
Conv1d(16, 128, kernel_size=(2,), stride=(1,))
MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
ReLU()
Sequential(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear): Linear(in_features=6144, out_features=1, bias=True)
)
Flatten(start_dim=1, end_dim=-1)
Linear(in_features=6144, out_features=1, bias=True)
module number: 12
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>下面我们通过 named_children 方法找到 embedding 层，并将其参数设置为不可训练(相当于冻结 embedding 层)。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>children_dict <span class="token operator">=</span> <span class="token punctuation">{</span>name<span class="token punctuation">:</span>module <span class="token keyword">for</span> name<span class="token punctuation">,</span>module <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token triple-quoted-string string">&#39;&#39;&#39;
{&#39;embedding&#39;: Embedding(10000, 3, padding_idx=1), &#39;conv&#39;: Sequential(
  (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))
  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_1): ReLU()
  (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))
  (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (relu_2): ReLU()
), &#39;dense&#39;: Sequential(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear): Linear(in_features=6144, out_features=1, bias=True)
)}
Embedding(10000, 3, padding_idx=1)
&#39;&#39;&#39;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>children_dict<span class="token punctuation">)</span>
embedding <span class="token operator">=</span> children_dict<span class="token punctuation">[</span><span class="token string">&quot;embedding&quot;</span><span class="token punctuation">]</span>
embedding<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment">#冻结其参数</span>

<span class="token comment">#可以看到其第一层的参数已经不可以被训练了。</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> embedding<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span> <span class="token comment"># False</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 30000</span>
    
<span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span>input_dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment"># 不可训练参数数量增加</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Embedding-1                             [-1, 200, 3]               30,000
Conv1d-2                               [-1, 16, 196]                  256
MaxPool1d-3                             [-1, 16, 98]                    0
ReLU-4                                  [-1, 16, 98]                    0
Conv1d-5                               [-1, 128, 97]                4,224
MaxPool1d-6                            [-1, 128, 48]                    0
ReLU-7                                 [-1, 128, 48]                    0
Flatten-8                                 [-1, 6144]                    0
Linear-9                                     [-1, 1]                6,145
==========================================================================
Total params: 40,625
Trainable params: 10,625
Non-trainable params: 30,000
--------------------------------------------------------------------------
Input size (MB): 0.000763
Forward/backward pass size (MB): 0.287788
Params size (MB): 0.154972
Estimated Total Size (MB): 0.443523
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/T4mako/T4mako.github.io/edit/main/src/code/python/Machine Learning/Pytorch/5、Pytorch 低阶 API.md" rel="noopener noreferrer" target="_blank" aria-label="在 GitHub 上编辑此页" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><!----><!----></div></footer><!----><div id="comment" class="waline-wrapper" darkmode="false" style="display:block;"><div data-waline provider="Waline" pageview="false"><!--v-if--><div class="wl-comment"><!--v-if--><div class="wl-panel"><div class="wl-header item3"><!--[--><div class="wl-header-item"><label for="wl-nick">昵称</label><input id="wl-nick" class="wl-input wl-nick" name="nick" type="text" value></div><div class="wl-header-item"><label for="wl-mail">邮箱</label><input id="wl-mail" class="wl-input wl-mail" name="mail" type="email" value></div><div class="wl-header-item"><label for="wl-link">网址</label><input id="wl-link" class="wl-input wl-link" name="link" type="text" value></div><!--]--></div><textarea id="wl-edit" class="wl-editor" placeholder="请留言。(填写邮箱可在被回复时收到邮件提醒)"></textarea><div class="wl-preview" style="display:none;"><hr><h4>预览:</h4><div class="wl-content"></div></div><div class="wl-footer"><div class="wl-actions"><a href="https://guides.github.com/features/mastering-markdown/" title="Markdown Guide" aria-label="Markdown is supported" class="wl-action" target="_blank" rel="noopener noreferrer"><svg width="16" height="16" ariaHidden="true"><path d="M14.85 3H1.15C.52 3 0 3.52 0 4.15v7.69C0 12.48.52 13 1.15 13h13.69c.64 0 1.15-.52 1.15-1.15v-7.7C16 3.52 15.48 3 14.85 3zM9 11H7V8L5.5 9.92 4 8v3H2V5h2l1.5 2L7 5h2v6zm2.99.5L9.5 8H11V5h2v3h1.5l-2.51 3.5z" fill="currentColor"></path></svg></a><button type="button" class="wl-action" title="表情" style="display:none;"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M563.2 463.3 677 540c1.7 1.2 3.7 1.8 5.8 1.8.7 0 1.4-.1 2-.2 2.7-.5 5.1-2.1 6.6-4.4l25.3-37.8c1.5-2.3 2.1-5.1 1.6-7.8s-2.1-5.1-4.4-6.6l-73.6-49.1 73.6-49.1c2.3-1.5 3.9-3.9 4.4-6.6.5-2.7 0-5.5-1.6-7.8l-25.3-37.8a10.1 10.1 0 0 0-6.6-4.4c-.7-.1-1.3-.2-2-.2-2.1 0-4.1.6-5.8 1.8l-113.8 76.6c-9.2 6.2-14.7 16.4-14.7 27.5.1 11 5.5 21.3 14.7 27.4zM387 348.8h-45.5c-5.7 0-10.4 4.7-10.4 10.4v153.3c0 5.7 4.7 10.4 10.4 10.4H387c5.7 0 10.4-4.7 10.4-10.4V359.2c0-5.7-4.7-10.4-10.4-10.4zm333.8 241.3-41-20a10.3 10.3 0 0 0-8.1-.5c-2.6.9-4.8 2.9-5.9 5.4-30.1 64.9-93.1 109.1-164.4 115.2-5.7.5-9.9 5.5-9.5 11.2l3.9 45.5c.5 5.3 5 9.5 10.3 9.5h.9c94.8-8 178.5-66.5 218.6-152.7 2.4-5 .3-11.2-4.8-13.6zm186-186.1c-11.9-42-30.5-81.4-55.2-117.1-24.1-34.9-53.5-65.6-87.5-91.2-33.9-25.6-71.5-45.5-111.6-59.2-41.2-14-84.1-21.1-127.8-21.1h-1.2c-75.4 0-148.8 21.4-212.5 61.7-63.7 40.3-114.3 97.6-146.5 165.8-32.2 68.1-44.3 143.6-35.1 218.4 9.3 74.8 39.4 145 87.3 203.3.1.2.3.3.4.5l36.2 38.4c1.1 1.2 2.5 2.1 3.9 2.6 73.3 66.7 168.2 103.5 267.5 103.5 73.3 0 145.2-20.3 207.7-58.7 37.3-22.9 70.3-51.5 98.1-85 27.1-32.7 48.7-69.5 64.2-109.1 15.5-39.7 24.4-81.3 26.6-123.8 2.4-43.6-2.5-87-14.5-129zm-60.5 181.1c-8.3 37-22.8 72-43 104-19.7 31.1-44.3 58.6-73.1 81.7-28.8 23.1-61 41-95.7 53.4-35.6 12.7-72.9 19.1-110.9 19.1-82.6 0-161.7-30.6-222.8-86.2l-34.1-35.8c-23.9-29.3-42.4-62.2-55.1-97.7-12.4-34.7-18.8-71-19.2-107.9-.4-36.9 5.4-73.3 17.1-108.2 12-35.8 30-69.2 53.4-99.1 31.7-40.4 71.1-72 117.2-94.1 44.5-21.3 94-32.6 143.4-32.6 49.3 0 97 10.8 141.8 32 34.3 16.3 65.3 38.1 92 64.8 26.1 26 47.5 56 63.6 89.2 16.2 33.2 26.6 68.5 31 105.1 4.6 37.5 2.7 75.3-5.6 112.3z" fill="currentColor"></path></svg></button><button type="button" class="wl-action" title="表情包"><svg width="24" height="24" fill="currentcolor" viewBox="0 0 24 24"><path style="transform: translateY(0.5px)" d="M18.968 10.5H15.968V11.484H17.984V12.984H15.968V15H14.468V9H18.968V10.5V10.5ZM8.984 9C9.26533 9 9.49967 9.09367 9.687 9.281C9.87433 9.46833 9.968 9.70267 9.968 9.984V10.5H6.499V13.5H8.468V12H9.968V14.016C9.968 14.2973 9.87433 14.5317 9.687 14.719C9.49967 14.9063 9.26533 15 8.984 15H5.984C5.70267 15 5.46833 14.9063 5.281 14.719C5.09367 14.5317 5 14.2973 5 14.016V9.985C5 9.70367 5.09367 9.46933 5.281 9.282C5.46833 9.09467 5.70267 9.001 5.984 9.001H8.984V9ZM11.468 9H12.968V15H11.468V9V9Z"></path><path d="M18.5 3H5.75C3.6875 3 2 4.6875 2 6.75V18C2 20.0625 3.6875 21.75 5.75 21.75H18.5C20.5625 21.75 22.25 20.0625 22.25 18V6.75C22.25 4.6875 20.5625 3 18.5 3ZM20.75 18C20.75 19.2375 19.7375 20.25 18.5 20.25H5.75C4.5125 20.25 3.5 19.2375 3.5 18V6.75C3.5 5.5125 4.5125 4.5 5.75 4.5H18.5C19.7375 4.5 20.75 5.5125 20.75 6.75V18Z"></path></svg></button><input id="wl-image-upload" class="upload" type="file" accept=".png,.jpg,.jpeg,.webp,.bmp,.gif"><label for="wl-image-upload" class="wl-action" title="上传图片"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M784 112H240c-88 0-160 72-160 160v480c0 88 72 160 160 160h544c88 0 160-72 160-160V272c0-88-72-160-160-160zm96 640c0 52.8-43.2 96-96 96H240c-52.8 0-96-43.2-96-96V272c0-52.8 43.2-96 96-96h544c52.8 0 96 43.2 96 96v480z" fill="currentColor"></path><path d="M352 480c52.8 0 96-43.2 96-96s-43.2-96-96-96-96 43.2-96 96 43.2 96 96 96zm0-128c17.6 0 32 14.4 32 32s-14.4 32-32 32-32-14.4-32-32 14.4-32 32-32zm462.4 379.2-3.2-3.2-177.6-177.6c-25.6-25.6-65.6-25.6-91.2 0l-80 80-36.8-36.8c-25.6-25.6-65.6-25.6-91.2 0L200 728c-4.8 6.4-8 14.4-8 24 0 17.6 14.4 32 32 32 9.6 0 16-3.2 22.4-9.6L380.8 640l134.4 134.4c6.4 6.4 14.4 9.6 24 9.6 17.6 0 32-14.4 32-32 0-9.6-4.8-17.6-9.6-24l-52.8-52.8 80-80L769.6 776c6.4 4.8 12.8 8 20.8 8 17.6 0 32-14.4 32-32 0-8-3.2-16-8-20.8z" fill="currentColor"></path></svg></label><button type="button" class="wl-action" title="预览"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M710.816 654.301c70.323-96.639 61.084-230.578-23.705-314.843-46.098-46.098-107.183-71.109-172.28-71.109-65.008 0-126.092 25.444-172.28 71.109-45.227 46.098-70.756 107.183-70.756 172.106 0 64.923 25.444 126.007 71.194 172.106 46.099 46.098 107.184 71.109 172.28 71.109 51.414 0 100.648-16.212 142.824-47.404l126.53 126.006c7.058 7.06 16.297 10.979 26.406 10.979 10.105 0 19.343-3.919 26.402-10.979 14.467-14.467 14.467-38.172 0-52.723L710.816 654.301zm-315.107-23.265c-65.88-65.88-65.88-172.54 0-238.42 32.069-32.07 74.245-49.149 119.471-49.149 45.227 0 87.407 17.603 119.472 49.149 65.88 65.879 65.88 172.539 0 238.42-63.612 63.178-175.242 63.178-238.943 0zm0 0" fill="currentColor"></path><path d="M703.319 121.603H321.03c-109.8 0-199.469 89.146-199.469 199.38v382.034c0 109.796 89.236 199.38 199.469 199.38h207.397c20.653 0 37.384-16.645 37.384-37.299 0-20.649-16.731-37.296-37.384-37.296H321.03c-68.582 0-124.352-55.77-124.352-124.267V321.421c0-68.496 55.77-124.267 124.352-124.267h382.289c68.582 0 124.352 55.771 124.352 124.267V524.72c0 20.654 16.736 37.299 37.385 37.299 20.654 0 37.384-16.645 37.384-37.299V320.549c-.085-109.8-89.321-198.946-199.121-198.946zm0 0" fill="currentColor"></path></svg></button></div><div class="wl-info"><div class="wl-captcha-container"></div><div class="wl-text-number">0 <!--v-if-->  字</div><button type="button" class="wl-btn">登录</button><button type="submit" class="primary wl-btn" title="Cmd|Ctrl + Enter"><!--[-->提交<!--]--></button></div><div class="wl-gif-popup"><input type="text" placeholder="搜索表情包"><!--v-if--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div></div><div class="wl-emoji-popup"><!--[--><!--]--><!--v-if--></div></div></div><!--v-if--></div><div class="wl-meta-head"><div class="wl-count"><!--v-if--> 评论</div><ul class="wl-sort"><!--[--><li class="active">按正序</li><li class="">按倒序</li><li class="">按热度</li><!--]--></ul></div><div class="wl-cards"><!--[--><!--]--></div><!--[--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div><!--]--><div class="wl-power"> Powered by <a href="https://github.com/walinejs/waline" target="_blank" rel="noopener noreferrer"> Waline </a> v2.15.5</div></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">T4mako's blog</div><div class="vp-copyright">Copyright © 2024 T4mako</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-2ac1fdf0.js" defer></script>
  </body>
</html>
