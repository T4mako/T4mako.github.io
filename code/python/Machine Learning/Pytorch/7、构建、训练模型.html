<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.66" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://T4mako.github.io/code/python/Machine%20Learning/Pytorch/7%E3%80%81%E6%9E%84%E5%BB%BA%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html"><meta property="og:site_name" content="T4mako"><meta property="og:description" content="7.1、构建模型 构建模型有三种方法： 继承 nn.Module 基类构建自定义模型（最常见） 使用 nn.Sequential 按层顺序构建模型（最简单） 继承 nn.Module 基类构建模型并辅助应用模型容器进行封装（nn.Sequential,nn.ModuleList,nn.ModuleDict）（最为灵活也较为复杂） 模型定义好后，会给参数（w，b）赋值 pytorch hub 模块，调用他人的网络架构"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="T4mako"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"","image":[""],"dateModified":null,"author":[{"@type":"Person","name":"T4mako","url":"https://github.com/T4mako/T4mako.github.io"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Zen+Maru+Gothic:wght@500&display=swap" rel="stylesheet"><link rel="alternate" type="application/rss+xml" href="https://T4mako.github.io/rss.xml" title="T4mako RSS Feed"><title>T4mako</title><meta name="description" content="7.1、构建模型 构建模型有三种方法： 继承 nn.Module 基类构建自定义模型（最常见） 使用 nn.Sequential 按层顺序构建模型（最简单） 继承 nn.Module 基类构建模型并辅助应用模型容器进行封装（nn.Sequential,nn.ModuleList,nn.ModuleDict）（最为灵活也较为复杂） 模型定义好后，会给参数（w，b）赋值 pytorch hub 模块，调用他人的网络架构">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-c43249a7.css" as="style"><link rel="stylesheet" href="/assets/style-c43249a7.css">
    <link rel="modulepreload" href="/assets/app-00d6fe81.js"><link rel="modulepreload" href="/assets/7、构建、训练模型.html-d518af36.js"><link rel="modulepreload" href="/assets/7、构建、训练模型.html-0f8b569c.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="prefetch" href="/assets/index.html-28de6f14.js" as="script"><link rel="prefetch" href="/assets/index.html-f5f264d6.js" as="script"><link rel="prefetch" href="/assets/index.html-30a1b7c2.js" as="script"><link rel="prefetch" href="/assets/Elasticsearch.html-cdfa620a.js" as="script"><link rel="prefetch" href="/assets/MongoDB.html-26953f36.js" as="script"><link rel="prefetch" href="/assets/MySQL基础.html-142c566d.js" as="script"><link rel="prefetch" href="/assets/Redis.html-00ca8519.js" as="script"><link rel="prefetch" href="/assets/IDEA、Eclipse快捷键.html-15e3dc66.js" as="script"><link rel="prefetch" href="/assets/JDBC.html-8ec2fd12.js" as="script"><link rel="prefetch" href="/assets/JVM.html-fa0d3015.js" as="script"><link rel="prefetch" href="/assets/JVM入门.html-5f1781e4.js" as="script"><link rel="prefetch" href="/assets/JWT.html-7c0fd9d7.js" as="script"><link rel="prefetch" href="/assets/JavaWeb基础.html-af51d1ad.js" as="script"><link rel="prefetch" href="/assets/Maven基础.html-ad80dbfe.js" as="script"><link rel="prefetch" href="/assets/MyBatis.html-1642006c.js" as="script"><link rel="prefetch" href="/assets/MybatisPlus.html-07f9ea4d.js" as="script"><link rel="prefetch" href="/assets/RabbitMQ.html-5aae586f.js" as="script"><link rel="prefetch" href="/assets/Shiro.html-fafd6510.js" as="script"><link rel="prefetch" href="/assets/SpringBoot.html-6d206ed6.js" as="script"><link rel="prefetch" href="/assets/SpringBoot常用注解总结.html-c19e968e.js" as="script"><link rel="prefetch" href="/assets/SpringBoot自动装配原理.html-83356abe.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础.html-081659a3.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础2024.html-5c5733dc.js" as="script"><link rel="prefetch" href="/assets/SpringMVC.html-20c731bf.js" as="script"><link rel="prefetch" href="/assets/Spring基础.html-7fdff257.js" as="script"><link rel="prefetch" href="/assets/index.html-8b1856b4.js" as="script"><link rel="prefetch" href="/assets/Matplotlib.html-d2aba437.js" as="script"><link rel="prefetch" href="/assets/Numpy.html-ffba3c01.js" as="script"><link rel="prefetch" href="/assets/Pandas.html-febe9de7.js" as="script"><link rel="prefetch" href="/assets/python 基础语法.html-d33402d6.js" as="script"><link rel="prefetch" href="/assets/python 项目注意事项.html-f13637d7.js" as="script"><link rel="prefetch" href="/assets/Ajax.html-73e0d2ee.js" as="script"><link rel="prefetch" href="/assets/Axios.html-6a0f7031.js" as="script"><link rel="prefetch" href="/assets/CSS3.html-fbf9bd49.js" as="script"><link rel="prefetch" href="/assets/HTML.html-dba9796c.js" as="script"><link rel="prefetch" href="/assets/Node.js笔记.html-edd6db0d.js" as="script"><link rel="prefetch" href="/assets/Promise.html-83aba73d.js" as="script"><link rel="prefetch" href="/assets/Git.html-ef4b5f14.js" as="script"><link rel="prefetch" href="/assets/Markdown语法基础.html-2825f872.js" as="script"><link rel="prefetch" href="/assets/操作系统.html-8bed0f34.js" as="script"><link rel="prefetch" href="/assets/数据结构.html-6f1a0269.js" as="script"><link rel="prefetch" href="/assets/正则表达式.html-be164830.js" as="script"><link rel="prefetch" href="/assets/计算机组成原理.html-2668b30e.js" as="script"><link rel="prefetch" href="/assets/计算机网络.html-b11deb88.js" as="script"><link rel="prefetch" href="/assets/设计模式.html-35cadb50.js" as="script"><link rel="prefetch" href="/assets/面向对象设计基本原则.html-edb429fa.js" as="script"><link rel="prefetch" href="/assets/Docker.html-9f4e5ab9.js" as="script"><link rel="prefetch" href="/assets/GitHub Actions.html-bc1f64fb.js" as="script"><link rel="prefetch" href="/assets/基于centos部署java项目.html-b44ac3d3.js" as="script"><link rel="prefetch" href="/assets/一些插件.html-7333e5f0.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-c14413e6.js" as="script"><link rel="prefetch" href="/assets/CSGO饰品图.html-41566c4f.js" as="script"><link rel="prefetch" href="/assets/基础.html-376a9d53.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-ff145bec.js" as="script"><link rel="prefetch" href="/assets/Guitar.html-88bc41a7.js" as="script"><link rel="prefetch" href="/assets/hlae.html-5be4d809.js" as="script"><link rel="prefetch" href="/assets/settings.html-ed8baefd.js" as="script"><link rel="prefetch" href="/assets/index.html-71b38232.js" as="script"><link rel="prefetch" href="/assets/index.html-648f386b.js" as="script"><link rel="prefetch" href="/assets/30天JavaScript挑战.html-90b1a895.js" as="script"><link rel="prefetch" href="/assets/高频 SQL 50 题（基础版）.html-405179ee.js" as="script"><link rel="prefetch" href="/assets/多线程.html-46ffbab2.js" as="script"><link rel="prefetch" href="/assets/noob-Rg-better.html-cc14aa26.js" as="script"><link rel="prefetch" href="/assets/noob-Rg.html-3a2fdcc8.js" as="script"><link rel="prefetch" href="/assets/1、JavaScript基础语法笔记.html-69b3cd61.js" as="script"><link rel="prefetch" href="/assets/2、WebAPIs笔记.html-a8c50328.js" as="script"><link rel="prefetch" href="/assets/3、JavaScript进阶.html-180a19d8.js" as="script"><link rel="prefetch" href="/assets/leetcode228_汇总区间.html-cddb8f7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_001_两数之和.html-4d2935f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_002_两数相加.html-fe20f202.js" as="script"><link rel="prefetch" href="/assets/leetcode_003_无重复字符的最长子串.html-267e65ef.js" as="script"><link rel="prefetch" href="/assets/leetcode_004_寻找两个正序数组的中位数.html-9efd45da.js" as="script"><link rel="prefetch" href="/assets/leetcode_005_最长回文子串.html-39e1fea9.js" as="script"><link rel="prefetch" href="/assets/leetcode_006_N 字形变换.html-b4f920fe.js" as="script"><link rel="prefetch" href="/assets/leetcode_007_整数反转.html-4dd1c7a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_008_字符串转换整数 (atoi).html-fa0a27da.js" as="script"><link rel="prefetch" href="/assets/leetcode_009_回文数.html-55377a9f.js" as="script"><link rel="prefetch" href="/assets/leetcode_010_正则表达式匹配.html-674b100d.js" as="script"><link rel="prefetch" href="/assets/leetcode_011_盛最多水的容器.html-c8a38d1c.js" as="script"><link rel="prefetch" href="/assets/leetcode_012_整数转罗马数字.html-6b38adef.js" as="script"><link rel="prefetch" href="/assets/leetcode_013_罗马数字转整数.html-22c1adfb.js" as="script"><link rel="prefetch" href="/assets/leetcode_014_最长公共前缀.html-c172cec6.js" as="script"><link rel="prefetch" href="/assets/leetcode_015_三数之和.html-875a5ed0.js" as="script"><link rel="prefetch" href="/assets/leetcode_016_最接近的三数之和.html-b931e3c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_017_电话号码的字母组合.html-6d899101.js" as="script"><link rel="prefetch" href="/assets/leetcode_018_四数之和.html-087b71dc.js" as="script"><link rel="prefetch" href="/assets/leetcode_019_删除链表的倒数第 N 个结点.html-8241fe9c.js" as="script"><link rel="prefetch" href="/assets/leetcode_020_有效的括号.html-e07e2181.js" as="script"><link rel="prefetch" href="/assets/leetcode_021_合并两个有序链表.html-3e5fdc85.js" as="script"><link rel="prefetch" href="/assets/leetcode_022_括号生成.html-34027bae.js" as="script"><link rel="prefetch" href="/assets/leetcode_023_合并 K 个升序链表.html-2830aabf.js" as="script"><link rel="prefetch" href="/assets/leetcode_024_两两交换链表中的节点.html-aa44f045.js" as="script"><link rel="prefetch" href="/assets/leetcode_025_K 个一组翻转链表.html-1cb0de2d.js" as="script"><link rel="prefetch" href="/assets/leetcode_026_删除有序数组中的重复项.html-bf359f60.js" as="script"><link rel="prefetch" href="/assets/leetcode_027_移除元素.html-529831e9.js" as="script"><link rel="prefetch" href="/assets/leetcode_028_找出字符串中第一个匹配项的下标.html-dc2e4f17.js" as="script"><link rel="prefetch" href="/assets/leetcode_029_两数相除.html-03436b7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_030_串联所有单词的子串.html-faa41612.js" as="script"><link rel="prefetch" href="/assets/leetcode_031_下一个排列.html-1bf62ff0.js" as="script"><link rel="prefetch" href="/assets/leetcode_032_最长有效括号.html-dbd4329f.js" as="script"><link rel="prefetch" href="/assets/leetcode_033_搜索旋转排序数组.html-b3f9f227.js" as="script"><link rel="prefetch" href="/assets/leetcode_034_在排序数组中查找元素的第一个和最后一个位置.html-df6d34be.js" as="script"><link rel="prefetch" href="/assets/leetcode_035_搜索插入位置.html-f3871315.js" as="script"><link rel="prefetch" href="/assets/leetcode_036_有效的数独.html-5f2bc80d.js" as="script"><link rel="prefetch" href="/assets/leetcode_038_外观数列.html-6e3a5b1a.js" as="script"><link rel="prefetch" href="/assets/leetcode_039_ 组合总和.html-b0a7cd1a.js" as="script"><link rel="prefetch" href="/assets/leetcode_040_ 组合总和II.html-87cd31b2.js" as="script"><link rel="prefetch" href="/assets/leetcode_041_ 缺失的第一个正数.html-c08437a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_042_接雨水.html-4f929eb5.js" as="script"><link rel="prefetch" href="/assets/leetcode_043_字符串相乘.html-81486896.js" as="script"><link rel="prefetch" href="/assets/leetcode_045_跳跃游戏II.html-a0a07e13.js" as="script"><link rel="prefetch" href="/assets/leetcode_046_全排列.html-8e33255c.js" as="script"><link rel="prefetch" href="/assets/leetcode_047_全排列II.html-bc7cb387.js" as="script"><link rel="prefetch" href="/assets/leetcode_048_旋转图像.html-ec0a782c.js" as="script"><link rel="prefetch" href="/assets/leetcode_049_字母异位词分组.html-dc410cab.js" as="script"><link rel="prefetch" href="/assets/leetcode_050_Pow(x_n).html-29adea25.js" as="script"><link rel="prefetch" href="/assets/leetcode_051_N 皇后.html-54792019.js" as="script"><link rel="prefetch" href="/assets/leetcode_052_N 皇后 II.html-cae35ca8.js" as="script"><link rel="prefetch" href="/assets/leetcode_053_最大子数组和.html-f84751f2.js" as="script"><link rel="prefetch" href="/assets/leetcode_054_螺旋矩阵.html-7c2f26d1.js" as="script"><link rel="prefetch" href="/assets/leetcode_055_跳跃游戏.html-196b4f14.js" as="script"><link rel="prefetch" href="/assets/leetcode_056_合并区间.html-3c8d49b7.js" as="script"><link rel="prefetch" href="/assets/leetcode_058_最后一个单词的长度.html-c74c97db.js" as="script"><link rel="prefetch" href="/assets/leetcode_061_旋转链表.html-c1b9f0bb.js" as="script"><link rel="prefetch" href="/assets/leetcode_062_不同路径.html-5571caa7.js" as="script"><link rel="prefetch" href="/assets/leetcode_063_不同路径II.html-761d387b.js" as="script"><link rel="prefetch" href="/assets/leetcode_064_最小路径和.html-cecd8a72.js" as="script"><link rel="prefetch" href="/assets/leetcode_066_加一.html-12eefde8.js" as="script"><link rel="prefetch" href="/assets/leetcode_067_二进制求和.html-555cfc00.js" as="script"><link rel="prefetch" href="/assets/leetcode_068_文本左右对齐.html-7a5c575d.js" as="script"><link rel="prefetch" href="/assets/leetcode_069_x的平方根.html-b20ef54c.js" as="script"><link rel="prefetch" href="/assets/leetcode_070_爬楼梯.html-d52a7e95.js" as="script"><link rel="prefetch" href="/assets/leetcode_072_编辑距离.html-00a22365.js" as="script"><link rel="prefetch" href="/assets/leetcode_073_矩阵置零.html-2bf295e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_075_颜色分类.html-5d29d6eb.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串 copy.html-dba3ee02.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串.html-58de2813.js" as="script"><link rel="prefetch" href="/assets/leetcode_079_单词搜索.html-c3ecad05.js" as="script"><link rel="prefetch" href="/assets/leetcode_080_删除有序数组中的重复项.html-ad954572.js" as="script"><link rel="prefetch" href="/assets/leetcode_082_删除排序链表中的重复元素 II.html-ffc51573.js" as="script"><link rel="prefetch" href="/assets/leetcode_083_删除排序链表中的重复元素.html-70bf5bb7.js" as="script"><link rel="prefetch" href="/assets/leetcode_086_分隔链表.html-79aea5ef.js" as="script"><link rel="prefetch" href="/assets/leetcode_088_合并两个有序数组.html-ba540966.js" as="script"><link rel="prefetch" href="/assets/leetcode_092_反转链表 II.html-23caaca0.js" as="script"><link rel="prefetch" href="/assets/leetcode_094_二叉树的中序遍历.html-8288cdbe.js" as="script"><link rel="prefetch" href="/assets/leetcode_095_不同的二叉搜索树 II.html-47652036.js" as="script"><link rel="prefetch" href="/assets/leetcode_096_不同的二叉搜索树.html-ae75ff17.js" as="script"><link rel="prefetch" href="/assets/leetcode_098_验证二叉搜索树.html-03e5a7b1.js" as="script"><link rel="prefetch" href="/assets/leetcode_1004_最大连续1的个数 III.html-5533e255.js" as="script"><link rel="prefetch" href="/assets/leetcode_100_相同的树.html-b3027eaa.js" as="script"><link rel="prefetch" href="/assets/leetcode_101_对称二叉树.html-ce76548e.js" as="script"><link rel="prefetch" href="/assets/leetcode_102_二叉树的层序遍历.html-bf767249.js" as="script"><link rel="prefetch" href="/assets/leetcode_103_二叉树的锯齿形层序遍历.html-c877409c.js" as="script"><link rel="prefetch" href="/assets/leetcode_104_二叉树的最大深度.html-1b32579f.js" as="script"><link rel="prefetch" href="/assets/leetcode_105_从前序与中序遍历序列构造二叉树.html-d13a65a1.js" as="script"><link rel="prefetch" href="/assets/leetcode_106_从中序与后序遍历序列构造二叉树.html-a6327af2.js" as="script"><link rel="prefetch" href="/assets/leetcode_1071_字符串的最大公因子.html-5476c3fe.js" as="script"><link rel="prefetch" href="/assets/leetcode_107_二叉树的层序遍历 II.html-8d1b9daf.js" as="script"><link rel="prefetch" href="/assets/leetcode_108_将有序数组转换为二叉搜索树.html-56c9fcfb.js" as="script"><link rel="prefetch" href="/assets/leetcode_112_路径总和.html-bde85dfa.js" as="script"><link rel="prefetch" href="/assets/leetcode_113_路径总和II.html-8f74fe65.js" as="script"><link rel="prefetch" href="/assets/leetcode_1143_最长公共子序列.html-99c668c7.js" as="script"><link rel="prefetch" href="/assets/leetcode_114_二叉树展开为链表.html-bdd88a01.js" as="script"><link rel="prefetch" href="/assets/leetcode_1161_最大层内元素和.html-fcb209f5.js" as="script"><link rel="prefetch" href="/assets/leetcode_117_填充每个节点的下一个右侧节点指针 II.html-764ce2a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_118_杨辉三角.html-479e30a4.js" as="script"><link rel="prefetch" href="/assets/leetcode_119_杨辉三角 II.html-a59406df.js" as="script"><link rel="prefetch" href="/assets/leetcode_1207_独一无二的出现次数.html-16dda148.js" as="script"><link rel="prefetch" href="/assets/leetcode_120_三角形最小路径和.html-86703591.js" as="script"><link rel="prefetch" href="/assets/leetcode_121_买卖股票的最佳时机 I.html-13626864.js" as="script"><link rel="prefetch" href="/assets/leetcode_122_买卖股票的最佳时机 II.html-bb37bd6e.js" as="script"><link rel="prefetch" href="/assets/leetcode_124_二叉树中的最大路径和.html-8e211f55.js" as="script"><link rel="prefetch" href="/assets/leetcode_125_验证回文串.html-90dfd796.js" as="script"><link rel="prefetch" href="/assets/leetcode_128_最长连续序列.html-8b798fa6.js" as="script"><link rel="prefetch" href="/assets/leetcode_129_求根节点到叶节点数字之和.html-8758fc10.js" as="script"><link rel="prefetch" href="/assets/leetcode_130_被围绕的区域.html-31108440.js" as="script"><link rel="prefetch" href="/assets/leetcode_1318_或运算的最小翻转次数.html-b1d00d09.js" as="script"><link rel="prefetch" href="/assets/leetcode_134_加油站.html-aa290400.js" as="script"><link rel="prefetch" href="/assets/leetcode_135_分发糖果.html-169212a1.js" as="script"><link rel="prefetch" href="/assets/leetcode_136_只出现一次的数字.html-efac1a41.js" as="script"><link rel="prefetch" href="/assets/leetcode_1372_二叉树中的最长交错路径.html-1f702f8e.js" as="script"><link rel="prefetch" href="/assets/leetcode_139_单词拆分.html-60a3eec6.js" as="script"><link rel="prefetch" href="/assets/leetcode_141_环形链表.html-caf4560c.js" as="script"><link rel="prefetch" href="/assets/leetcode_1431_拥有最多糖果的孩子.html-c46bc216.js" as="script"><link rel="prefetch" href="/assets/leetcode_1448_统计二叉树中好节点的数目.html-badf2d7e.js" as="script"><link rel="prefetch" href="/assets/leetcode_144_二叉树的前序遍历.html-782a3002.js" as="script"><link rel="prefetch" href="/assets/leetcode_1456_定长子串中元音的最大数目.html-0bebd911.js" as="script"><link rel="prefetch" href="/assets/leetcode_145_二叉树的后序遍历.html-f423c8ea.js" as="script"><link rel="prefetch" href="/assets/leetcode_1466_重新规划路线.html-61eb288d.js" as="script"><link rel="prefetch" href="/assets/leetcode_146_LRU 缓存.html-ef476ae2.js" as="script"><link rel="prefetch" href="/assets/leetcode_148_排序链表.html-6835afd8.js" as="script"><link rel="prefetch" href="/assets/leetcode_1493_删掉一个元素以后全为 1 的最长子数组.html-1c9feb8e.js" as="script"><link rel="prefetch" href="/assets/leetcode_150_逆波兰表达式求值.html-8c4709cc.js" as="script"><link rel="prefetch" href="/assets/leetcode_151_反转字符串中的单词.html-f91b8216.js" as="script"><link rel="prefetch" href="/assets/leetcode_155_最小栈.html-20c00992.js" as="script"><link rel="prefetch" href="/assets/leetcode_160_相交链表.html-5627acf7.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值 copy.html-f24beb30.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值.html-42e7d40f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1657_确定两个字符串是否接近.html-8a42e6de.js" as="script"><link rel="prefetch" href="/assets/leetcode_1679_K 和数对的最大数目.html-75040006.js" as="script"><link rel="prefetch" href="/assets/leetcode_169_多数元素.html-b7c60141.js" as="script"><link rel="prefetch" href="/assets/leetcode_1732_找到最高海拔.html-7ecbb8c1.js" as="script"><link rel="prefetch" href="/assets/leetcode_173_二叉搜索树迭代器.html-5f9afb5f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1768_交替合并字符串.html-fa23ddd6.js" as="script"><link rel="prefetch" href="/assets/leetcode_189_轮转数组.html-c42a0832.js" as="script"><link rel="prefetch" href="/assets/leetcode_1926_迷宫中离入口最近的出口.html-ba13a452.js" as="script"><link rel="prefetch" href="/assets/leetcode_198_打家劫舍.html-01ddc8ed.js" as="script"><link rel="prefetch" href="/assets/leetcode_199. 二叉树的右视图.html-b4044b3b.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数 copy.html-4128158a.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数.html-df50f511.js" as="script"><link rel="prefetch" href="/assets/leetcode_203_移除链表元素.html-e917fc2e.js" as="script"><link rel="prefetch" href="/assets/leetcode_206_反转链表.html-c20741fc.js" as="script"><link rel="prefetch" href="/assets/leetcode_208_实现 Trie (前缀树).html-b62d7f4f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2095_删除链表的中间节点.html-deb3033e.js" as="script"><link rel="prefetch" href="/assets/leetcode_209_长度最小的子数组.html-b4fb933f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2130_链表最大孪生和.html-d152e296.js" as="script"><link rel="prefetch" href="/assets/leetcode_215_数组中的第K个最大元素.html-facb19af.js" as="script"><link rel="prefetch" href="/assets/leetcode_216_组合总和 III.html-449b0a0b.js" as="script"><link rel="prefetch" href="/assets/leetcode_219_存在重复元素 II.html-426b13a6.js" as="script"><link rel="prefetch" href="/assets/leetcode_2215_找出两数组的不同.html-8f3c9866.js" as="script"><link rel="prefetch" href="/assets/leetcode_222_完全二叉树的节点个数.html-e247e501.js" as="script"><link rel="prefetch" href="/assets/leetcode_226_翻转二叉树.html-a6fe8a1b.js" as="script"><link rel="prefetch" href="/assets/leetcode_2300. 咒语和药水的成功对数.html-451a870e.js" as="script"><link rel="prefetch" href="/assets/leetcode_230_二叉搜索树中第K小的元素.html-8f9aff36.js" as="script"><link rel="prefetch" href="/assets/leetcode_2336_无限集中的最小数字.html-0186d2f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_234_回文链表.html-5ffc51ac.js" as="script"><link rel="prefetch" href="/assets/leetcode_2352_相等行列对.html-aa32ea65.js" as="script"><link rel="prefetch" href="/assets/leetcode_236_二叉树的最近公共祖先.html-067dc510.js" as="script"><link rel="prefetch" href="/assets/leetcode_238_除自身以外数组的乘积.html-d416e8f0.js" as="script"><link rel="prefetch" href="/assets/leetcode_2390_从字符串中移除星号.html-f97fadc9.js" as="script"><link rel="prefetch" href="/assets/leetcode_242_有效的字母异位词.html-50564962.js" as="script"><link rel="prefetch" href="/assets/leetcode_2542_最大序列的分数.html-f5e8bf7d.js" as="script"><link rel="prefetch" href="/assets/leetcode_274_H指数.html-219397c4.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy 2.html-2ece538f.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy.html-b2dcfc16.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0.html-28326917.js" as="script"><link rel="prefetch" href="/assets/leetcode_300_最长递增子序列.html-7bc25e46.js" as="script"><link rel="prefetch" href="/assets/leetcode_322_零钱兑换.html-338820d0.js" as="script"><link rel="prefetch" href="/assets/leetcode_328_奇偶链表.html-c221c5e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_334_递增的三元子序列.html-eaa7359c.js" as="script"><link rel="prefetch" href="/assets/leetcode_338_比特位计数.html-1ca3e264.js" as="script"><link rel="prefetch" href="/assets/leetcode_345_反转字符串中的元音字母.html-a53a56ed.js" as="script"><link rel="prefetch" href="/assets/leetcode_374_猜数字大小.html-838e47cd.js" as="script"><link rel="prefetch" href="/assets/leetcode_380_O(1) 时间插入、删除和获取随机元素.html-809dfc48.js" as="script"><link rel="prefetch" href="/assets/leetcode_383_赎金信.html-b140905d.js" as="script"><link rel="prefetch" href="/assets/leetcode_392_判断子序列.html-0f679959.js" as="script"><link rel="prefetch" href="/assets/leetcode_394_字符串解码.html-34dbf0a9.js" as="script"><link rel="prefetch" href="/assets/leetcode_435_无重叠区间.html-a86bed80.js" as="script"><link rel="prefetch" href="/assets/leetcode_437_路径总和 III.html-03d25af8.js" as="script"><link rel="prefetch" href="/assets/leetcode_443_压缩字符串.html-04e19523.js" as="script"><link rel="prefetch" href="/assets/leetcode_450_删除二叉搜索树中的节点.html-b96c20de.js" as="script"><link rel="prefetch" href="/assets/leetcode_452_用最少数量的箭引爆气球.html-38e27162.js" as="script"><link rel="prefetch" href="/assets/leetcode_530_二叉搜索树的最小绝对差.html-67141eeb.js" as="script"><link rel="prefetch" href="/assets/leetcode_547_省份数量.html-b3b6bac4.js" as="script"><link rel="prefetch" href="/assets/leetcode_605_种花问题.html-031d3116.js" as="script"><link rel="prefetch" href="/assets/leetcode_637_二叉树的层平均值.html-a7a36db9.js" as="script"><link rel="prefetch" href="/assets/leetcode_643_子数组最大平均数 I.html-a8f43e75.js" as="script"><link rel="prefetch" href="/assets/leetcode_649_Dota2 参议院.html-57e2951e.js" as="script"><link rel="prefetch" href="/assets/leetcode_700_二叉搜索树中的搜索.html-023dc167.js" as="script"><link rel="prefetch" href="/assets/leetcode_714_买卖股票的最佳时机含手续费.html-7ad01ab6.js" as="script"><link rel="prefetch" href="/assets/leetcode_724_寻找数组的中心下标.html-71388c1f.js" as="script"><link rel="prefetch" href="/assets/leetcode_735_行星碰撞.html-79670bf6.js" as="script"><link rel="prefetch" href="/assets/leetcode_739_每日温度.html-00bbc948.js" as="script"><link rel="prefetch" href="/assets/leetcode_746_使用最小花费爬楼梯.html-568fe2b8.js" as="script"><link rel="prefetch" href="/assets/leetcode_790_多米诺和托米诺平铺.html-e3681c3f.js" as="script"><link rel="prefetch" href="/assets/leetcode_841_钥匙和房间.html-75e3c562.js" as="script"><link rel="prefetch" href="/assets/leetcode_872_叶子相似的树.html-4ff19ccc.js" as="script"><link rel="prefetch" href="/assets/leetcode_875_爱吃香蕉的珂珂.html-c23d801c.js" as="script"><link rel="prefetch" href="/assets/leetcode_876_链表的中间结点.html-e827b29b.js" as="script"><link rel="prefetch" href="/assets/leetcode_901_股票价格跨度.html-6195f435.js" as="script"><link rel="prefetch" href="/assets/leetcode_933_最近的请求次数.html-b601ebe2.js" as="script"><link rel="prefetch" href="/assets/leetcode_994_腐烂的橘子.html-c9fcbc99.js" as="script"><link rel="prefetch" href="/assets/leetcode_LCP68_美丽的花束.html-bea99396.js" as="script"><link rel="prefetch" href="/assets/1、TypeScript语言简介.html-ecee5a2a.js" as="script"><link rel="prefetch" href="/assets/2、基本用法.html-8e7f792b.js" as="script"><link rel="prefetch" href="/assets/3、any，unknown ，never 类型.html-92d935e7.js" as="script"><link rel="prefetch" href="/assets/4、系统类型.html-564a8c20.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-74cacfb8.js" as="script"><link rel="prefetch" href="/assets/6、元祖.html-df4609ec.js" as="script"><link rel="prefetch" href="/assets/7、symbol 类型.html-459544bf.js" as="script"><link rel="prefetch" href="/assets/8、函数.html-c5c268c2.js" as="script"><link rel="prefetch" href="/assets/index.html-9b0abc8d.js" as="script"><link rel="prefetch" href="/assets/Arrays类.html-5cff467d.js" as="script"><link rel="prefetch" href="/assets/BigInteger和BigDecimal.html-b00a56b8.js" as="script"><link rel="prefetch" href="/assets/Collections类.html-6e3e4ec0.js" as="script"><link rel="prefetch" href="/assets/Java比较器.html-f75c5cab.js" as="script"><link rel="prefetch" href="/assets/Math类.html-66218b19.js" as="script"><link rel="prefetch" href="/assets/Object类.html-43eeba34.js" as="script"><link rel="prefetch" href="/assets/Pattern 与 Matcher 类.html-ee7d45a1.js" as="script"><link rel="prefetch" href="/assets/Stream API.html-9b418bda.js" as="script"><link rel="prefetch" href="/assets/String、Scanner相关类.html-ab539520.js" as="script"><link rel="prefetch" href="/assets/System类.html-0388d0ad.js" as="script"><link rel="prefetch" href="/assets/日期时间API.html-abcd5dc6.js" as="script"><link rel="prefetch" href="/assets/10、多线程.html-35e659db.js" as="script"><link rel="prefetch" href="/assets/11、枚举类.html-0bf87ec6.js" as="script"><link rel="prefetch" href="/assets/12、注解.html-50944a71.js" as="script"><link rel="prefetch" href="/assets/13、集合.html-9439bdbe.js" as="script"><link rel="prefetch" href="/assets/14、泛型.html-d7592650.js" as="script"><link rel="prefetch" href="/assets/15、IO流.html-515b20a8.js" as="script"><link rel="prefetch" href="/assets/16、网络编程.html-d4102567.js" as="script"><link rel="prefetch" href="/assets/17、反射.html-539859f0.js" as="script"><link rel="prefetch" href="/assets/18、新特性.html-ef7a4719.js" as="script"><link rel="prefetch" href="/assets/19、格式化输入输出.html-9690fc0f.js" as="script"><link rel="prefetch" href="/assets/1、基础概念.html-8e40e2f0.js" as="script"><link rel="prefetch" href="/assets/2、数据类型.html-7994f88b.js" as="script"><link rel="prefetch" href="/assets/3、运算符.html-457a2f56.js" as="script"><link rel="prefetch" href="/assets/4、程序流程控制.html-7c29dc6c.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-a4c355fe.js" as="script"><link rel="prefetch" href="/assets/6、面向对象.html-ad3a75f9.js" as="script"><link rel="prefetch" href="/assets/7、单元测试Junit.html-6c06e896.js" as="script"><link rel="prefetch" href="/assets/8、包装类.html-91494c0b.js" as="script"><link rel="prefetch" href="/assets/9、异常处理.html-efeedf1f.js" as="script"><link rel="prefetch" href="/assets/网络架构.html-7e97e386.js" as="script"><link rel="prefetch" href="/assets/1、Pytorch 建模流程.html-bc26fc1e.js" as="script"><link rel="prefetch" href="/assets/2、张量数据结构.html-369a6bfb.js" as="script"><link rel="prefetch" href="/assets/3、自动微分机制、优化器.html-a51e51d3.js" as="script"><link rel="prefetch" href="/assets/4、动态计算图.html-6751486b.js" as="script"><link rel="prefetch" href="/assets/5、Pytorch 低阶 API.html-384aa62f.js" as="script"><link rel="prefetch" href="/assets/6、Pytorch 中阶 API.html-12d00ec0.js" as="script"><link rel="prefetch" href="/assets/Pytorch-20.html-26d96f13.js" as="script"><link rel="prefetch" href="/assets/Pytorch.html-d1d2957f.js" as="script"><link rel="prefetch" href="/assets/强化学习.html-936d4c17.js" as="script"><link rel="prefetch" href="/assets/Vue笔记1-核心.html-e989c925.js" as="script"><link rel="prefetch" href="/assets/Vue笔记2-组件.html-8621d7cf.js" as="script"><link rel="prefetch" href="/assets/Vue笔记3-脚手架.html-de68fd83.js" as="script"><link rel="prefetch" href="/assets/Vue笔记4-Vue中的ajax.html-df24fe68.js" as="script"><link rel="prefetch" href="/assets/Vue笔记5-插槽.html-3155ce14.js" as="script"><link rel="prefetch" href="/assets/Vue笔记6-vuex.html-90ee75fa.js" as="script"><link rel="prefetch" href="/assets/Vue笔记7-路由.html-9023e075.js" as="script"><link rel="prefetch" href="/assets/Vue笔记8-element-ui.html-a3b54a99.js" as="script"><link rel="prefetch" href="/assets/Vue3快速上手.html-943296f4.js" as="script"><link rel="prefetch" href="/assets/markdown扩展.html-1b4673b3.js" as="script"><link rel="prefetch" href="/assets/404.html-cc91ab3d.js" as="script"><link rel="prefetch" href="/assets/index.html-4d071ae6.js" as="script"><link rel="prefetch" href="/assets/index.html-a6b9d739.js" as="script"><link rel="prefetch" href="/assets/index.html-673bc96c.js" as="script"><link rel="prefetch" href="/assets/index.html-a7a29c4c.js" as="script"><link rel="prefetch" href="/assets/index.html-194b0620.js" as="script"><link rel="prefetch" href="/assets/index.html-a899c6cf.js" as="script"><link rel="prefetch" href="/assets/index.html-e2494c9f.js" as="script"><link rel="prefetch" href="/assets/index.html-61c0a09c.js" as="script"><link rel="prefetch" href="/assets/index.html-be2636ab.js" as="script"><link rel="prefetch" href="/assets/index.html-67b37d25.js" as="script"><link rel="prefetch" href="/assets/index.html-2f703168.js" as="script"><link rel="prefetch" href="/assets/index.html-49eef8d8.js" as="script"><link rel="prefetch" href="/assets/index.html-2d0de498.js" as="script"><link rel="prefetch" href="/assets/index.html-2fa96ec7.js" as="script"><link rel="prefetch" href="/assets/index.html-d9cf3019.js" as="script"><link rel="prefetch" href="/assets/index.html-6d51d871.js" as="script"><link rel="prefetch" href="/assets/index.html-d782a376.js" as="script"><link rel="prefetch" href="/assets/index.html-848ebbe8.js" as="script"><link rel="prefetch" href="/assets/index.html-1ba1d180.js" as="script"><link rel="prefetch" href="/assets/index.html-9e55ee4d.js" as="script"><link rel="prefetch" href="/assets/index.html-106d954c.js" as="script"><link rel="prefetch" href="/assets/index.html-5fbc2a0d.js" as="script"><link rel="prefetch" href="/assets/index.html-c03d1584.js" as="script"><link rel="prefetch" href="/assets/index.html-9c648683.js" as="script"><link rel="prefetch" href="/assets/index.html-1c24935a.js" as="script"><link rel="prefetch" href="/assets/index.html-99af66e2.js" as="script"><link rel="prefetch" href="/assets/index.html-ee02ddf0.js" as="script"><link rel="prefetch" href="/assets/index.html-20b834a5.js" as="script"><link rel="prefetch" href="/assets/index.html-3a4d6e36.js" as="script"><link rel="prefetch" href="/assets/index.html-139f2f06.js" as="script"><link rel="prefetch" href="/assets/index.html-a935f094.js" as="script"><link rel="prefetch" href="/assets/index.html-e92ce08c.js" as="script"><link rel="prefetch" href="/assets/index.html-63bc6b2b.js" as="script"><link rel="prefetch" href="/assets/index.html-94957f61.js" as="script"><link rel="prefetch" href="/assets/index.html-91bcd141.js" as="script"><link rel="prefetch" href="/assets/index.html-e5933818.js" as="script"><link rel="prefetch" href="/assets/index.html-abd11527.js" as="script"><link rel="prefetch" href="/assets/index.html-d6c5a433.js" as="script"><link rel="prefetch" href="/assets/index.html-ec18a7df.js" as="script"><link rel="prefetch" href="/assets/index.html-d3624e38.js" as="script"><link rel="prefetch" href="/assets/index.html-13f98761.js" as="script"><link rel="prefetch" href="/assets/index.html-0cce8e2d.js" as="script"><link rel="prefetch" href="/assets/index.html-7193a535.js" as="script"><link rel="prefetch" href="/assets/index.html-0e85c606.js" as="script"><link rel="prefetch" href="/assets/index.html-41fd6d63.js" as="script"><link rel="prefetch" href="/assets/index.html-faa3c911.js" as="script"><link rel="prefetch" href="/assets/index.html-bfb66f86.js" as="script"><link rel="prefetch" href="/assets/index.html-f5020150.js" as="script"><link rel="prefetch" href="/assets/index.html-5c2c76d5.js" as="script"><link rel="prefetch" href="/assets/index.html-a2feaac9.js" as="script"><link rel="prefetch" href="/assets/index.html-b7b8c4b6.js" as="script"><link rel="prefetch" href="/assets/index.html-ff6eb04f.js" as="script"><link rel="prefetch" href="/assets/index.html-a3550230.js" as="script"><link rel="prefetch" href="/assets/index.html-7a3254b0.js" as="script"><link rel="prefetch" href="/assets/index.html-c5715831.js" as="script"><link rel="prefetch" href="/assets/index.html-8af2a3d1.js" as="script"><link rel="prefetch" href="/assets/index.html-9d2fd3be.js" as="script"><link rel="prefetch" href="/assets/index.html-e9a4a4e1.js" as="script"><link rel="prefetch" href="/assets/index.html-cc614db6.js" as="script"><link rel="prefetch" href="/assets/index.html-b772e465.js" as="script"><link rel="prefetch" href="/assets/index.html-b1a752fe.js" as="script"><link rel="prefetch" href="/assets/index.html-4209efbb.js" as="script"><link rel="prefetch" href="/assets/index.html-4ff744ba.js" as="script"><link rel="prefetch" href="/assets/index.html-c424e42c.js" as="script"><link rel="prefetch" href="/assets/index.html-7f168d0f.js" as="script"><link rel="prefetch" href="/assets/index.html-56de2f95.js" as="script"><link rel="prefetch" href="/assets/index.html-f7cb97d3.js" as="script"><link rel="prefetch" href="/assets/index.html-c546e8a1.js" as="script"><link rel="prefetch" href="/assets/index.html-0009964a.js" as="script"><link rel="prefetch" href="/assets/index.html-00b637a2.js" as="script"><link rel="prefetch" href="/assets/index.html-fb5f6e90.js" as="script"><link rel="prefetch" href="/assets/index.html-ac4d56df.js" as="script"><link rel="prefetch" href="/assets/index.html-6aa2d78e.js" as="script"><link rel="prefetch" href="/assets/index.html-d462cdeb.js" as="script"><link rel="prefetch" href="/assets/index.html-6b698fb1.js" as="script"><link rel="prefetch" href="/assets/index.html-acbfbf53.js" as="script"><link rel="prefetch" href="/assets/index.html-905f1804.js" as="script"><link rel="prefetch" href="/assets/index.html-16d7d340.js" as="script"><link rel="prefetch" href="/assets/index.html-46271911.js" as="script"><link rel="prefetch" href="/assets/index.html-b604d4ee.js" as="script"><link rel="prefetch" href="/assets/index.html-14c05c19.js" as="script"><link rel="prefetch" href="/assets/index.html-f310c092.js" as="script"><link rel="prefetch" href="/assets/index.html-ccaf9ee9.js" as="script"><link rel="prefetch" href="/assets/index.html-e22bc441.js" as="script"><link rel="prefetch" href="/assets/index.html-1c66cf59.js" as="script"><link rel="prefetch" href="/assets/index.html-8208559f.js" as="script"><link rel="prefetch" href="/assets/index.html-2aea38ab.js" as="script"><link rel="prefetch" href="/assets/index.html-9c6eba41.js" as="script"><link rel="prefetch" href="/assets/index.html-38a7a2af.js" as="script"><link rel="prefetch" href="/assets/index.html-c8b179d7.js" as="script"><link rel="prefetch" href="/assets/index.html-7e1863fb.js" as="script"><link rel="prefetch" href="/assets/index.html-8968a188.js" as="script"><link rel="prefetch" href="/assets/index.html-64ee687b.js" as="script"><link rel="prefetch" href="/assets/index.html-80fe2383.js" as="script"><link rel="prefetch" href="/assets/index.html-fea946c3.js" as="script"><link rel="prefetch" href="/assets/index.html-f17f8ab5.js" as="script"><link rel="prefetch" href="/assets/index.html-1a5be529.js" as="script"><link rel="prefetch" href="/assets/index.html-0e767346.js" as="script"><link rel="prefetch" href="/assets/index.html-3ca31bd8.js" as="script"><link rel="prefetch" href="/assets/index.html-b133f8c8.js" as="script"><link rel="prefetch" href="/assets/index.html-7195b3a2.js" as="script"><link rel="prefetch" href="/assets/index.html-1beacc22.js" as="script"><link rel="prefetch" href="/assets/index.html-88e5e4ce.js" as="script"><link rel="prefetch" href="/assets/index.html-210be80e.js" as="script"><link rel="prefetch" href="/assets/index.html-f33d538b.js" as="script"><link rel="prefetch" href="/assets/index.html-4941c0fe.js" as="script"><link rel="prefetch" href="/assets/index.html-c736be09.js" as="script"><link rel="prefetch" href="/assets/index.html-03c9f91d.js" as="script"><link rel="prefetch" href="/assets/index.html-0b4b9ae3.js" as="script"><link rel="prefetch" href="/assets/index.html-229119d0.js" as="script"><link rel="prefetch" href="/assets/index.html-bc2fb4cf.js" as="script"><link rel="prefetch" href="/assets/index.html-1c4a3288.js" as="script"><link rel="prefetch" href="/assets/index.html-842d27e2.js" as="script"><link rel="prefetch" href="/assets/index.html-b4206ac4.js" as="script"><link rel="prefetch" href="/assets/index.html-73e0d1d2.js" as="script"><link rel="prefetch" href="/assets/index.html-72b69436.js" as="script"><link rel="prefetch" href="/assets/index.html-3477f208.js" as="script"><link rel="prefetch" href="/assets/index.html-7c416790.js" as="script"><link rel="prefetch" href="/assets/index.html-2fa8126d.js" as="script"><link rel="prefetch" href="/assets/index.html-c4278da5.js" as="script"><link rel="prefetch" href="/assets/index.html-97b358be.js" as="script"><link rel="prefetch" href="/assets/index.html-a3c429a2.js" as="script"><link rel="prefetch" href="/assets/index.html-e28d3b12.js" as="script"><link rel="prefetch" href="/assets/index.html-e18dcbc2.js" as="script"><link rel="prefetch" href="/assets/index.html-9cbad9b7.js" as="script"><link rel="prefetch" href="/assets/index.html-c02de52a.js" as="script"><link rel="prefetch" href="/assets/index.html-375eef32.js" as="script"><link rel="prefetch" href="/assets/index.html-3b8fb7db.js" as="script"><link rel="prefetch" href="/assets/index.html-2b8d0809.js" as="script"><link rel="prefetch" href="/assets/index.html-186dd8fe.js" as="script"><link rel="prefetch" href="/assets/index.html-62cabbed.js" as="script"><link rel="prefetch" href="/assets/index.html-869377bc.js" as="script"><link rel="prefetch" href="/assets/index.html-9e0c0478.js" as="script"><link rel="prefetch" href="/assets/index.html-5043e7e4.js" as="script"><link rel="prefetch" href="/assets/Elasticsearch.html-437025c1.js" as="script"><link rel="prefetch" href="/assets/MongoDB.html-25b1cecf.js" as="script"><link rel="prefetch" href="/assets/MySQL基础.html-0ddc049d.js" as="script"><link rel="prefetch" href="/assets/Redis.html-70fd5aa1.js" as="script"><link rel="prefetch" href="/assets/IDEA、Eclipse快捷键.html-b57cef48.js" as="script"><link rel="prefetch" href="/assets/JDBC.html-66b0b827.js" as="script"><link rel="prefetch" href="/assets/JVM.html-7cd13c65.js" as="script"><link rel="prefetch" href="/assets/JVM入门.html-50a73810.js" as="script"><link rel="prefetch" href="/assets/JWT.html-a1b29690.js" as="script"><link rel="prefetch" href="/assets/JavaWeb基础.html-41a29361.js" as="script"><link rel="prefetch" href="/assets/Maven基础.html-ad22f103.js" as="script"><link rel="prefetch" href="/assets/MyBatis.html-17a90147.js" as="script"><link rel="prefetch" href="/assets/MybatisPlus.html-58d04eaa.js" as="script"><link rel="prefetch" href="/assets/RabbitMQ.html-ee514b8f.js" as="script"><link rel="prefetch" href="/assets/Shiro.html-5f92207b.js" as="script"><link rel="prefetch" href="/assets/SpringBoot.html-6d892a84.js" as="script"><link rel="prefetch" href="/assets/SpringBoot常用注解总结.html-f29d6acb.js" as="script"><link rel="prefetch" href="/assets/SpringBoot自动装配原理.html-835d0fdf.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础.html-fd3a27df.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础2024.html-9b88c952.js" as="script"><link rel="prefetch" href="/assets/SpringMVC.html-e7e72d28.js" as="script"><link rel="prefetch" href="/assets/Spring基础.html-a2eaea06.js" as="script"><link rel="prefetch" href="/assets/index.html-ca81cc05.js" as="script"><link rel="prefetch" href="/assets/Matplotlib.html-a6359f6a.js" as="script"><link rel="prefetch" href="/assets/Numpy.html-35d9f920.js" as="script"><link rel="prefetch" href="/assets/Pandas.html-6f04370a.js" as="script"><link rel="prefetch" href="/assets/python 基础语法.html-a3aed805.js" as="script"><link rel="prefetch" href="/assets/python 项目注意事项.html-ee9803a7.js" as="script"><link rel="prefetch" href="/assets/Ajax.html-17a74240.js" as="script"><link rel="prefetch" href="/assets/Axios.html-d7ae5762.js" as="script"><link rel="prefetch" href="/assets/CSS3.html-5f601096.js" as="script"><link rel="prefetch" href="/assets/HTML.html-43768a8b.js" as="script"><link rel="prefetch" href="/assets/Node.js笔记.html-b7a740fc.js" as="script"><link rel="prefetch" href="/assets/Promise.html-475877e2.js" as="script"><link rel="prefetch" href="/assets/Git.html-5e00f6f6.js" as="script"><link rel="prefetch" href="/assets/Markdown语法基础.html-e5fea8a8.js" as="script"><link rel="prefetch" href="/assets/操作系统.html-d69804bf.js" as="script"><link rel="prefetch" href="/assets/数据结构.html-1324e738.js" as="script"><link rel="prefetch" href="/assets/正则表达式.html-24e6ee15.js" as="script"><link rel="prefetch" href="/assets/计算机组成原理.html-c5931e8f.js" as="script"><link rel="prefetch" href="/assets/计算机网络.html-b0659649.js" as="script"><link rel="prefetch" href="/assets/设计模式.html-0e333ab7.js" as="script"><link rel="prefetch" href="/assets/面向对象设计基本原则.html-113b6ab1.js" as="script"><link rel="prefetch" href="/assets/Docker.html-de987d32.js" as="script"><link rel="prefetch" href="/assets/GitHub Actions.html-bda7c07a.js" as="script"><link rel="prefetch" href="/assets/基于centos部署java项目.html-1e9c2862.js" as="script"><link rel="prefetch" href="/assets/一些插件.html-0170d056.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-6ae121b3.js" as="script"><link rel="prefetch" href="/assets/CSGO饰品图.html-c3efd34a.js" as="script"><link rel="prefetch" href="/assets/基础.html-56d4dd7c.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-e2f39a54.js" as="script"><link rel="prefetch" href="/assets/Guitar.html-a506f5fd.js" as="script"><link rel="prefetch" href="/assets/hlae.html-69e932b9.js" as="script"><link rel="prefetch" href="/assets/settings.html-de2b3cb4.js" as="script"><link rel="prefetch" href="/assets/index.html-5e841747.js" as="script"><link rel="prefetch" href="/assets/index.html-b23a3dc1.js" as="script"><link rel="prefetch" href="/assets/30天JavaScript挑战.html-204f8779.js" as="script"><link rel="prefetch" href="/assets/高频 SQL 50 题（基础版）.html-a775d14b.js" as="script"><link rel="prefetch" href="/assets/多线程.html-4e1dde4d.js" as="script"><link rel="prefetch" href="/assets/noob-Rg-better.html-cd070d14.js" as="script"><link rel="prefetch" href="/assets/noob-Rg.html-a40f13b2.js" as="script"><link rel="prefetch" href="/assets/1、JavaScript基础语法笔记.html-c4ff792a.js" as="script"><link rel="prefetch" href="/assets/2、WebAPIs笔记.html-b8b0ad3a.js" as="script"><link rel="prefetch" href="/assets/3、JavaScript进阶.html-d78d0d84.js" as="script"><link rel="prefetch" href="/assets/leetcode228_汇总区间.html-08754ee6.js" as="script"><link rel="prefetch" href="/assets/leetcode_001_两数之和.html-fc48ebfc.js" as="script"><link rel="prefetch" href="/assets/leetcode_002_两数相加.html-dd446c2b.js" as="script"><link rel="prefetch" href="/assets/leetcode_003_无重复字符的最长子串.html-4b9551ad.js" as="script"><link rel="prefetch" href="/assets/leetcode_004_寻找两个正序数组的中位数.html-4353979e.js" as="script"><link rel="prefetch" href="/assets/leetcode_005_最长回文子串.html-f9ea55fb.js" as="script"><link rel="prefetch" href="/assets/leetcode_006_N 字形变换.html-c0e51bf1.js" as="script"><link rel="prefetch" href="/assets/leetcode_007_整数反转.html-716540dc.js" as="script"><link rel="prefetch" href="/assets/leetcode_008_字符串转换整数 (atoi).html-fb233f0f.js" as="script"><link rel="prefetch" href="/assets/leetcode_009_回文数.html-874c5d9c.js" as="script"><link rel="prefetch" href="/assets/leetcode_010_正则表达式匹配.html-052802a8.js" as="script"><link rel="prefetch" href="/assets/leetcode_011_盛最多水的容器.html-69a0459d.js" as="script"><link rel="prefetch" href="/assets/leetcode_012_整数转罗马数字.html-76656ec7.js" as="script"><link rel="prefetch" href="/assets/leetcode_013_罗马数字转整数.html-9afce7ee.js" as="script"><link rel="prefetch" href="/assets/leetcode_014_最长公共前缀.html-c3d96ea9.js" as="script"><link rel="prefetch" href="/assets/leetcode_015_三数之和.html-69828b6a.js" as="script"><link rel="prefetch" href="/assets/leetcode_016_最接近的三数之和.html-6d0caa23.js" as="script"><link rel="prefetch" href="/assets/leetcode_017_电话号码的字母组合.html-c5bf8fc0.js" as="script"><link rel="prefetch" href="/assets/leetcode_018_四数之和.html-77bc40bc.js" as="script"><link rel="prefetch" href="/assets/leetcode_019_删除链表的倒数第 N 个结点.html-b8090058.js" as="script"><link rel="prefetch" href="/assets/leetcode_020_有效的括号.html-0d03a2b5.js" as="script"><link rel="prefetch" href="/assets/leetcode_021_合并两个有序链表.html-0c9890ea.js" as="script"><link rel="prefetch" href="/assets/leetcode_022_括号生成.html-875eb34c.js" as="script"><link rel="prefetch" href="/assets/leetcode_023_合并 K 个升序链表.html-7bb091bd.js" as="script"><link rel="prefetch" href="/assets/leetcode_024_两两交换链表中的节点.html-8698e3bf.js" as="script"><link rel="prefetch" href="/assets/leetcode_025_K 个一组翻转链表.html-385f003f.js" as="script"><link rel="prefetch" href="/assets/leetcode_026_删除有序数组中的重复项.html-593ce0f6.js" as="script"><link rel="prefetch" href="/assets/leetcode_027_移除元素.html-13b5d9d0.js" as="script"><link rel="prefetch" href="/assets/leetcode_028_找出字符串中第一个匹配项的下标.html-253f103a.js" as="script"><link rel="prefetch" href="/assets/leetcode_029_两数相除.html-ab6f9843.js" as="script"><link rel="prefetch" href="/assets/leetcode_030_串联所有单词的子串.html-e2f96c71.js" as="script"><link rel="prefetch" href="/assets/leetcode_031_下一个排列.html-6e572841.js" as="script"><link rel="prefetch" href="/assets/leetcode_032_最长有效括号.html-2ff62db1.js" as="script"><link rel="prefetch" href="/assets/leetcode_033_搜索旋转排序数组.html-b6fd8b64.js" as="script"><link rel="prefetch" href="/assets/leetcode_034_在排序数组中查找元素的第一个和最后一个位置.html-6d576912.js" as="script"><link rel="prefetch" href="/assets/leetcode_035_搜索插入位置.html-8aefcf58.js" as="script"><link rel="prefetch" href="/assets/leetcode_036_有效的数独.html-16a895ec.js" as="script"><link rel="prefetch" href="/assets/leetcode_038_外观数列.html-1a0ea8bc.js" as="script"><link rel="prefetch" href="/assets/leetcode_039_ 组合总和.html-54148c3d.js" as="script"><link rel="prefetch" href="/assets/leetcode_040_ 组合总和II.html-8c462a4c.js" as="script"><link rel="prefetch" href="/assets/leetcode_041_ 缺失的第一个正数.html-c0b998ee.js" as="script"><link rel="prefetch" href="/assets/leetcode_042_接雨水.html-c8d63c6e.js" as="script"><link rel="prefetch" href="/assets/leetcode_043_字符串相乘.html-a91b7969.js" as="script"><link rel="prefetch" href="/assets/leetcode_045_跳跃游戏II.html-6e4abd0d.js" as="script"><link rel="prefetch" href="/assets/leetcode_046_全排列.html-6685e692.js" as="script"><link rel="prefetch" href="/assets/leetcode_047_全排列II.html-d47cb2ba.js" as="script"><link rel="prefetch" href="/assets/leetcode_048_旋转图像.html-48b9c1be.js" as="script"><link rel="prefetch" href="/assets/leetcode_049_字母异位词分组.html-7f36e34d.js" as="script"><link rel="prefetch" href="/assets/leetcode_050_Pow(x_n).html-93ff6e34.js" as="script"><link rel="prefetch" href="/assets/leetcode_051_N 皇后.html-4717bb08.js" as="script"><link rel="prefetch" href="/assets/leetcode_052_N 皇后 II.html-f072d0e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_053_最大子数组和.html-fe56c3b5.js" as="script"><link rel="prefetch" href="/assets/leetcode_054_螺旋矩阵.html-56e00241.js" as="script"><link rel="prefetch" href="/assets/leetcode_055_跳跃游戏.html-5a3b2116.js" as="script"><link rel="prefetch" href="/assets/leetcode_056_合并区间.html-3e339e45.js" as="script"><link rel="prefetch" href="/assets/leetcode_058_最后一个单词的长度.html-e29329a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_061_旋转链表.html-d6a12766.js" as="script"><link rel="prefetch" href="/assets/leetcode_062_不同路径.html-6b15150d.js" as="script"><link rel="prefetch" href="/assets/leetcode_063_不同路径II.html-d19a09ed.js" as="script"><link rel="prefetch" href="/assets/leetcode_064_最小路径和.html-5af3f431.js" as="script"><link rel="prefetch" href="/assets/leetcode_066_加一.html-22120f0c.js" as="script"><link rel="prefetch" href="/assets/leetcode_067_二进制求和.html-74a661e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_068_文本左右对齐.html-d8500303.js" as="script"><link rel="prefetch" href="/assets/leetcode_069_x的平方根.html-f81b5344.js" as="script"><link rel="prefetch" href="/assets/leetcode_070_爬楼梯.html-6d5e4d6d.js" as="script"><link rel="prefetch" href="/assets/leetcode_072_编辑距离.html-27bbe1d7.js" as="script"><link rel="prefetch" href="/assets/leetcode_073_矩阵置零.html-4ce1cb84.js" as="script"><link rel="prefetch" href="/assets/leetcode_075_颜色分类.html-b80f5db4.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串 copy.html-7bc32e41.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串.html-93eb1013.js" as="script"><link rel="prefetch" href="/assets/leetcode_079_单词搜索.html-5bcd3d94.js" as="script"><link rel="prefetch" href="/assets/leetcode_080_删除有序数组中的重复项.html-cda6b4e7.js" as="script"><link rel="prefetch" href="/assets/leetcode_082_删除排序链表中的重复元素 II.html-9362ec09.js" as="script"><link rel="prefetch" href="/assets/leetcode_083_删除排序链表中的重复元素.html-47b2f5dd.js" as="script"><link rel="prefetch" href="/assets/leetcode_086_分隔链表.html-7dcb337a.js" as="script"><link rel="prefetch" href="/assets/leetcode_088_合并两个有序数组.html-bca65e70.js" as="script"><link rel="prefetch" href="/assets/leetcode_092_反转链表 II.html-1f2c5869.js" as="script"><link rel="prefetch" href="/assets/leetcode_094_二叉树的中序遍历.html-e00b9386.js" as="script"><link rel="prefetch" href="/assets/leetcode_095_不同的二叉搜索树 II.html-36e21153.js" as="script"><link rel="prefetch" href="/assets/leetcode_096_不同的二叉搜索树.html-6711dfaa.js" as="script"><link rel="prefetch" href="/assets/leetcode_098_验证二叉搜索树.html-675e123e.js" as="script"><link rel="prefetch" href="/assets/leetcode_1004_最大连续1的个数 III.html-2d782d72.js" as="script"><link rel="prefetch" href="/assets/leetcode_100_相同的树.html-2aa2f3c0.js" as="script"><link rel="prefetch" href="/assets/leetcode_101_对称二叉树.html-cb22fd27.js" as="script"><link rel="prefetch" href="/assets/leetcode_102_二叉树的层序遍历.html-c189ca05.js" as="script"><link rel="prefetch" href="/assets/leetcode_103_二叉树的锯齿形层序遍历.html-86d70833.js" as="script"><link rel="prefetch" href="/assets/leetcode_104_二叉树的最大深度.html-7db76bbf.js" as="script"><link rel="prefetch" href="/assets/leetcode_105_从前序与中序遍历序列构造二叉树.html-5305134e.js" as="script"><link rel="prefetch" href="/assets/leetcode_106_从中序与后序遍历序列构造二叉树.html-e64147f7.js" as="script"><link rel="prefetch" href="/assets/leetcode_1071_字符串的最大公因子.html-0523e1fd.js" as="script"><link rel="prefetch" href="/assets/leetcode_107_二叉树的层序遍历 II.html-1a418454.js" as="script"><link rel="prefetch" href="/assets/leetcode_108_将有序数组转换为二叉搜索树.html-f7e0a38c.js" as="script"><link rel="prefetch" href="/assets/leetcode_112_路径总和.html-1c7ccb7d.js" as="script"><link rel="prefetch" href="/assets/leetcode_113_路径总和II.html-6f27866a.js" as="script"><link rel="prefetch" href="/assets/leetcode_1143_最长公共子序列.html-d7be9bbb.js" as="script"><link rel="prefetch" href="/assets/leetcode_114_二叉树展开为链表.html-9f9e759f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1161_最大层内元素和.html-675936c0.js" as="script"><link rel="prefetch" href="/assets/leetcode_117_填充每个节点的下一个右侧节点指针 II.html-8ffb0b73.js" as="script"><link rel="prefetch" href="/assets/leetcode_118_杨辉三角.html-8ff78181.js" as="script"><link rel="prefetch" href="/assets/leetcode_119_杨辉三角 II.html-6f45f181.js" as="script"><link rel="prefetch" href="/assets/leetcode_1207_独一无二的出现次数.html-96ecd1d5.js" as="script"><link rel="prefetch" href="/assets/leetcode_120_三角形最小路径和.html-0304edae.js" as="script"><link rel="prefetch" href="/assets/leetcode_121_买卖股票的最佳时机 I.html-8a6cb804.js" as="script"><link rel="prefetch" href="/assets/leetcode_122_买卖股票的最佳时机 II.html-db273729.js" as="script"><link rel="prefetch" href="/assets/leetcode_124_二叉树中的最大路径和.html-c49146ca.js" as="script"><link rel="prefetch" href="/assets/leetcode_125_验证回文串.html-b6f74c0e.js" as="script"><link rel="prefetch" href="/assets/leetcode_128_最长连续序列.html-267dfa7c.js" as="script"><link rel="prefetch" href="/assets/leetcode_129_求根节点到叶节点数字之和.html-2f9aa564.js" as="script"><link rel="prefetch" href="/assets/leetcode_130_被围绕的区域.html-631c7e37.js" as="script"><link rel="prefetch" href="/assets/leetcode_1318_或运算的最小翻转次数.html-6f852c47.js" as="script"><link rel="prefetch" href="/assets/leetcode_134_加油站.html-086708a6.js" as="script"><link rel="prefetch" href="/assets/leetcode_135_分发糖果.html-7a24ec5c.js" as="script"><link rel="prefetch" href="/assets/leetcode_136_只出现一次的数字.html-edf34f28.js" as="script"><link rel="prefetch" href="/assets/leetcode_1372_二叉树中的最长交错路径.html-68c84002.js" as="script"><link rel="prefetch" href="/assets/leetcode_139_单词拆分.html-c9ffb5a9.js" as="script"><link rel="prefetch" href="/assets/leetcode_141_环形链表.html-5094a97e.js" as="script"><link rel="prefetch" href="/assets/leetcode_1431_拥有最多糖果的孩子.html-0528bd0a.js" as="script"><link rel="prefetch" href="/assets/leetcode_1448_统计二叉树中好节点的数目.html-69cf1234.js" as="script"><link rel="prefetch" href="/assets/leetcode_144_二叉树的前序遍历.html-b7a6fba4.js" as="script"><link rel="prefetch" href="/assets/leetcode_1456_定长子串中元音的最大数目.html-e0fa879c.js" as="script"><link rel="prefetch" href="/assets/leetcode_145_二叉树的后序遍历.html-fb8ee0b4.js" as="script"><link rel="prefetch" href="/assets/leetcode_1466_重新规划路线.html-b09f862d.js" as="script"><link rel="prefetch" href="/assets/leetcode_146_LRU 缓存.html-25e45ccb.js" as="script"><link rel="prefetch" href="/assets/leetcode_148_排序链表.html-5eecbb47.js" as="script"><link rel="prefetch" href="/assets/leetcode_1493_删掉一个元素以后全为 1 的最长子数组.html-5eaee037.js" as="script"><link rel="prefetch" href="/assets/leetcode_150_逆波兰表达式求值.html-76937a7e.js" as="script"><link rel="prefetch" href="/assets/leetcode_151_反转字符串中的单词.html-43862cc6.js" as="script"><link rel="prefetch" href="/assets/leetcode_155_最小栈.html-405c9e5f.js" as="script"><link rel="prefetch" href="/assets/leetcode_160_相交链表.html-c4f33a46.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值 copy.html-0f8f6a92.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值.html-a87c0596.js" as="script"><link rel="prefetch" href="/assets/leetcode_1657_确定两个字符串是否接近.html-154139d1.js" as="script"><link rel="prefetch" href="/assets/leetcode_1679_K 和数对的最大数目.html-f40b3734.js" as="script"><link rel="prefetch" href="/assets/leetcode_169_多数元素.html-5cf530fc.js" as="script"><link rel="prefetch" href="/assets/leetcode_1732_找到最高海拔.html-3c385d07.js" as="script"><link rel="prefetch" href="/assets/leetcode_173_二叉搜索树迭代器.html-c1ec8746.js" as="script"><link rel="prefetch" href="/assets/leetcode_1768_交替合并字符串.html-fc2a1f76.js" as="script"><link rel="prefetch" href="/assets/leetcode_189_轮转数组.html-e71b232f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1926_迷宫中离入口最近的出口.html-90fe5373.js" as="script"><link rel="prefetch" href="/assets/leetcode_198_打家劫舍.html-5fe52812.js" as="script"><link rel="prefetch" href="/assets/leetcode_199. 二叉树的右视图.html-db36ff65.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数 copy.html-88afefba.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数.html-033185e6.js" as="script"><link rel="prefetch" href="/assets/leetcode_203_移除链表元素.html-91e14bb7.js" as="script"><link rel="prefetch" href="/assets/leetcode_206_反转链表.html-61ca2d33.js" as="script"><link rel="prefetch" href="/assets/leetcode_208_实现 Trie (前缀树).html-5306ed16.js" as="script"><link rel="prefetch" href="/assets/leetcode_2095_删除链表的中间节点.html-17eba02e.js" as="script"><link rel="prefetch" href="/assets/leetcode_209_长度最小的子数组.html-d5413fac.js" as="script"><link rel="prefetch" href="/assets/leetcode_2130_链表最大孪生和.html-35d7a965.js" as="script"><link rel="prefetch" href="/assets/leetcode_215_数组中的第K个最大元素.html-a10602a4.js" as="script"><link rel="prefetch" href="/assets/leetcode_216_组合总和 III.html-b14d2faf.js" as="script"><link rel="prefetch" href="/assets/leetcode_219_存在重复元素 II.html-cc577077.js" as="script"><link rel="prefetch" href="/assets/leetcode_2215_找出两数组的不同.html-0d632bd0.js" as="script"><link rel="prefetch" href="/assets/leetcode_222_完全二叉树的节点个数.html-22222621.js" as="script"><link rel="prefetch" href="/assets/leetcode_226_翻转二叉树.html-216427f4.js" as="script"><link rel="prefetch" href="/assets/leetcode_2300. 咒语和药水的成功对数.html-5113bccf.js" as="script"><link rel="prefetch" href="/assets/leetcode_230_二叉搜索树中第K小的元素.html-2256d4c2.js" as="script"><link rel="prefetch" href="/assets/leetcode_2336_无限集中的最小数字.html-55f87681.js" as="script"><link rel="prefetch" href="/assets/leetcode_234_回文链表.html-6ca95450.js" as="script"><link rel="prefetch" href="/assets/leetcode_2352_相等行列对.html-5febb6aa.js" as="script"><link rel="prefetch" href="/assets/leetcode_236_二叉树的最近公共祖先.html-fe2a03e9.js" as="script"><link rel="prefetch" href="/assets/leetcode_238_除自身以外数组的乘积.html-bc4d13df.js" as="script"><link rel="prefetch" href="/assets/leetcode_2390_从字符串中移除星号.html-c4cc4b66.js" as="script"><link rel="prefetch" href="/assets/leetcode_242_有效的字母异位词.html-bf3ecd01.js" as="script"><link rel="prefetch" href="/assets/leetcode_2542_最大序列的分数.html-16142d5a.js" as="script"><link rel="prefetch" href="/assets/leetcode_274_H指数.html-4b81ac5a.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy 2.html-ae60a07b.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy.html-a9e85e5a.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0.html-46c15db4.js" as="script"><link rel="prefetch" href="/assets/leetcode_300_最长递增子序列.html-30c594d0.js" as="script"><link rel="prefetch" href="/assets/leetcode_322_零钱兑换.html-dec4d73d.js" as="script"><link rel="prefetch" href="/assets/leetcode_328_奇偶链表.html-ee95c05d.js" as="script"><link rel="prefetch" href="/assets/leetcode_334_递增的三元子序列.html-7879ee66.js" as="script"><link rel="prefetch" href="/assets/leetcode_338_比特位计数.html-1aca7ef5.js" as="script"><link rel="prefetch" href="/assets/leetcode_345_反转字符串中的元音字母.html-fec6b6c6.js" as="script"><link rel="prefetch" href="/assets/leetcode_374_猜数字大小.html-2e5300f8.js" as="script"><link rel="prefetch" href="/assets/leetcode_380_O(1) 时间插入、删除和获取随机元素.html-fe1ceb7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_383_赎金信.html-0a5b9e10.js" as="script"><link rel="prefetch" href="/assets/leetcode_392_判断子序列.html-3265a5a6.js" as="script"><link rel="prefetch" href="/assets/leetcode_394_字符串解码.html-e178809e.js" as="script"><link rel="prefetch" href="/assets/leetcode_435_无重叠区间.html-14020f52.js" as="script"><link rel="prefetch" href="/assets/leetcode_437_路径总和 III.html-6ebb0fd9.js" as="script"><link rel="prefetch" href="/assets/leetcode_443_压缩字符串.html-08ba3135.js" as="script"><link rel="prefetch" href="/assets/leetcode_450_删除二叉搜索树中的节点.html-4350edef.js" as="script"><link rel="prefetch" href="/assets/leetcode_452_用最少数量的箭引爆气球.html-f8787cad.js" as="script"><link rel="prefetch" href="/assets/leetcode_530_二叉搜索树的最小绝对差.html-97a64aa5.js" as="script"><link rel="prefetch" href="/assets/leetcode_547_省份数量.html-0cd253d7.js" as="script"><link rel="prefetch" href="/assets/leetcode_605_种花问题.html-2308b414.js" as="script"><link rel="prefetch" href="/assets/leetcode_637_二叉树的层平均值.html-0447480d.js" as="script"><link rel="prefetch" href="/assets/leetcode_643_子数组最大平均数 I.html-9d207242.js" as="script"><link rel="prefetch" href="/assets/leetcode_649_Dota2 参议院.html-0946fd2e.js" as="script"><link rel="prefetch" href="/assets/leetcode_700_二叉搜索树中的搜索.html-1408cd68.js" as="script"><link rel="prefetch" href="/assets/leetcode_714_买卖股票的最佳时机含手续费.html-a273c743.js" as="script"><link rel="prefetch" href="/assets/leetcode_724_寻找数组的中心下标.html-d5f49617.js" as="script"><link rel="prefetch" href="/assets/leetcode_735_行星碰撞.html-dc3efbb1.js" as="script"><link rel="prefetch" href="/assets/leetcode_739_每日温度.html-7ff69298.js" as="script"><link rel="prefetch" href="/assets/leetcode_746_使用最小花费爬楼梯.html-c5c14732.js" as="script"><link rel="prefetch" href="/assets/leetcode_790_多米诺和托米诺平铺.html-3353a841.js" as="script"><link rel="prefetch" href="/assets/leetcode_841_钥匙和房间.html-a2342076.js" as="script"><link rel="prefetch" href="/assets/leetcode_872_叶子相似的树.html-810538ee.js" as="script"><link rel="prefetch" href="/assets/leetcode_875_爱吃香蕉的珂珂.html-3e43d32c.js" as="script"><link rel="prefetch" href="/assets/leetcode_876_链表的中间结点.html-e8f4e1e4.js" as="script"><link rel="prefetch" href="/assets/leetcode_901_股票价格跨度.html-e57e6ae8.js" as="script"><link rel="prefetch" href="/assets/leetcode_933_最近的请求次数.html-73d59e17.js" as="script"><link rel="prefetch" href="/assets/leetcode_994_腐烂的橘子.html-542f8ec1.js" as="script"><link rel="prefetch" href="/assets/leetcode_LCP68_美丽的花束.html-844776d3.js" as="script"><link rel="prefetch" href="/assets/1、TypeScript语言简介.html-8ea31da3.js" as="script"><link rel="prefetch" href="/assets/2、基本用法.html-9a4e65cd.js" as="script"><link rel="prefetch" href="/assets/3、any，unknown ，never 类型.html-c8b8141b.js" as="script"><link rel="prefetch" href="/assets/4、系统类型.html-be2b3811.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-01e2e101.js" as="script"><link rel="prefetch" href="/assets/6、元祖.html-a60203f3.js" as="script"><link rel="prefetch" href="/assets/7、symbol 类型.html-41995a74.js" as="script"><link rel="prefetch" href="/assets/8、函数.html-fdbd163c.js" as="script"><link rel="prefetch" href="/assets/index.html-837e49b6.js" as="script"><link rel="prefetch" href="/assets/Arrays类.html-37898e2a.js" as="script"><link rel="prefetch" href="/assets/BigInteger和BigDecimal.html-42c08d5b.js" as="script"><link rel="prefetch" href="/assets/Collections类.html-559ab7c1.js" as="script"><link rel="prefetch" href="/assets/Java比较器.html-f990a282.js" as="script"><link rel="prefetch" href="/assets/Math类.html-4cf07e09.js" as="script"><link rel="prefetch" href="/assets/Object类.html-30da13c2.js" as="script"><link rel="prefetch" href="/assets/Pattern 与 Matcher 类.html-c3807bf0.js" as="script"><link rel="prefetch" href="/assets/Stream API.html-81b9cff5.js" as="script"><link rel="prefetch" href="/assets/String、Scanner相关类.html-0945eeb9.js" as="script"><link rel="prefetch" href="/assets/System类.html-244bcfe4.js" as="script"><link rel="prefetch" href="/assets/日期时间API.html-d35a1f02.js" as="script"><link rel="prefetch" href="/assets/10、多线程.html-86b00b30.js" as="script"><link rel="prefetch" href="/assets/11、枚举类.html-c48b5017.js" as="script"><link rel="prefetch" href="/assets/12、注解.html-8663bee0.js" as="script"><link rel="prefetch" href="/assets/13、集合.html-7530600e.js" as="script"><link rel="prefetch" href="/assets/14、泛型.html-778aaa29.js" as="script"><link rel="prefetch" href="/assets/15、IO流.html-41d24aa2.js" as="script"><link rel="prefetch" href="/assets/16、网络编程.html-dd58e9d1.js" as="script"><link rel="prefetch" href="/assets/17、反射.html-170550bf.js" as="script"><link rel="prefetch" href="/assets/18、新特性.html-1a1ead2a.js" as="script"><link rel="prefetch" href="/assets/19、格式化输入输出.html-ff5fccf4.js" as="script"><link rel="prefetch" href="/assets/1、基础概念.html-487f9122.js" as="script"><link rel="prefetch" href="/assets/2、数据类型.html-5faa925e.js" as="script"><link rel="prefetch" href="/assets/3、运算符.html-c97b1945.js" as="script"><link rel="prefetch" href="/assets/4、程序流程控制.html-c9e9c6ac.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-53d01724.js" as="script"><link rel="prefetch" href="/assets/6、面向对象.html-c47280f0.js" as="script"><link rel="prefetch" href="/assets/7、单元测试Junit.html-547fc1c1.js" as="script"><link rel="prefetch" href="/assets/8、包装类.html-ed2df884.js" as="script"><link rel="prefetch" href="/assets/9、异常处理.html-062d5e3b.js" as="script"><link rel="prefetch" href="/assets/网络架构.html-0c9a575f.js" as="script"><link rel="prefetch" href="/assets/1、Pytorch 建模流程.html-e7f69be9.js" as="script"><link rel="prefetch" href="/assets/2、张量数据结构.html-7f176093.js" as="script"><link rel="prefetch" href="/assets/3、自动微分机制、优化器.html-511a3a09.js" as="script"><link rel="prefetch" href="/assets/4、动态计算图.html-55abe16e.js" as="script"><link rel="prefetch" href="/assets/5、Pytorch 低阶 API.html-f399389b.js" as="script"><link rel="prefetch" href="/assets/6、Pytorch 中阶 API.html-8445d222.js" as="script"><link rel="prefetch" href="/assets/Pytorch-20.html-aa31642e.js" as="script"><link rel="prefetch" href="/assets/Pytorch.html-f702739d.js" as="script"><link rel="prefetch" href="/assets/强化学习.html-a3fa0248.js" as="script"><link rel="prefetch" href="/assets/Vue笔记1-核心.html-67aad14c.js" as="script"><link rel="prefetch" href="/assets/Vue笔记2-组件.html-9d8d9e8a.js" as="script"><link rel="prefetch" href="/assets/Vue笔记3-脚手架.html-6991a254.js" as="script"><link rel="prefetch" href="/assets/Vue笔记4-Vue中的ajax.html-d36582cd.js" as="script"><link rel="prefetch" href="/assets/Vue笔记5-插槽.html-4b0e49dc.js" as="script"><link rel="prefetch" href="/assets/Vue笔记6-vuex.html-9a2415bd.js" as="script"><link rel="prefetch" href="/assets/Vue笔记7-路由.html-bd0eff71.js" as="script"><link rel="prefetch" href="/assets/Vue笔记8-element-ui.html-eadd0ea6.js" as="script"><link rel="prefetch" href="/assets/Vue3快速上手.html-a1b9f5ac.js" as="script"><link rel="prefetch" href="/assets/markdown扩展.html-a901d893.js" as="script"><link rel="prefetch" href="/assets/404.html-de3e783f.js" as="script"><link rel="prefetch" href="/assets/index.html-05b005fc.js" as="script"><link rel="prefetch" href="/assets/index.html-88ed9766.js" as="script"><link rel="prefetch" href="/assets/index.html-cf9478e0.js" as="script"><link rel="prefetch" href="/assets/index.html-792b9c2a.js" as="script"><link rel="prefetch" href="/assets/index.html-2627fec4.js" as="script"><link rel="prefetch" href="/assets/index.html-062c2317.js" as="script"><link rel="prefetch" href="/assets/index.html-5aa6f5d3.js" as="script"><link rel="prefetch" href="/assets/index.html-1ac6db78.js" as="script"><link rel="prefetch" href="/assets/index.html-a810cd69.js" as="script"><link rel="prefetch" href="/assets/index.html-d0e74486.js" as="script"><link rel="prefetch" href="/assets/index.html-ed231ab8.js" as="script"><link rel="prefetch" href="/assets/index.html-6c8c9674.js" as="script"><link rel="prefetch" href="/assets/index.html-533dd96d.js" as="script"><link rel="prefetch" href="/assets/index.html-14da24f7.js" as="script"><link rel="prefetch" href="/assets/index.html-a7c49452.js" as="script"><link rel="prefetch" href="/assets/index.html-05a68aab.js" as="script"><link rel="prefetch" href="/assets/index.html-bfaa8599.js" as="script"><link rel="prefetch" href="/assets/index.html-9c55d0c0.js" as="script"><link rel="prefetch" href="/assets/index.html-610d07a7.js" as="script"><link rel="prefetch" href="/assets/index.html-143ac05e.js" as="script"><link rel="prefetch" href="/assets/index.html-49bf244e.js" as="script"><link rel="prefetch" href="/assets/index.html-28c0758f.js" as="script"><link rel="prefetch" href="/assets/index.html-4db3568d.js" as="script"><link rel="prefetch" href="/assets/index.html-44e07f4b.js" as="script"><link rel="prefetch" href="/assets/index.html-3780fc30.js" as="script"><link rel="prefetch" href="/assets/index.html-84b94c4a.js" as="script"><link rel="prefetch" href="/assets/index.html-d2c4b6e5.js" as="script"><link rel="prefetch" href="/assets/index.html-66ba7e1f.js" as="script"><link rel="prefetch" href="/assets/index.html-64c01c01.js" as="script"><link rel="prefetch" href="/assets/index.html-e4daebab.js" as="script"><link rel="prefetch" href="/assets/index.html-32544faa.js" as="script"><link rel="prefetch" href="/assets/index.html-3bf8d89d.js" as="script"><link rel="prefetch" href="/assets/index.html-440bb9a5.js" as="script"><link rel="prefetch" href="/assets/index.html-b9849e9e.js" as="script"><link rel="prefetch" href="/assets/index.html-d78f4874.js" as="script"><link rel="prefetch" href="/assets/index.html-9bd8ad72.js" as="script"><link rel="prefetch" href="/assets/index.html-e4fae4c4.js" as="script"><link rel="prefetch" href="/assets/index.html-1a2dee55.js" as="script"><link rel="prefetch" href="/assets/index.html-961875dc.js" as="script"><link rel="prefetch" href="/assets/index.html-82cad33d.js" as="script"><link rel="prefetch" href="/assets/index.html-50a83565.js" as="script"><link rel="prefetch" href="/assets/index.html-0e64070d.js" as="script"><link rel="prefetch" href="/assets/index.html-094c7053.js" as="script"><link rel="prefetch" href="/assets/index.html-13e3d0c8.js" as="script"><link rel="prefetch" href="/assets/index.html-463e2df5.js" as="script"><link rel="prefetch" href="/assets/index.html-7e7eb480.js" as="script"><link rel="prefetch" href="/assets/index.html-b1b95c61.js" as="script"><link rel="prefetch" href="/assets/index.html-ca835bf7.js" as="script"><link rel="prefetch" href="/assets/index.html-94f50b81.js" as="script"><link rel="prefetch" href="/assets/index.html-0409ea3b.js" as="script"><link rel="prefetch" href="/assets/index.html-b2ef5b87.js" as="script"><link rel="prefetch" href="/assets/index.html-98e6b422.js" as="script"><link rel="prefetch" href="/assets/index.html-a7f475f3.js" as="script"><link rel="prefetch" href="/assets/index.html-c121cbb6.js" as="script"><link rel="prefetch" href="/assets/index.html-187a1ed0.js" as="script"><link rel="prefetch" href="/assets/index.html-94eb5ac1.js" as="script"><link rel="prefetch" href="/assets/index.html-968d1626.js" as="script"><link rel="prefetch" href="/assets/index.html-a08fec8a.js" as="script"><link rel="prefetch" href="/assets/index.html-e1496543.js" as="script"><link rel="prefetch" href="/assets/index.html-1c7d4457.js" as="script"><link rel="prefetch" href="/assets/index.html-c3aa2868.js" as="script"><link rel="prefetch" href="/assets/index.html-0b5768e0.js" as="script"><link rel="prefetch" href="/assets/index.html-cfa50cb7.js" as="script"><link rel="prefetch" href="/assets/index.html-a1ab96b4.js" as="script"><link rel="prefetch" href="/assets/index.html-ba0a7d21.js" as="script"><link rel="prefetch" href="/assets/index.html-92ba7175.js" as="script"><link rel="prefetch" href="/assets/index.html-6dd85329.js" as="script"><link rel="prefetch" href="/assets/index.html-3d265399.js" as="script"><link rel="prefetch" href="/assets/index.html-57cad8dc.js" as="script"><link rel="prefetch" href="/assets/index.html-83cdcfb2.js" as="script"><link rel="prefetch" href="/assets/index.html-9748cb26.js" as="script"><link rel="prefetch" href="/assets/index.html-76f2d321.js" as="script"><link rel="prefetch" href="/assets/index.html-e64794a3.js" as="script"><link rel="prefetch" href="/assets/index.html-ea5ccfaf.js" as="script"><link rel="prefetch" href="/assets/index.html-39aeb31e.js" as="script"><link rel="prefetch" href="/assets/index.html-e7b8a8a4.js" as="script"><link rel="prefetch" href="/assets/index.html-9e3315ab.js" as="script"><link rel="prefetch" href="/assets/index.html-b3e713aa.js" as="script"><link rel="prefetch" href="/assets/index.html-9e82a281.js" as="script"><link rel="prefetch" href="/assets/index.html-b5ad0d96.js" as="script"><link rel="prefetch" href="/assets/index.html-2099412e.js" as="script"><link rel="prefetch" href="/assets/index.html-f131c474.js" as="script"><link rel="prefetch" href="/assets/index.html-b4aeeee8.js" as="script"><link rel="prefetch" href="/assets/index.html-25ee8870.js" as="script"><link rel="prefetch" href="/assets/index.html-c982be6f.js" as="script"><link rel="prefetch" href="/assets/index.html-694fa037.js" as="script"><link rel="prefetch" href="/assets/index.html-6d48975d.js" as="script"><link rel="prefetch" href="/assets/index.html-fb395a20.js" as="script"><link rel="prefetch" href="/assets/index.html-bd47c5b6.js" as="script"><link rel="prefetch" href="/assets/index.html-ab509a4a.js" as="script"><link rel="prefetch" href="/assets/index.html-0bdd4246.js" as="script"><link rel="prefetch" href="/assets/index.html-cf4ca353.js" as="script"><link rel="prefetch" href="/assets/index.html-9ab8a47d.js" as="script"><link rel="prefetch" href="/assets/index.html-c730aabf.js" as="script"><link rel="prefetch" href="/assets/index.html-3decdaca.js" as="script"><link rel="prefetch" href="/assets/index.html-5e35fb0d.js" as="script"><link rel="prefetch" href="/assets/index.html-6def40dd.js" as="script"><link rel="prefetch" href="/assets/index.html-c79fc327.js" as="script"><link rel="prefetch" href="/assets/index.html-9967267a.js" as="script"><link rel="prefetch" href="/assets/index.html-0c0767e2.js" as="script"><link rel="prefetch" href="/assets/index.html-a8bfe770.js" as="script"><link rel="prefetch" href="/assets/index.html-755869b2.js" as="script"><link rel="prefetch" href="/assets/index.html-33d043e3.js" as="script"><link rel="prefetch" href="/assets/index.html-241faa04.js" as="script"><link rel="prefetch" href="/assets/index.html-06324811.js" as="script"><link rel="prefetch" href="/assets/index.html-901b5283.js" as="script"><link rel="prefetch" href="/assets/index.html-0bad2c80.js" as="script"><link rel="prefetch" href="/assets/index.html-26bd76cb.js" as="script"><link rel="prefetch" href="/assets/index.html-2005bdc9.js" as="script"><link rel="prefetch" href="/assets/index.html-d034ac7d.js" as="script"><link rel="prefetch" href="/assets/index.html-0994eff8.js" as="script"><link rel="prefetch" href="/assets/index.html-43f55b30.js" as="script"><link rel="prefetch" href="/assets/index.html-a0558e34.js" as="script"><link rel="prefetch" href="/assets/index.html-cd56d0fd.js" as="script"><link rel="prefetch" href="/assets/index.html-6acf22b5.js" as="script"><link rel="prefetch" href="/assets/index.html-e5c14607.js" as="script"><link rel="prefetch" href="/assets/index.html-3d863c56.js" as="script"><link rel="prefetch" href="/assets/index.html-13f9ca48.js" as="script"><link rel="prefetch" href="/assets/index.html-52d17234.js" as="script"><link rel="prefetch" href="/assets/index.html-7ab99d8f.js" as="script"><link rel="prefetch" href="/assets/index.html-c6ea490e.js" as="script"><link rel="prefetch" href="/assets/index.html-cfdad79f.js" as="script"><link rel="prefetch" href="/assets/index.html-7d95a480.js" as="script"><link rel="prefetch" href="/assets/index.html-20e5ea3c.js" as="script"><link rel="prefetch" href="/assets/index.html-f92b08ed.js" as="script"><link rel="prefetch" href="/assets/index.html-a2cb2e9f.js" as="script"><link rel="prefetch" href="/assets/index.html-357e21da.js" as="script"><link rel="prefetch" href="/assets/index.html-6d59b405.js" as="script"><link rel="prefetch" href="/assets/index.html-622eb83b.js" as="script"><link rel="prefetch" href="/assets/index.html-7dc80ecc.js" as="script"><link rel="prefetch" href="/assets/index.html-aa672a69.js" as="script"><link rel="prefetch" href="/assets/waline-meta-56fbc549.js" as="script"><link rel="prefetch" href="/assets/component-dea8dad9.js" as="script"><link rel="prefetch" href="/assets/auto-fa8841cf.js" as="script"><link rel="prefetch" href="/assets/index-a7d1ee58.js" as="script"><link rel="prefetch" href="/assets/flowchart-c441f34d.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-72498b39.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-abe06b83.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-ec5549c1.js" as="script"><link rel="prefetch" href="/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-fdf273e2.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-5794cde2.js" as="script"><link rel="prefetch" href="/assets/pageview-0e335d06.js" as="script"><link rel="prefetch" href="/assets/style-e9220a04.js" as="script"><link rel="prefetch" href="/assets/docsearch-1d421ddb.js" as="script"><link rel="prefetch" href="/assets/index-5161ad19.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand" href="/"><img class="vp-nav-logo" src="/favicon.ico" alt="T4mako"><!----><span class="vp-site-name hide-in-pad">T4mako</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a class="vp-link nav-link" href="/"><span class="font-icon icon iconfont icon-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="代码笔记"><span class="title"><span class="font-icon icon iconfont icon-code" style=""></span>代码笔记</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html"><!---->基础知识<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/java.html"><!---->Java<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91.html"><!---->前端开发<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/数据库.html"><!---->数据库<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E8%BF%90%E7%BB%B4%E4%B8%8E%E9%83%A8%E7%BD%B2.html"><!---->运维与部署<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link active" href="/code/python.html"><!---->Python<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/leetcode.html"><!---->Leetcode<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/project.html"><!---->项目笔记<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/其他.html"><!---->其他<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="兴趣使然"><span class="title"><span class="font-icon icon iconfont icon-view" style=""></span>兴趣使然</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/AE.html"><!---->AE<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/Blender.html"><!---->Blender<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/HLAE.html"><!---->HLAE<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/cook.html"><!---->吃饭糊弄学<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="生活碎片"><span class="title"><span class="font-icon icon iconfont icon-note" style=""></span>生活碎片</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/life/随笔.html"><!---->随笔<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/life/%E8%A7%82%E5%BD%B1%E5%8C%BA.html"><!---->观影区<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><a class="vp-link nav-link" href="/friends.html"><span class="font-icon icon iconfont icon-group" style=""></span>友链<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/T4mako/T4mako.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!----></h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/T4mako/T4mako.github.io" target="_blank" rel="noopener noreferrer">T4mako</a></span><span property="author" content="T4mako"></span></span><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_7-1、构建模型">7.1、构建模型</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-1-1、继承-nn-module-基类构建自定义模型">7.1.1、继承 nn.Module 基类构建自定义模型</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-1-2、使用-nn-sequential-按层顺序构建模型">7.1.2、使用 nn.Sequential 按层顺序构建模型</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装">7.1.3、继承 nn.Module 基类构建模型并辅助应用模型容器进行封装</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_7-2、训练模型">7.2、训练模型</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-0、准备数据">7.2.0、准备数据</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-1、脚本风格">7.2.1、脚本风格</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-2、函数风格">7.2.2、函数风格</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-3、类风格">7.2.3、类风格</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_7-3、使用-gpu-训练模型">7.3、使用 GPU 训练模型</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-0、gpu-相关操作汇总">7.3.0、GPU 相关操作汇总</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-1、矩阵乘法案例">7.3.1、矩阵乘法案例</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-2、线性回归范例">7.3.2、线性回归范例</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-3、图片分类范例">7.3.3、图片分类范例</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-4、torchkeras-kerasmodel-中使用-gpu">7.3.4、torchkeras.KerasModel 中使用 GPU</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h2 id="_7-1、构建模型" tabindex="-1"><a class="header-anchor" href="#_7-1、构建模型" aria-hidden="true">#</a> 7.1、构建模型</h2><p>构建模型有三种方法：</p><ol><li>继承 nn.Module 基类构建自定义模型（最常见）</li><li>使用 nn.Sequential 按层顺序构建模型（最简单）</li><li>继承 nn.Module 基类构建模型并辅助应用模型容器进行封装（nn.Sequential,nn.ModuleList,nn.ModuleDict）（最为灵活也较为复杂）</li></ol><p>模型定义好后，会给参数（w，b）赋值</p><blockquote><p>pytorch hub 模块，调用他人的网络架构</p></blockquote><h3 id="_7-1-1、继承-nn-module-基类构建自定义模型" tabindex="-1"><a class="header-anchor" href="#_7-1-1、继承-nn-module-基类构建自定义模型" aria-hidden="true">#</a> 7.1.1、继承 nn.Module 基类构建自定义模型</h3><p>模型中：</p><ul><li><strong>用到的层</strong> 在 <strong><code>__init__</code></strong> 函数中定义</li><li>在 <strong><code>forward</code></strong> 方法中定义模型的正向传播逻辑</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>adaptive_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>adaptive_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y
        
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-1-2、使用-nn-sequential-按层顺序构建模型" tabindex="-1"><a class="header-anchor" href="#_7-1-2、使用-nn-sequential-按层顺序构建模型" aria-hidden="true">#</a> 7.1.2、使用 nn.Sequential 按层顺序构建模型</h3><p>使用 nn.Sequential 按层顺序构建模型 <strong>无需定义 forward 方法。仅仅适合于简单的模型</strong>。</p><p>以下是使用 nn.Sequential 搭建模型的一些等价方法</p><ol><li><p>利用 add_module 方法</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>利用变长参数</p><p>这种方式构建时不能给每个层指定名称</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (4): Dropout2d(p=0.1, inplace=False)
  (5): AdaptiveMaxPool2d(output_size=(1, 1))
  (6): Flatten(start_dim=1, end_dim=-1)
  (7): Linear(in_features=64, out_features=32, bias=True)
  (8): ReLU()
  (9): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>利用 OrderedDict</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict

net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span>
          <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装" tabindex="-1"><a class="header-anchor" href="#_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装" aria-hidden="true">#</a> 7.1.3、继承 nn.Module 基类构建模型并辅助应用模型容器进行封装</h3><p>当模型的结构比较复杂时，我们可以应用模型容器（nn.Sequential,nn.ModuleList,nn.ModuleDict）对模型的部分结构进行封装</p><p>这样做会让模型整体更加有层次感，有时候也能减少代码量。</p><blockquote><p>注意，在下面的范例中我们每次仅仅使用一种模型容器，但实际上这些模型容器的使用是非常灵活的，可以在一个模型中任意组合任意嵌套使用。</p></blockquote><ol><li><p>nn.Sequential 作为模型容器</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y 
    
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (conv): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
  )
  (dense): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=64, out_features=32, bias=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>nn.ModuleList 作为模型容器</p><p>注意下面中的 ModuleList 不能用 Python 中的列表代替。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>nn.ModuleDict 作为模型容器</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers_dict <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;pool&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;conv2&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;dropout&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;adaptive&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;flatten&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;linear1&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;relu&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;linear2&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
              <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;pool&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;pool&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;adaptive&quot;</span><span class="token punctuation">,</span>
                  <span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>layers_dict<span class="token punctuation">[</span>layer<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers_dict): ModuleDict(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (adaptive): AdaptiveMaxPool2d(output_size=(1, 1))
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (linear1): Linear(in_features=64, out_features=32, bias=True)
    (relu): ReLU()
    (linear2): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h2 id="_7-2、训练模型" tabindex="-1"><a class="header-anchor" href="#_7-2、训练模型" aria-hidden="true">#</a> 7.2、训练模型</h2><p>Pytorch 通常需要用户编写自定义训练循环</p><p>有 3 类典型的训练循环代码风格：</p><ul><li>脚本形式训练循环</li><li>函数形式训练循环</li><li>类形式训练循环</li></ul><p><strong>训练模式</strong> 和 <strong>预测模式</strong> 的切换：</p><ul><li>一般在训练模型时加上 <strong>model.train()</strong>，这样会正常使用 Batch Normalization 和 Dropout</li><li>测试的时候选择 <strong>model.eval()</strong>，这样就不会使用 Batch Normalization 和 Dropout</li></ul><p>下面以 minist 数据集的多分类模型的训练为例，演示这 3 种训练模型的风格</p><p>其中类形式训练循环我们同时演示 torchkeras.KerasModel 和 torchkeras.LightModel 两种示范</p><h3 id="_7-2-0、准备数据" tabindex="-1"><a class="header-anchor" href="#_7-2-0、准备数据" aria-hidden="true">#</a> 7.2.0、准备数据</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">import</span> torchvision 
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

<span class="token comment"># 将图像数据转换为张量（tensor）</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

ds_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
ds_val <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

dl_train <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
dl_val <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 60000</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_val<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 10000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-1、脚本风格" tabindex="-1"><a class="header-anchor" href="#_7-2-1、脚本风格" aria-hidden="true">#</a> 7.2.1、脚本风格</h3><p>脚本风格的训练循环非常常见</p><p>构建模型：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 构建模型</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=10, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>训练模型</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm <span class="token comment"># 进度条库</span>

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

<span class="token comment"># 于打印带有时间戳的日志信息</span>
<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
    
<span class="token comment"># 交叉熵损失函数、Adam 优化器、准确率评估指标    </span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token comment"># 训练的轮数、检查点路径、早停监控指标、容忍度和模式，以及历史记录的字典</span>
epochs <span class="token operator">=</span> <span class="token number">20</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>
<span class="token comment"># early_stopping 相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">5</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token comment"># 在每个 epoch 中，首先进行训练模式的前向和反向传播，然后进行验证模式的前向传播，并记录损失和指标。所有指标和损失在每个 epoch 结束时都会被存储在 history 字典中</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    <span class="token comment"># 训练模式</span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 初始化本轮训练的总损失和步数计数器</span>
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token comment"># 使用 tqdm 包装数据加载器 dl_train，以显示训练进度条。enumerate函数用于生成数据批次的索引和值</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 深拷贝 metrics_dict，用于记录本轮训练的评估指标</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    <span class="token comment"># 遍历训练数据集 dl_train，每个 batch 是一个批次的训练数据</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        <span class="token comment"># 解包批次数据，features 是输入特征，labels 是对应的标签。</span>
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        <span class="token comment"># forward</span>
        <span class="token comment"># 向前传播，生成预测值</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        <span class="token comment"># 计算损失（目标函数）</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment"># backward 反向传播计算梯度。</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 使用优化器更新模型参数。</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 清零优化器中的梯度，以便下一步计算。</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment"># metrics</span>
        <span class="token comment"># 计算当前批次的评估指标，train_metrics_dict 中包含了准确率等指标。</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
        <span class="token comment"># 将当前批次的损失和评估指标存入 step_log 字典。</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 累加当前批次的损失到总损失中。</span>
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token comment"># 增加步数计数器。</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 如果不是最后一个批次，更新进度条的后缀为 step_log。如果是最后一个批次，计算整个 epoch 的平均损失和评估指标，更新进度条的后缀为epoch_log，并重置评估指标。            </span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    <span class="token comment"># 将模型设置为评估模式，禁用 dropout 等只在训练期间有效的层</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 初始化本轮验证的总损失和步数计数器</span>
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token comment"># 使用tqdm包装验证数据加载器dl_val，以显示验证进度条</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 深拷贝metrics_dict，用于记录本轮验证的评估指标</span>
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    <span class="token comment"># 禁用梯度计算，以节省内存并加快计算</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
		   <span class="token comment"># 解包批次数据，features是输入特征，labels是对应的标签</span>
            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment"># forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            <span class="token comment"># 计算当前批次的损失，使用预定义的损失函数 loss_fn</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment"># metrics</span>
            <span class="token comment"># 计算当前批次的评估指标，val_metrics_dict中包含了准确率等指标</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
		   <span class="token comment"># 将当前批次的损失和评估指标存入step_log字典</span>
            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
 		   <span class="token comment"># 累加当前批次的损失到总损失中。</span>
            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 增加步数计数器。</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token comment"># 如果不是最后一个批次，更新进度条的后缀为step_log。如果是最后一个批次，计算整个epoch的平均损失和评估指标，更新进度条的后缀为epoch_log，并重置评估指标。</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>
                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
    <span class="token comment"># 将本轮验证的损失和评估指标存入history字典中</span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    <span class="token comment"># 早停机制：根据验证集上的性能指标决定是否保存当前模型参数，并在指定的轮次内指标没有提升时停止训练</span>
    <span class="token comment"># 获取监控指标的历史记录</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    <span class="token comment"># 根据监控模式（最大化或最小化），找到最佳得分的索引</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token comment"># 如果当前轮次是最佳得分，保存模型参数，并打印提示信息。</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
    <span class="token comment"># 如果在指定的容忍度内（patience）没有取得进步，打印提示信息并停止训练。</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    <span class="token comment"># 加载保存的最佳模型参数。</span>
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 将历史记录转换为 DataFrame：</span>
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-2、函数风格" tabindex="-1"><a class="header-anchor" href="#_7-2-2、函数风格" aria-hidden="true">#</a> 7.2.2、函数风格</h3><p>该风格在脚本形式上做了进一步的函数封装</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=10, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">StepRunner</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> net<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span>
                 stage <span class="token operator">=</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span> metrics_dict <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> 
                 optimizer <span class="token operator">=</span> <span class="token boolean">None</span>
                 <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">,</span>self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">,</span>self<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">,</span>self<span class="token punctuation">.</span>stage <span class="token operator">=</span> net<span class="token punctuation">,</span>loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token punctuation">,</span>stage
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optimizer
            
    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#loss</span>
        preds <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward()</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>optimizer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>stage<span class="token operator">==</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span> 
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>step_metrics
    
    <span class="token keyword">def</span> <span class="token function">train_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#训练模式, dropout层发生作用</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
    
    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">eval_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#预测模式, dropout层不发生作用</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>stage<span class="token operator">==</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>train_step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span> 
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>eval_step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
<span class="token keyword">class</span> <span class="token class-name">EpochRunner</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>steprunner<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>steprunner <span class="token operator">=</span> steprunner
        self<span class="token punctuation">.</span>stage <span class="token operator">=</span> steprunner<span class="token punctuation">.</span>stage
        
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
        loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
            loss<span class="token punctuation">,</span> step_metrics <span class="token operator">=</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span>
            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
            total_loss <span class="token operator">+=</span> loss
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> epoch_log


<span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metrics_dict<span class="token punctuation">,</span> 
                train_data<span class="token punctuation">,</span> val_data<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> 
                epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span><span class="token punctuation">,</span>
                patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> monitor<span class="token operator">=</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&quot;min&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 1，train -------------------------------------------------  </span>
        train_step_runner <span class="token operator">=</span> StepRunner<span class="token punctuation">(</span>net <span class="token operator">=</span> net<span class="token punctuation">,</span>stage<span class="token operator">=</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span>
                loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token operator">=</span>deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span><span class="token punctuation">,</span>
                optimizer <span class="token operator">=</span> optimizer<span class="token punctuation">)</span>
        train_epoch_runner <span class="token operator">=</span> EpochRunner<span class="token punctuation">(</span>train_step_runner<span class="token punctuation">)</span>
        train_metrics <span class="token operator">=</span> train_epoch_runner<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>

        <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> train_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

        <span class="token comment"># 2，validate -------------------------------------------------</span>
        <span class="token keyword">if</span> val_data<span class="token punctuation">:</span>
            val_step_runner <span class="token operator">=</span> StepRunner<span class="token punctuation">(</span>net <span class="token operator">=</span> net<span class="token punctuation">,</span>stage<span class="token operator">=</span><span class="token string">&quot;val&quot;</span><span class="token punctuation">,</span>
                loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token operator">=</span>deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>
            val_epoch_runner <span class="token operator">=</span> EpochRunner<span class="token punctuation">(</span>val_step_runner<span class="token punctuation">)</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                val_metrics <span class="token operator">=</span> val_epoch_runner<span class="token punctuation">(</span>val_data<span class="token punctuation">)</span>
            val_metrics<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
            <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> val_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

        <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
        arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
        best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
        <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
                 arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
            <span class="token keyword">break</span> 
        net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

dfhistory <span class="token operator">=</span> train_model<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
    optimizer<span class="token punctuation">,</span>
    loss_fn<span class="token punctuation">,</span>
    metrics_dict<span class="token punctuation">,</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-3、类风格" tabindex="-1"><a class="header-anchor" href="#_7-2-3、类风格" aria-hidden="true">#</a> 7.2.3、类风格</h3><p>此处使用torchkeras.KerasModel高层次API接口中的fit方法训练模型。</p><p>使用该形式训练模型非常简洁明了</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> KerasModel 

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
    
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=10, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

model <span class="token operator">=</span> KerasModel<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
                   loss_fn<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                   optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">,</span>
    plot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    cpu<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_7-3、使用-gpu-训练模型" tabindex="-1"><a class="header-anchor" href="#_7-3、使用-gpu-训练模型" aria-hidden="true">#</a> 7.3、使用 GPU 训练模型</h2><p>训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代</p><ol><li>当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据</li><li>当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用 GPU 来进行加速</li></ol><p>Pytorch 中使用 GPU 加速模型非常简单，只要将模型和数据移动到 GPU 上。核心代码只有以下几行：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 定义模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动模型到 cuda</span>

<span class="token comment"># 训练模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动数据到 cuda</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 或者  labels = labels.cuda() if torch.cuda.is_available() else labels</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果要使用多个 GPU 训练模型，也非常简单。只需要在将模型设置为数据并行风格模型。 则模型移动到 GPU 上之后，会在每一个 GPU 上拷贝一个副本，并把数据平分到各个 GPU 上进行训练。核心代码如下：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 定义模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>model<span class="token punctuation">)</span> <span class="token comment"># 包装为并行风格模型</span>

<span class="token comment"># 训练模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动数据到 cuda</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 或者 labels = labels.cuda() if torch.cuda.is_available() else labels</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-0、gpu-相关操作汇总" tabindex="-1"><a class="header-anchor" href="#_7-3-0、gpu-相关操作汇总" aria-hidden="true">#</a> 7.3.0、GPU 相关操作汇总</h3><ol><li><p>查看 GPU 信息</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 

<span class="token comment"># 1，查看 gpu 信息</span>
if_cuda <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;if_cuda=&quot;</span><span class="token punctuation">,</span>if_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>

gpu_count <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;gpu_count=&quot;</span><span class="token punctuation">,</span>gpu_count<span class="token punctuation">)</span> <span class="token comment"># 1</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>将张量在 GPU 和 CPU 间移动</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 2，将张量在gpu和cpu间移动</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor_gpu <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 或者 tensor_gpu = tensor.cuda()</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_gpu<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_gpu<span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>

tensor_cpu <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 或者 tensor_cpu = tensor_gpu.cpu() </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_cpu<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cpu</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>将模型中的全部张量移动到 GPU 上</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 3，将模型中的全部张量移动到gpu上</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># False</span>
net<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 将模型中的全部参数张量依次到GPU上，注意，无需重新赋值为 net = net.to(&quot;cuda:0&quot;)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>创建支持多个 GPU 数据并行的模型</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 4，创建支持多个gpu数据并行的模型</span>
linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cpu</span>

model <span class="token operator">=</span> nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>linear<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>device_ids<span class="token punctuation">)</span> <span class="token comment"># [0]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>

<span class="token comment">#注意保存参数时要指定保存model.module的参数</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;model_parameter.pt&quot;</span><span class="token punctuation">)</span> 

linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
linear<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;model_parameter.pt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="_7-3-1、矩阵乘法案例" tabindex="-1"><a class="header-anchor" href="#_7-3-1、矩阵乘法案例" aria-hidden="true">#</a> 7.3.1、矩阵乘法案例</h3><p>下面分别使用 CPU 和 GPU 作一个矩阵乘法，并比较其计算效率。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> time
<span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

<span class="token comment"># 使用 CPU</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># 使用 Gpu</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">,</span>device <span class="token operator">=</span> device<span class="token punctuation">)</span> <span class="token comment">#可以指定在GPU上创建张量</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#也可以在CPU上创建张量后移动到GPU上</span>
b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment">#或者 b = b.cuda() if torch.cuda.is_available() else b </span>
tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-2、线性回归范例" tabindex="-1"><a class="header-anchor" href="#_7-3-2、线性回归范例" aria-hidden="true">#</a> 7.3.2、线性回归范例</h3><p>下面对比使用 CPU 和 GPU 训练一个线性回归模型的效率</p><p>使用 CPU：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 准备数据</span>
n <span class="token operator">=</span> <span class="token number">1000000</span> <span class="token comment">#样本数量</span>

X <span class="token operator">=</span> <span class="token number">10</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5.0</span>  <span class="token comment">#torch.rand是均匀分布 </span>
w0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> X@w0<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b0 <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># @表示矩阵乘法,增加正态扰动</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>w0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>b0<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#正向传播</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> x@self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        
linear <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 训练模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        Y_pred <span class="token operator">=</span> linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span> 
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>Y_pred<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> 
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch<span class="token operator">%</span><span class="token number">50</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">:</span>epoch<span class="token punctuation">,</span><span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;time used:&quot;</span><span class="token punctuation">,</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>

train<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 GPU：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 准备数据</span>
n <span class="token operator">=</span> <span class="token number">1000000</span> <span class="token comment"># 样本数量</span>

X <span class="token operator">=</span> <span class="token number">10</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5.0</span>  <span class="token comment">#torch.rand 是均匀分布 </span>
w0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> X@w0<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b0 <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># @表示矩阵乘法,增加正态扰动</span>

<span class="token comment"># 数据移动到 GPU 上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;torch.cuda.is_available() = &quot;</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> X<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> Y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;X.device:&quot;</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Y.device:&quot;</span><span class="token punctuation">,</span>Y<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>w0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>b0<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 正向传播</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> x@self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        
linear <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 移动模型到GPU上</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
linear<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 查看模型是否已经移动到 GPU 上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;if on cuda:&quot;</span><span class="token punctuation">,</span><span class="token builtin">next</span><span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        Y_pred <span class="token operator">=</span> linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span> 
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>Y_pred<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> 
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch<span class="token operator">%</span><span class="token number">50</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">:</span>epoch<span class="token punctuation">,</span><span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;time used:&quot;</span><span class="token punctuation">,</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
    
train<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-3、图片分类范例" tabindex="-1"><a class="header-anchor" href="#_7-3-3、图片分类范例" aria-hidden="true">#</a> 7.3.3、图片分类范例</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">import</span> torchvision 
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

<span class="token comment"># 准备数据</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
ds_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
ds_val <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
dl_train <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
dl_val <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_val<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">def</span> <span class="token function">create_net</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> net

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 CPU 训练：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
<span class="token comment">#注：多分类使用 torchmetrics 中的评估指标，二分类使用 torchkeras.metrics 中的评估指标</span>

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
    

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 

loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

epochs <span class="token operator">=</span> <span class="token number">3</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>

<span class="token comment">#early_stopping 相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">1</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        <span class="token comment">#forward</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 

            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment">#forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment">#metrics</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch           
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 GPU 训练：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
<span class="token comment">#注：多分类使用torchmetrics中的评估指标，二分类使用torchkeras.metrics中的评估指标</span>

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
    
net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 


loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>


<span class="token comment"># =========================移动模型到GPU上==============================</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
loss_fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token keyword">for</span> name<span class="token punctuation">,</span>fn <span class="token keyword">in</span> metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment"># ====================================================================</span>


epochs <span class="token operator">=</span> <span class="token number">5</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>

<span class="token comment">#early_stopping相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">1</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        
        <span class="token comment"># =========================移动数据到GPU上==============================</span>
        features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment"># ====================================================================</span>
        
        <span class="token comment">#forward</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 

            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment"># =========================移动数据到GPU上==============================</span>
            features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            <span class="token comment"># ====================================================================</span>
            
            <span class="token comment">#forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment">#metrics</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch           
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-4、torchkeras-kerasmodel-中使用-gpu" tabindex="-1"><a class="header-anchor" href="#_7-3-4、torchkeras-kerasmodel-中使用-gpu" aria-hidden="true">#</a> 7.3.4、torchkeras.KerasModel 中使用 GPU</h3><p>从上面的例子可以看到，在 pytorch 中使用 GPU 并不复杂，但对于经常炼丹的同学来说，模型和数据老是移来移去还是蛮麻烦的。</p><p>一不小心就会忘了移动某些数据或者某些 module，导致报错。</p><p>torchkeras.KerasModel 在设计的时候考虑到了这一点，如果环境当中存在可用的 GPU，会自动使用 GPU，反之则使用 CPU。</p><p>通过引入 accelerate 的一些基础功能，torchkeras.KerasModel 以非常优雅的方式在 GPU 和 CPU 之间切换。</p><p>详细实现可以参考 torchkeras.KerasModel 的源码。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span>  accelerate 
accelerator <span class="token operator">=</span> accelerate<span class="token punctuation">.</span>Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>accelerator<span class="token punctuation">.</span>device<span class="token punctuation">)</span>  <span class="token comment"># cuda</span>

<span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> KerasModel 
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 
model <span class="token operator">=</span> KerasModel<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
                   loss_fn<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                   optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/T4mako/T4mako.github.io/edit/main/src/code/python/Machine Learning/Pytorch/7、构建、训练模型.md" rel="noopener noreferrer" target="_blank" aria-label="在 GitHub 上编辑此页" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><!----><!----></div></footer><!----><div id="comment" class="waline-wrapper" darkmode="false" style="display:block;"><div data-waline provider="Waline" pageview="false"><!--v-if--><div class="wl-comment"><!--v-if--><div class="wl-panel"><div class="wl-header item3"><!--[--><div class="wl-header-item"><label for="wl-nick">昵称</label><input id="wl-nick" class="wl-input wl-nick" name="nick" type="text" value></div><div class="wl-header-item"><label for="wl-mail">邮箱</label><input id="wl-mail" class="wl-input wl-mail" name="mail" type="email" value></div><div class="wl-header-item"><label for="wl-link">网址</label><input id="wl-link" class="wl-input wl-link" name="link" type="text" value></div><!--]--></div><textarea id="wl-edit" class="wl-editor" placeholder="请留言。(填写邮箱可在被回复时收到邮件提醒)"></textarea><div class="wl-preview" style="display:none;"><hr><h4>预览:</h4><div class="wl-content"></div></div><div class="wl-footer"><div class="wl-actions"><a href="https://guides.github.com/features/mastering-markdown/" title="Markdown Guide" aria-label="Markdown is supported" class="wl-action" target="_blank" rel="noopener noreferrer"><svg width="16" height="16" ariaHidden="true"><path d="M14.85 3H1.15C.52 3 0 3.52 0 4.15v7.69C0 12.48.52 13 1.15 13h13.69c.64 0 1.15-.52 1.15-1.15v-7.7C16 3.52 15.48 3 14.85 3zM9 11H7V8L5.5 9.92 4 8v3H2V5h2l1.5 2L7 5h2v6zm2.99.5L9.5 8H11V5h2v3h1.5l-2.51 3.5z" fill="currentColor"></path></svg></a><button type="button" class="wl-action" title="表情" style="display:none;"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M563.2 463.3 677 540c1.7 1.2 3.7 1.8 5.8 1.8.7 0 1.4-.1 2-.2 2.7-.5 5.1-2.1 6.6-4.4l25.3-37.8c1.5-2.3 2.1-5.1 1.6-7.8s-2.1-5.1-4.4-6.6l-73.6-49.1 73.6-49.1c2.3-1.5 3.9-3.9 4.4-6.6.5-2.7 0-5.5-1.6-7.8l-25.3-37.8a10.1 10.1 0 0 0-6.6-4.4c-.7-.1-1.3-.2-2-.2-2.1 0-4.1.6-5.8 1.8l-113.8 76.6c-9.2 6.2-14.7 16.4-14.7 27.5.1 11 5.5 21.3 14.7 27.4zM387 348.8h-45.5c-5.7 0-10.4 4.7-10.4 10.4v153.3c0 5.7 4.7 10.4 10.4 10.4H387c5.7 0 10.4-4.7 10.4-10.4V359.2c0-5.7-4.7-10.4-10.4-10.4zm333.8 241.3-41-20a10.3 10.3 0 0 0-8.1-.5c-2.6.9-4.8 2.9-5.9 5.4-30.1 64.9-93.1 109.1-164.4 115.2-5.7.5-9.9 5.5-9.5 11.2l3.9 45.5c.5 5.3 5 9.5 10.3 9.5h.9c94.8-8 178.5-66.5 218.6-152.7 2.4-5 .3-11.2-4.8-13.6zm186-186.1c-11.9-42-30.5-81.4-55.2-117.1-24.1-34.9-53.5-65.6-87.5-91.2-33.9-25.6-71.5-45.5-111.6-59.2-41.2-14-84.1-21.1-127.8-21.1h-1.2c-75.4 0-148.8 21.4-212.5 61.7-63.7 40.3-114.3 97.6-146.5 165.8-32.2 68.1-44.3 143.6-35.1 218.4 9.3 74.8 39.4 145 87.3 203.3.1.2.3.3.4.5l36.2 38.4c1.1 1.2 2.5 2.1 3.9 2.6 73.3 66.7 168.2 103.5 267.5 103.5 73.3 0 145.2-20.3 207.7-58.7 37.3-22.9 70.3-51.5 98.1-85 27.1-32.7 48.7-69.5 64.2-109.1 15.5-39.7 24.4-81.3 26.6-123.8 2.4-43.6-2.5-87-14.5-129zm-60.5 181.1c-8.3 37-22.8 72-43 104-19.7 31.1-44.3 58.6-73.1 81.7-28.8 23.1-61 41-95.7 53.4-35.6 12.7-72.9 19.1-110.9 19.1-82.6 0-161.7-30.6-222.8-86.2l-34.1-35.8c-23.9-29.3-42.4-62.2-55.1-97.7-12.4-34.7-18.8-71-19.2-107.9-.4-36.9 5.4-73.3 17.1-108.2 12-35.8 30-69.2 53.4-99.1 31.7-40.4 71.1-72 117.2-94.1 44.5-21.3 94-32.6 143.4-32.6 49.3 0 97 10.8 141.8 32 34.3 16.3 65.3 38.1 92 64.8 26.1 26 47.5 56 63.6 89.2 16.2 33.2 26.6 68.5 31 105.1 4.6 37.5 2.7 75.3-5.6 112.3z" fill="currentColor"></path></svg></button><button type="button" class="wl-action" title="表情包"><svg width="24" height="24" fill="currentcolor" viewBox="0 0 24 24"><path style="transform: translateY(0.5px)" d="M18.968 10.5H15.968V11.484H17.984V12.984H15.968V15H14.468V9H18.968V10.5V10.5ZM8.984 9C9.26533 9 9.49967 9.09367 9.687 9.281C9.87433 9.46833 9.968 9.70267 9.968 9.984V10.5H6.499V13.5H8.468V12H9.968V14.016C9.968 14.2973 9.87433 14.5317 9.687 14.719C9.49967 14.9063 9.26533 15 8.984 15H5.984C5.70267 15 5.46833 14.9063 5.281 14.719C5.09367 14.5317 5 14.2973 5 14.016V9.985C5 9.70367 5.09367 9.46933 5.281 9.282C5.46833 9.09467 5.70267 9.001 5.984 9.001H8.984V9ZM11.468 9H12.968V15H11.468V9V9Z"></path><path d="M18.5 3H5.75C3.6875 3 2 4.6875 2 6.75V18C2 20.0625 3.6875 21.75 5.75 21.75H18.5C20.5625 21.75 22.25 20.0625 22.25 18V6.75C22.25 4.6875 20.5625 3 18.5 3ZM20.75 18C20.75 19.2375 19.7375 20.25 18.5 20.25H5.75C4.5125 20.25 3.5 19.2375 3.5 18V6.75C3.5 5.5125 4.5125 4.5 5.75 4.5H18.5C19.7375 4.5 20.75 5.5125 20.75 6.75V18Z"></path></svg></button><input id="wl-image-upload" class="upload" type="file" accept=".png,.jpg,.jpeg,.webp,.bmp,.gif"><label for="wl-image-upload" class="wl-action" title="上传图片"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M784 112H240c-88 0-160 72-160 160v480c0 88 72 160 160 160h544c88 0 160-72 160-160V272c0-88-72-160-160-160zm96 640c0 52.8-43.2 96-96 96H240c-52.8 0-96-43.2-96-96V272c0-52.8 43.2-96 96-96h544c52.8 0 96 43.2 96 96v480z" fill="currentColor"></path><path d="M352 480c52.8 0 96-43.2 96-96s-43.2-96-96-96-96 43.2-96 96 43.2 96 96 96zm0-128c17.6 0 32 14.4 32 32s-14.4 32-32 32-32-14.4-32-32 14.4-32 32-32zm462.4 379.2-3.2-3.2-177.6-177.6c-25.6-25.6-65.6-25.6-91.2 0l-80 80-36.8-36.8c-25.6-25.6-65.6-25.6-91.2 0L200 728c-4.8 6.4-8 14.4-8 24 0 17.6 14.4 32 32 32 9.6 0 16-3.2 22.4-9.6L380.8 640l134.4 134.4c6.4 6.4 14.4 9.6 24 9.6 17.6 0 32-14.4 32-32 0-9.6-4.8-17.6-9.6-24l-52.8-52.8 80-80L769.6 776c6.4 4.8 12.8 8 20.8 8 17.6 0 32-14.4 32-32 0-8-3.2-16-8-20.8z" fill="currentColor"></path></svg></label><button type="button" class="wl-action" title="预览"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M710.816 654.301c70.323-96.639 61.084-230.578-23.705-314.843-46.098-46.098-107.183-71.109-172.28-71.109-65.008 0-126.092 25.444-172.28 71.109-45.227 46.098-70.756 107.183-70.756 172.106 0 64.923 25.444 126.007 71.194 172.106 46.099 46.098 107.184 71.109 172.28 71.109 51.414 0 100.648-16.212 142.824-47.404l126.53 126.006c7.058 7.06 16.297 10.979 26.406 10.979 10.105 0 19.343-3.919 26.402-10.979 14.467-14.467 14.467-38.172 0-52.723L710.816 654.301zm-315.107-23.265c-65.88-65.88-65.88-172.54 0-238.42 32.069-32.07 74.245-49.149 119.471-49.149 45.227 0 87.407 17.603 119.472 49.149 65.88 65.879 65.88 172.539 0 238.42-63.612 63.178-175.242 63.178-238.943 0zm0 0" fill="currentColor"></path><path d="M703.319 121.603H321.03c-109.8 0-199.469 89.146-199.469 199.38v382.034c0 109.796 89.236 199.38 199.469 199.38h207.397c20.653 0 37.384-16.645 37.384-37.299 0-20.649-16.731-37.296-37.384-37.296H321.03c-68.582 0-124.352-55.77-124.352-124.267V321.421c0-68.496 55.77-124.267 124.352-124.267h382.289c68.582 0 124.352 55.771 124.352 124.267V524.72c0 20.654 16.736 37.299 37.385 37.299 20.654 0 37.384-16.645 37.384-37.299V320.549c-.085-109.8-89.321-198.946-199.121-198.946zm0 0" fill="currentColor"></path></svg></button></div><div class="wl-info"><div class="wl-captcha-container"></div><div class="wl-text-number">0 <!--v-if-->  字</div><button type="button" class="wl-btn">登录</button><button type="submit" class="primary wl-btn" title="Cmd|Ctrl + Enter"><!--[-->提交<!--]--></button></div><div class="wl-gif-popup"><input type="text" placeholder="搜索表情包"><!--v-if--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div></div><div class="wl-emoji-popup"><!--[--><!--]--><!--v-if--></div></div></div><!--v-if--></div><div class="wl-meta-head"><div class="wl-count"><!--v-if--> 评论</div><ul class="wl-sort"><!--[--><li class="active">按正序</li><li class="">按倒序</li><li class="">按热度</li><!--]--></ul></div><div class="wl-cards"><!--[--><!--]--></div><!--[--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div><!--]--><div class="wl-power"> Powered by <a href="https://github.com/walinejs/waline" target="_blank" rel="noopener noreferrer"> Waline </a> v2.15.5</div></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">T4mako's blog</div><div class="vp-copyright">Copyright © 2024 T4mako</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-00d6fe81.js" defer></script>
  </body>
</html>
