<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.66" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://T4mako.github.io/code/python/Machine%20Learning/Pytorch/7%E3%80%81%E6%9E%84%E5%BB%BA%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html"><meta property="og:site_name" content="T4mako"><meta property="og:title" content="7、构建、训练模型"><meta property="og:description" content="7、构建、训练模型 7.1、构建模型 构建模型有三种方法： 继承 nn.Module 基类构建自定义模型（最常见） 使用 nn.Sequential 按层顺序构建模型（最简单） 继承 nn.Module 基类构建模型并辅助应用模型容器进行封装（nn.Sequential,nn.ModuleList,nn.ModuleDict）（最为灵活也较为复杂） 模型定义好后，会给参数（w，b）赋值 pytorch hub 模块，调用他人的网络架构"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="T4mako"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"7、构建、训练模型","image":[""],"dateModified":null,"author":[{"@type":"Person","name":"T4mako","url":"https://github.com/T4mako/T4mako.github.io"}]}</script><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Zen+Maru+Gothic:wght@500&display=swap" rel="stylesheet"><link rel="alternate" type="application/rss+xml" href="https://T4mako.github.io/rss.xml" title="T4mako RSS Feed"><title>7、构建、训练模型 | T4mako</title><meta name="description" content="7、构建、训练模型 7.1、构建模型 构建模型有三种方法： 继承 nn.Module 基类构建自定义模型（最常见） 使用 nn.Sequential 按层顺序构建模型（最简单） 继承 nn.Module 基类构建模型并辅助应用模型容器进行封装（nn.Sequential,nn.ModuleList,nn.ModuleDict）（最为灵活也较为复杂） 模型定义好后，会给参数（w，b）赋值 pytorch hub 模块，调用他人的网络架构">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-c43249a7.css" as="style"><link rel="stylesheet" href="/assets/style-c43249a7.css">
    <link rel="modulepreload" href="/assets/app-6225af5c.js"><link rel="modulepreload" href="/assets/7、构建、训练模型.html-4dc44cad.js"><link rel="modulepreload" href="/assets/7、构建、训练模型.html-d780f7b1.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="prefetch" href="/assets/index.html-28de6f14.js" as="script"><link rel="prefetch" href="/assets/index.html-f5f264d6.js" as="script"><link rel="prefetch" href="/assets/index.html-30a1b7c2.js" as="script"><link rel="prefetch" href="/assets/Elasticsearch.html-cdfa620a.js" as="script"><link rel="prefetch" href="/assets/MongoDB.html-26953f36.js" as="script"><link rel="prefetch" href="/assets/MySQL基础.html-142c566d.js" as="script"><link rel="prefetch" href="/assets/Redis.html-00ca8519.js" as="script"><link rel="prefetch" href="/assets/IDEA、Eclipse快捷键.html-15e3dc66.js" as="script"><link rel="prefetch" href="/assets/JDBC.html-8ec2fd12.js" as="script"><link rel="prefetch" href="/assets/JVM.html-fa0d3015.js" as="script"><link rel="prefetch" href="/assets/JVM入门.html-5f1781e4.js" as="script"><link rel="prefetch" href="/assets/JWT.html-7c0fd9d7.js" as="script"><link rel="prefetch" href="/assets/JavaWeb基础.html-af51d1ad.js" as="script"><link rel="prefetch" href="/assets/Maven基础.html-ad80dbfe.js" as="script"><link rel="prefetch" href="/assets/MyBatis.html-1642006c.js" as="script"><link rel="prefetch" href="/assets/MybatisPlus.html-07f9ea4d.js" as="script"><link rel="prefetch" href="/assets/RabbitMQ.html-5aae586f.js" as="script"><link rel="prefetch" href="/assets/Shiro.html-fafd6510.js" as="script"><link rel="prefetch" href="/assets/SpringBoot.html-6d206ed6.js" as="script"><link rel="prefetch" href="/assets/SpringBoot常用注解总结.html-c19e968e.js" as="script"><link rel="prefetch" href="/assets/SpringBoot自动装配原理.html-83356abe.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础.html-081659a3.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础2024.html-5c5733dc.js" as="script"><link rel="prefetch" href="/assets/SpringMVC.html-20c731bf.js" as="script"><link rel="prefetch" href="/assets/Spring基础.html-7fdff257.js" as="script"><link rel="prefetch" href="/assets/index.html-8b1856b4.js" as="script"><link rel="prefetch" href="/assets/Matplotlib.html-d2aba437.js" as="script"><link rel="prefetch" href="/assets/Numpy.html-ffba3c01.js" as="script"><link rel="prefetch" href="/assets/Pandas.html-febe9de7.js" as="script"><link rel="prefetch" href="/assets/python 基础语法.html-d33402d6.js" as="script"><link rel="prefetch" href="/assets/python 项目注意事项.html-f13637d7.js" as="script"><link rel="prefetch" href="/assets/Ajax.html-73e0d2ee.js" as="script"><link rel="prefetch" href="/assets/Axios.html-6a0f7031.js" as="script"><link rel="prefetch" href="/assets/CSS3.html-fbf9bd49.js" as="script"><link rel="prefetch" href="/assets/HTML.html-dba9796c.js" as="script"><link rel="prefetch" href="/assets/Node.js笔记.html-edd6db0d.js" as="script"><link rel="prefetch" href="/assets/Promise.html-83aba73d.js" as="script"><link rel="prefetch" href="/assets/Git.html-ef4b5f14.js" as="script"><link rel="prefetch" href="/assets/Markdown语法基础.html-2825f872.js" as="script"><link rel="prefetch" href="/assets/操作系统.html-8bed0f34.js" as="script"><link rel="prefetch" href="/assets/数据结构.html-6f1a0269.js" as="script"><link rel="prefetch" href="/assets/正则表达式.html-be164830.js" as="script"><link rel="prefetch" href="/assets/计算机组成原理.html-2668b30e.js" as="script"><link rel="prefetch" href="/assets/计算机网络.html-b11deb88.js" as="script"><link rel="prefetch" href="/assets/设计模式.html-35cadb50.js" as="script"><link rel="prefetch" href="/assets/面向对象设计基本原则.html-edb429fa.js" as="script"><link rel="prefetch" href="/assets/Docker.html-9f4e5ab9.js" as="script"><link rel="prefetch" href="/assets/GitHub Actions.html-bc1f64fb.js" as="script"><link rel="prefetch" href="/assets/基于centos部署java项目.html-b44ac3d3.js" as="script"><link rel="prefetch" href="/assets/一些插件.html-7333e5f0.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-c14413e6.js" as="script"><link rel="prefetch" href="/assets/CSGO饰品图.html-41566c4f.js" as="script"><link rel="prefetch" href="/assets/基础.html-376a9d53.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-ff145bec.js" as="script"><link rel="prefetch" href="/assets/Guitar.html-88bc41a7.js" as="script"><link rel="prefetch" href="/assets/hlae.html-5be4d809.js" as="script"><link rel="prefetch" href="/assets/settings.html-ed8baefd.js" as="script"><link rel="prefetch" href="/assets/Japanese.html-9358f7c6.js" as="script"><link rel="prefetch" href="/assets/index.html-71b38232.js" as="script"><link rel="prefetch" href="/assets/index.html-648f386b.js" as="script"><link rel="prefetch" href="/assets/30天JavaScript挑战.html-90b1a895.js" as="script"><link rel="prefetch" href="/assets/高频 SQL 50 题（基础版）.html-405179ee.js" as="script"><link rel="prefetch" href="/assets/多线程.html-46ffbab2.js" as="script"><link rel="prefetch" href="/assets/noob-Rg-better.html-cc14aa26.js" as="script"><link rel="prefetch" href="/assets/noob-Rg.html-3a2fdcc8.js" as="script"><link rel="prefetch" href="/assets/1、JavaScript基础语法笔记.html-69b3cd61.js" as="script"><link rel="prefetch" href="/assets/2、WebAPIs笔记.html-a8c50328.js" as="script"><link rel="prefetch" href="/assets/3、JavaScript进阶.html-180a19d8.js" as="script"><link rel="prefetch" href="/assets/leetcode228_汇总区间.html-cddb8f7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_001_两数之和.html-4d2935f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_002_两数相加.html-fe20f202.js" as="script"><link rel="prefetch" href="/assets/leetcode_003_无重复字符的最长子串.html-267e65ef.js" as="script"><link rel="prefetch" href="/assets/leetcode_004_寻找两个正序数组的中位数.html-9efd45da.js" as="script"><link rel="prefetch" href="/assets/leetcode_005_最长回文子串.html-39e1fea9.js" as="script"><link rel="prefetch" href="/assets/leetcode_006_N 字形变换.html-b4f920fe.js" as="script"><link rel="prefetch" href="/assets/leetcode_007_整数反转.html-4dd1c7a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_008_字符串转换整数 (atoi).html-fa0a27da.js" as="script"><link rel="prefetch" href="/assets/leetcode_009_回文数.html-55377a9f.js" as="script"><link rel="prefetch" href="/assets/leetcode_010_正则表达式匹配.html-674b100d.js" as="script"><link rel="prefetch" href="/assets/leetcode_011_盛最多水的容器.html-c8a38d1c.js" as="script"><link rel="prefetch" href="/assets/leetcode_012_整数转罗马数字.html-6b38adef.js" as="script"><link rel="prefetch" href="/assets/leetcode_013_罗马数字转整数.html-22c1adfb.js" as="script"><link rel="prefetch" href="/assets/leetcode_014_最长公共前缀.html-c172cec6.js" as="script"><link rel="prefetch" href="/assets/leetcode_015_三数之和.html-875a5ed0.js" as="script"><link rel="prefetch" href="/assets/leetcode_016_最接近的三数之和.html-b931e3c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_017_电话号码的字母组合.html-6d899101.js" as="script"><link rel="prefetch" href="/assets/leetcode_018_四数之和.html-087b71dc.js" as="script"><link rel="prefetch" href="/assets/leetcode_019_删除链表的倒数第 N 个结点.html-8241fe9c.js" as="script"><link rel="prefetch" href="/assets/leetcode_020_有效的括号.html-e07e2181.js" as="script"><link rel="prefetch" href="/assets/leetcode_021_合并两个有序链表.html-3e5fdc85.js" as="script"><link rel="prefetch" href="/assets/leetcode_022_括号生成.html-34027bae.js" as="script"><link rel="prefetch" href="/assets/leetcode_023_合并 K 个升序链表.html-2830aabf.js" as="script"><link rel="prefetch" href="/assets/leetcode_024_两两交换链表中的节点.html-aa44f045.js" as="script"><link rel="prefetch" href="/assets/leetcode_025_K 个一组翻转链表.html-1cb0de2d.js" as="script"><link rel="prefetch" href="/assets/leetcode_026_删除有序数组中的重复项.html-bf359f60.js" as="script"><link rel="prefetch" href="/assets/leetcode_027_移除元素.html-529831e9.js" as="script"><link rel="prefetch" href="/assets/leetcode_028_找出字符串中第一个匹配项的下标.html-dc2e4f17.js" as="script"><link rel="prefetch" href="/assets/leetcode_029_两数相除.html-03436b7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_030_串联所有单词的子串.html-faa41612.js" as="script"><link rel="prefetch" href="/assets/leetcode_031_下一个排列.html-1bf62ff0.js" as="script"><link rel="prefetch" href="/assets/leetcode_032_最长有效括号.html-dbd4329f.js" as="script"><link rel="prefetch" href="/assets/leetcode_033_搜索旋转排序数组.html-b3f9f227.js" as="script"><link rel="prefetch" href="/assets/leetcode_034_在排序数组中查找元素的第一个和最后一个位置.html-df6d34be.js" as="script"><link rel="prefetch" href="/assets/leetcode_035_搜索插入位置.html-f3871315.js" as="script"><link rel="prefetch" href="/assets/leetcode_036_有效的数独.html-5f2bc80d.js" as="script"><link rel="prefetch" href="/assets/leetcode_038_外观数列.html-6e3a5b1a.js" as="script"><link rel="prefetch" href="/assets/leetcode_039_ 组合总和.html-b0a7cd1a.js" as="script"><link rel="prefetch" href="/assets/leetcode_040_ 组合总和II.html-87cd31b2.js" as="script"><link rel="prefetch" href="/assets/leetcode_041_ 缺失的第一个正数.html-c08437a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_042_接雨水.html-4f929eb5.js" as="script"><link rel="prefetch" href="/assets/leetcode_043_字符串相乘.html-81486896.js" as="script"><link rel="prefetch" href="/assets/leetcode_045_跳跃游戏II.html-a0a07e13.js" as="script"><link rel="prefetch" href="/assets/leetcode_046_全排列.html-8e33255c.js" as="script"><link rel="prefetch" href="/assets/leetcode_047_全排列II.html-bc7cb387.js" as="script"><link rel="prefetch" href="/assets/leetcode_048_旋转图像.html-ec0a782c.js" as="script"><link rel="prefetch" href="/assets/leetcode_049_字母异位词分组.html-dc410cab.js" as="script"><link rel="prefetch" href="/assets/leetcode_050_Pow(x_n).html-29adea25.js" as="script"><link rel="prefetch" href="/assets/leetcode_051_N 皇后.html-54792019.js" as="script"><link rel="prefetch" href="/assets/leetcode_052_N 皇后 II.html-cae35ca8.js" as="script"><link rel="prefetch" href="/assets/leetcode_053_最大子数组和.html-f84751f2.js" as="script"><link rel="prefetch" href="/assets/leetcode_054_螺旋矩阵.html-7c2f26d1.js" as="script"><link rel="prefetch" href="/assets/leetcode_055_跳跃游戏.html-196b4f14.js" as="script"><link rel="prefetch" href="/assets/leetcode_056_合并区间.html-3c8d49b7.js" as="script"><link rel="prefetch" href="/assets/leetcode_058_最后一个单词的长度.html-c74c97db.js" as="script"><link rel="prefetch" href="/assets/leetcode_061_旋转链表.html-c1b9f0bb.js" as="script"><link rel="prefetch" href="/assets/leetcode_062_不同路径.html-5571caa7.js" as="script"><link rel="prefetch" href="/assets/leetcode_063_不同路径II.html-761d387b.js" as="script"><link rel="prefetch" href="/assets/leetcode_064_最小路径和.html-cecd8a72.js" as="script"><link rel="prefetch" href="/assets/leetcode_066_加一.html-12eefde8.js" as="script"><link rel="prefetch" href="/assets/leetcode_067_二进制求和.html-555cfc00.js" as="script"><link rel="prefetch" href="/assets/leetcode_068_文本左右对齐.html-7a5c575d.js" as="script"><link rel="prefetch" href="/assets/leetcode_069_x的平方根.html-b20ef54c.js" as="script"><link rel="prefetch" href="/assets/leetcode_070_爬楼梯.html-d52a7e95.js" as="script"><link rel="prefetch" href="/assets/leetcode_072_编辑距离.html-00a22365.js" as="script"><link rel="prefetch" href="/assets/leetcode_073_矩阵置零.html-2bf295e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_075_颜色分类.html-5d29d6eb.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串 copy.html-dba3ee02.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串.html-58de2813.js" as="script"><link rel="prefetch" href="/assets/leetcode_079_单词搜索.html-c3ecad05.js" as="script"><link rel="prefetch" href="/assets/leetcode_080_删除有序数组中的重复项.html-ad954572.js" as="script"><link rel="prefetch" href="/assets/leetcode_082_删除排序链表中的重复元素 II.html-ffc51573.js" as="script"><link rel="prefetch" href="/assets/leetcode_083_删除排序链表中的重复元素.html-70bf5bb7.js" as="script"><link rel="prefetch" href="/assets/leetcode_086_分隔链表.html-79aea5ef.js" as="script"><link rel="prefetch" href="/assets/leetcode_088_合并两个有序数组.html-ba540966.js" as="script"><link rel="prefetch" href="/assets/leetcode_092_反转链表 II.html-23caaca0.js" as="script"><link rel="prefetch" href="/assets/leetcode_094_二叉树的中序遍历.html-8288cdbe.js" as="script"><link rel="prefetch" href="/assets/leetcode_095_不同的二叉搜索树 II.html-47652036.js" as="script"><link rel="prefetch" href="/assets/leetcode_096_不同的二叉搜索树.html-ae75ff17.js" as="script"><link rel="prefetch" href="/assets/leetcode_098_验证二叉搜索树.html-03e5a7b1.js" as="script"><link rel="prefetch" href="/assets/leetcode_1004_最大连续1的个数 III.html-5533e255.js" as="script"><link rel="prefetch" href="/assets/leetcode_100_相同的树.html-b3027eaa.js" as="script"><link rel="prefetch" href="/assets/leetcode_101_对称二叉树.html-ce76548e.js" as="script"><link rel="prefetch" href="/assets/leetcode_102_二叉树的层序遍历.html-bf767249.js" as="script"><link rel="prefetch" href="/assets/leetcode_103_二叉树的锯齿形层序遍历.html-c877409c.js" as="script"><link rel="prefetch" href="/assets/leetcode_104_二叉树的最大深度.html-1b32579f.js" as="script"><link rel="prefetch" href="/assets/leetcode_105_从前序与中序遍历序列构造二叉树.html-d13a65a1.js" as="script"><link rel="prefetch" href="/assets/leetcode_106_从中序与后序遍历序列构造二叉树.html-a6327af2.js" as="script"><link rel="prefetch" href="/assets/leetcode_1071_字符串的最大公因子.html-5476c3fe.js" as="script"><link rel="prefetch" href="/assets/leetcode_107_二叉树的层序遍历 II.html-8d1b9daf.js" as="script"><link rel="prefetch" href="/assets/leetcode_108_将有序数组转换为二叉搜索树.html-56c9fcfb.js" as="script"><link rel="prefetch" href="/assets/leetcode_112_路径总和.html-bde85dfa.js" as="script"><link rel="prefetch" href="/assets/leetcode_113_路径总和II.html-8f74fe65.js" as="script"><link rel="prefetch" href="/assets/leetcode_1143_最长公共子序列.html-99c668c7.js" as="script"><link rel="prefetch" href="/assets/leetcode_114_二叉树展开为链表.html-bdd88a01.js" as="script"><link rel="prefetch" href="/assets/leetcode_1161_最大层内元素和.html-fcb209f5.js" as="script"><link rel="prefetch" href="/assets/leetcode_117_填充每个节点的下一个右侧节点指针 II.html-764ce2a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_118_杨辉三角.html-479e30a4.js" as="script"><link rel="prefetch" href="/assets/leetcode_119_杨辉三角 II.html-a59406df.js" as="script"><link rel="prefetch" href="/assets/leetcode_1207_独一无二的出现次数.html-16dda148.js" as="script"><link rel="prefetch" href="/assets/leetcode_120_三角形最小路径和.html-86703591.js" as="script"><link rel="prefetch" href="/assets/leetcode_121_买卖股票的最佳时机 I.html-13626864.js" as="script"><link rel="prefetch" href="/assets/leetcode_122_买卖股票的最佳时机 II.html-bb37bd6e.js" as="script"><link rel="prefetch" href="/assets/leetcode_124_二叉树中的最大路径和.html-8e211f55.js" as="script"><link rel="prefetch" href="/assets/leetcode_125_验证回文串.html-90dfd796.js" as="script"><link rel="prefetch" href="/assets/leetcode_128_最长连续序列.html-8b798fa6.js" as="script"><link rel="prefetch" href="/assets/leetcode_129_求根节点到叶节点数字之和.html-8758fc10.js" as="script"><link rel="prefetch" href="/assets/leetcode_130_被围绕的区域.html-31108440.js" as="script"><link rel="prefetch" href="/assets/leetcode_1318_或运算的最小翻转次数.html-b1d00d09.js" as="script"><link rel="prefetch" href="/assets/leetcode_134_加油站.html-aa290400.js" as="script"><link rel="prefetch" href="/assets/leetcode_135_分发糖果.html-169212a1.js" as="script"><link rel="prefetch" href="/assets/leetcode_136_只出现一次的数字.html-efac1a41.js" as="script"><link rel="prefetch" href="/assets/leetcode_1372_二叉树中的最长交错路径.html-1f702f8e.js" as="script"><link rel="prefetch" href="/assets/leetcode_139_单词拆分.html-60a3eec6.js" as="script"><link rel="prefetch" href="/assets/leetcode_141_环形链表.html-caf4560c.js" as="script"><link rel="prefetch" href="/assets/leetcode_1431_拥有最多糖果的孩子.html-c46bc216.js" as="script"><link rel="prefetch" href="/assets/leetcode_1448_统计二叉树中好节点的数目.html-badf2d7e.js" as="script"><link rel="prefetch" href="/assets/leetcode_144_二叉树的前序遍历.html-782a3002.js" as="script"><link rel="prefetch" href="/assets/leetcode_1456_定长子串中元音的最大数目.html-0bebd911.js" as="script"><link rel="prefetch" href="/assets/leetcode_145_二叉树的后序遍历.html-f423c8ea.js" as="script"><link rel="prefetch" href="/assets/leetcode_1466_重新规划路线.html-61eb288d.js" as="script"><link rel="prefetch" href="/assets/leetcode_146_LRU 缓存.html-ef476ae2.js" as="script"><link rel="prefetch" href="/assets/leetcode_148_排序链表.html-6835afd8.js" as="script"><link rel="prefetch" href="/assets/leetcode_1493_删掉一个元素以后全为 1 的最长子数组.html-1c9feb8e.js" as="script"><link rel="prefetch" href="/assets/leetcode_150_逆波兰表达式求值.html-8c4709cc.js" as="script"><link rel="prefetch" href="/assets/leetcode_151_反转字符串中的单词.html-f91b8216.js" as="script"><link rel="prefetch" href="/assets/leetcode_155_最小栈.html-20c00992.js" as="script"><link rel="prefetch" href="/assets/leetcode_160_相交链表.html-5627acf7.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值 copy.html-f24beb30.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值.html-42e7d40f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1657_确定两个字符串是否接近.html-8a42e6de.js" as="script"><link rel="prefetch" href="/assets/leetcode_1679_K 和数对的最大数目.html-75040006.js" as="script"><link rel="prefetch" href="/assets/leetcode_169_多数元素.html-b7c60141.js" as="script"><link rel="prefetch" href="/assets/leetcode_1732_找到最高海拔.html-7ecbb8c1.js" as="script"><link rel="prefetch" href="/assets/leetcode_173_二叉搜索树迭代器.html-5f9afb5f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1768_交替合并字符串.html-fa23ddd6.js" as="script"><link rel="prefetch" href="/assets/leetcode_189_轮转数组.html-c42a0832.js" as="script"><link rel="prefetch" href="/assets/leetcode_1926_迷宫中离入口最近的出口.html-ba13a452.js" as="script"><link rel="prefetch" href="/assets/leetcode_198_打家劫舍.html-01ddc8ed.js" as="script"><link rel="prefetch" href="/assets/leetcode_199. 二叉树的右视图.html-b4044b3b.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数 copy.html-4128158a.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数.html-df50f511.js" as="script"><link rel="prefetch" href="/assets/leetcode_203_移除链表元素.html-e917fc2e.js" as="script"><link rel="prefetch" href="/assets/leetcode_206_反转链表.html-c20741fc.js" as="script"><link rel="prefetch" href="/assets/leetcode_208_实现 Trie (前缀树).html-b62d7f4f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2095_删除链表的中间节点.html-deb3033e.js" as="script"><link rel="prefetch" href="/assets/leetcode_209_长度最小的子数组.html-b4fb933f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2130_链表最大孪生和.html-d152e296.js" as="script"><link rel="prefetch" href="/assets/leetcode_215_数组中的第K个最大元素.html-facb19af.js" as="script"><link rel="prefetch" href="/assets/leetcode_216_组合总和 III.html-449b0a0b.js" as="script"><link rel="prefetch" href="/assets/leetcode_219_存在重复元素 II.html-426b13a6.js" as="script"><link rel="prefetch" href="/assets/leetcode_2215_找出两数组的不同.html-8f3c9866.js" as="script"><link rel="prefetch" href="/assets/leetcode_222_完全二叉树的节点个数.html-e247e501.js" as="script"><link rel="prefetch" href="/assets/leetcode_226_翻转二叉树.html-a6fe8a1b.js" as="script"><link rel="prefetch" href="/assets/leetcode_2300. 咒语和药水的成功对数.html-451a870e.js" as="script"><link rel="prefetch" href="/assets/leetcode_230_二叉搜索树中第K小的元素.html-8f9aff36.js" as="script"><link rel="prefetch" href="/assets/leetcode_2336_无限集中的最小数字.html-0186d2f3.js" as="script"><link rel="prefetch" href="/assets/leetcode_234_回文链表.html-5ffc51ac.js" as="script"><link rel="prefetch" href="/assets/leetcode_2352_相等行列对.html-aa32ea65.js" as="script"><link rel="prefetch" href="/assets/leetcode_236_二叉树的最近公共祖先.html-067dc510.js" as="script"><link rel="prefetch" href="/assets/leetcode_238_除自身以外数组的乘积.html-d416e8f0.js" as="script"><link rel="prefetch" href="/assets/leetcode_2390_从字符串中移除星号.html-f97fadc9.js" as="script"><link rel="prefetch" href="/assets/leetcode_242_有效的字母异位词.html-50564962.js" as="script"><link rel="prefetch" href="/assets/leetcode_2542_最大序列的分数.html-f5e8bf7d.js" as="script"><link rel="prefetch" href="/assets/leetcode_274_H指数.html-219397c4.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy 2.html-2ece538f.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy.html-b2dcfc16.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0.html-28326917.js" as="script"><link rel="prefetch" href="/assets/leetcode_300_最长递增子序列.html-7bc25e46.js" as="script"><link rel="prefetch" href="/assets/leetcode_322_零钱兑换.html-338820d0.js" as="script"><link rel="prefetch" href="/assets/leetcode_328_奇偶链表.html-c221c5e3.js" as="script"><link rel="prefetch" href="/assets/leetcode_334_递增的三元子序列.html-eaa7359c.js" as="script"><link rel="prefetch" href="/assets/leetcode_338_比特位计数.html-1ca3e264.js" as="script"><link rel="prefetch" href="/assets/leetcode_345_反转字符串中的元音字母.html-a53a56ed.js" as="script"><link rel="prefetch" href="/assets/leetcode_374_猜数字大小.html-838e47cd.js" as="script"><link rel="prefetch" href="/assets/leetcode_380_O(1) 时间插入、删除和获取随机元素.html-809dfc48.js" as="script"><link rel="prefetch" href="/assets/leetcode_383_赎金信.html-b140905d.js" as="script"><link rel="prefetch" href="/assets/leetcode_392_判断子序列.html-0f679959.js" as="script"><link rel="prefetch" href="/assets/leetcode_394_字符串解码.html-34dbf0a9.js" as="script"><link rel="prefetch" href="/assets/leetcode_435_无重叠区间.html-a86bed80.js" as="script"><link rel="prefetch" href="/assets/leetcode_437_路径总和 III.html-03d25af8.js" as="script"><link rel="prefetch" href="/assets/leetcode_443_压缩字符串.html-04e19523.js" as="script"><link rel="prefetch" href="/assets/leetcode_450_删除二叉搜索树中的节点.html-b96c20de.js" as="script"><link rel="prefetch" href="/assets/leetcode_452_用最少数量的箭引爆气球.html-38e27162.js" as="script"><link rel="prefetch" href="/assets/leetcode_530_二叉搜索树的最小绝对差.html-67141eeb.js" as="script"><link rel="prefetch" href="/assets/leetcode_547_省份数量.html-b3b6bac4.js" as="script"><link rel="prefetch" href="/assets/leetcode_605_种花问题.html-031d3116.js" as="script"><link rel="prefetch" href="/assets/leetcode_637_二叉树的层平均值.html-a7a36db9.js" as="script"><link rel="prefetch" href="/assets/leetcode_643_子数组最大平均数 I.html-a8f43e75.js" as="script"><link rel="prefetch" href="/assets/leetcode_649_Dota2 参议院.html-57e2951e.js" as="script"><link rel="prefetch" href="/assets/leetcode_700_二叉搜索树中的搜索.html-023dc167.js" as="script"><link rel="prefetch" href="/assets/leetcode_714_买卖股票的最佳时机含手续费.html-7ad01ab6.js" as="script"><link rel="prefetch" href="/assets/leetcode_724_寻找数组的中心下标.html-71388c1f.js" as="script"><link rel="prefetch" href="/assets/leetcode_735_行星碰撞.html-79670bf6.js" as="script"><link rel="prefetch" href="/assets/leetcode_739_每日温度.html-00bbc948.js" as="script"><link rel="prefetch" href="/assets/leetcode_746_使用最小花费爬楼梯.html-568fe2b8.js" as="script"><link rel="prefetch" href="/assets/leetcode_790_多米诺和托米诺平铺.html-e3681c3f.js" as="script"><link rel="prefetch" href="/assets/leetcode_841_钥匙和房间.html-75e3c562.js" as="script"><link rel="prefetch" href="/assets/leetcode_872_叶子相似的树.html-4ff19ccc.js" as="script"><link rel="prefetch" href="/assets/leetcode_875_爱吃香蕉的珂珂.html-c23d801c.js" as="script"><link rel="prefetch" href="/assets/leetcode_876_链表的中间结点.html-e827b29b.js" as="script"><link rel="prefetch" href="/assets/leetcode_901_股票价格跨度.html-6195f435.js" as="script"><link rel="prefetch" href="/assets/leetcode_933_最近的请求次数.html-b601ebe2.js" as="script"><link rel="prefetch" href="/assets/leetcode_994_腐烂的橘子.html-c9fcbc99.js" as="script"><link rel="prefetch" href="/assets/leetcode_LCP68_美丽的花束.html-bea99396.js" as="script"><link rel="prefetch" href="/assets/1、TypeScript语言简介.html-ecee5a2a.js" as="script"><link rel="prefetch" href="/assets/2、基本用法.html-8e7f792b.js" as="script"><link rel="prefetch" href="/assets/3、any，unknown ，never 类型.html-92d935e7.js" as="script"><link rel="prefetch" href="/assets/4、系统类型.html-564a8c20.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-74cacfb8.js" as="script"><link rel="prefetch" href="/assets/6、元祖.html-df4609ec.js" as="script"><link rel="prefetch" href="/assets/7、symbol 类型.html-459544bf.js" as="script"><link rel="prefetch" href="/assets/8、函数.html-c5c268c2.js" as="script"><link rel="prefetch" href="/assets/index.html-9b0abc8d.js" as="script"><link rel="prefetch" href="/assets/Arrays类.html-5cff467d.js" as="script"><link rel="prefetch" href="/assets/BigInteger和BigDecimal.html-b00a56b8.js" as="script"><link rel="prefetch" href="/assets/Collections类.html-6e3e4ec0.js" as="script"><link rel="prefetch" href="/assets/Java比较器.html-f75c5cab.js" as="script"><link rel="prefetch" href="/assets/Math类.html-66218b19.js" as="script"><link rel="prefetch" href="/assets/Object类.html-43eeba34.js" as="script"><link rel="prefetch" href="/assets/Pattern 与 Matcher 类.html-ee7d45a1.js" as="script"><link rel="prefetch" href="/assets/Stream API.html-9b418bda.js" as="script"><link rel="prefetch" href="/assets/String、Scanner相关类.html-ab539520.js" as="script"><link rel="prefetch" href="/assets/System类.html-0388d0ad.js" as="script"><link rel="prefetch" href="/assets/日期时间API.html-abcd5dc6.js" as="script"><link rel="prefetch" href="/assets/10、多线程.html-35e659db.js" as="script"><link rel="prefetch" href="/assets/11、枚举类.html-0bf87ec6.js" as="script"><link rel="prefetch" href="/assets/12、注解.html-50944a71.js" as="script"><link rel="prefetch" href="/assets/13、集合.html-9439bdbe.js" as="script"><link rel="prefetch" href="/assets/14、泛型.html-d7592650.js" as="script"><link rel="prefetch" href="/assets/15、IO流.html-515b20a8.js" as="script"><link rel="prefetch" href="/assets/16、网络编程.html-d4102567.js" as="script"><link rel="prefetch" href="/assets/17、反射.html-539859f0.js" as="script"><link rel="prefetch" href="/assets/18、新特性.html-ef7a4719.js" as="script"><link rel="prefetch" href="/assets/19、格式化输入输出.html-9690fc0f.js" as="script"><link rel="prefetch" href="/assets/1、基础概念.html-8e40e2f0.js" as="script"><link rel="prefetch" href="/assets/2、数据类型.html-7994f88b.js" as="script"><link rel="prefetch" href="/assets/3、运算符.html-457a2f56.js" as="script"><link rel="prefetch" href="/assets/4、程序流程控制.html-7c29dc6c.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-a4c355fe.js" as="script"><link rel="prefetch" href="/assets/6、面向对象.html-ad3a75f9.js" as="script"><link rel="prefetch" href="/assets/7、单元测试Junit.html-6c06e896.js" as="script"><link rel="prefetch" href="/assets/8、包装类.html-91494c0b.js" as="script"><link rel="prefetch" href="/assets/9、异常处理.html-efeedf1f.js" as="script"><link rel="prefetch" href="/assets/index.html-311b9a5b.js" as="script"><link rel="prefetch" href="/assets/1、Pytorch 建模流程.html-853004be.js" as="script"><link rel="prefetch" href="/assets/2、张量数据结构.html-369a6bfb.js" as="script"><link rel="prefetch" href="/assets/3、自动微分机制、优化器.html-a51e51d3.js" as="script"><link rel="prefetch" href="/assets/4、动态计算图.html-6751486b.js" as="script"><link rel="prefetch" href="/assets/5、Pytorch 低阶 API.html-384aa62f.js" as="script"><link rel="prefetch" href="/assets/6、Pytorch 中阶 API.html-12d00ec0.js" as="script"><link rel="prefetch" href="/assets/Pytorch-20.html-26d96f13.js" as="script"><link rel="prefetch" href="/assets/Pytorch.html-d1d2957f.js" as="script"><link rel="prefetch" href="/assets/强化学习.html-e85ae4ee.js" as="script"><link rel="prefetch" href="/assets/Vue笔记1-核心.html-e989c925.js" as="script"><link rel="prefetch" href="/assets/Vue笔记2-组件.html-8621d7cf.js" as="script"><link rel="prefetch" href="/assets/Vue笔记3-脚手架.html-de68fd83.js" as="script"><link rel="prefetch" href="/assets/Vue笔记4-Vue中的ajax.html-df24fe68.js" as="script"><link rel="prefetch" href="/assets/Vue笔记5-插槽.html-3155ce14.js" as="script"><link rel="prefetch" href="/assets/Vue笔记6-vuex.html-90ee75fa.js" as="script"><link rel="prefetch" href="/assets/Vue笔记7-路由.html-750fa33e.js" as="script"><link rel="prefetch" href="/assets/Vue笔记8-element-ui.html-a3b54a99.js" as="script"><link rel="prefetch" href="/assets/Vue3快速上手.html-943296f4.js" as="script"><link rel="prefetch" href="/assets/markdown扩展.html-1b4673b3.js" as="script"><link rel="prefetch" href="/assets/404.html-cc91ab3d.js" as="script"><link rel="prefetch" href="/assets/index.html-4d071ae6.js" as="script"><link rel="prefetch" href="/assets/index.html-a6b9d739.js" as="script"><link rel="prefetch" href="/assets/index.html-673bc96c.js" as="script"><link rel="prefetch" href="/assets/index.html-a7a29c4c.js" as="script"><link rel="prefetch" href="/assets/index.html-194b0620.js" as="script"><link rel="prefetch" href="/assets/index.html-a899c6cf.js" as="script"><link rel="prefetch" href="/assets/index.html-e2494c9f.js" as="script"><link rel="prefetch" href="/assets/index.html-61c0a09c.js" as="script"><link rel="prefetch" href="/assets/index.html-be2636ab.js" as="script"><link rel="prefetch" href="/assets/index.html-67b37d25.js" as="script"><link rel="prefetch" href="/assets/index.html-2f703168.js" as="script"><link rel="prefetch" href="/assets/index.html-ed384e30.js" as="script"><link rel="prefetch" href="/assets/index.html-49eef8d8.js" as="script"><link rel="prefetch" href="/assets/index.html-2d0de498.js" as="script"><link rel="prefetch" href="/assets/index.html-2fa96ec7.js" as="script"><link rel="prefetch" href="/assets/index.html-d9cf3019.js" as="script"><link rel="prefetch" href="/assets/index.html-6d51d871.js" as="script"><link rel="prefetch" href="/assets/index.html-d782a376.js" as="script"><link rel="prefetch" href="/assets/index.html-848ebbe8.js" as="script"><link rel="prefetch" href="/assets/index.html-1ba1d180.js" as="script"><link rel="prefetch" href="/assets/index.html-9e55ee4d.js" as="script"><link rel="prefetch" href="/assets/index.html-106d954c.js" as="script"><link rel="prefetch" href="/assets/index.html-5fbc2a0d.js" as="script"><link rel="prefetch" href="/assets/index.html-9c648683.js" as="script"><link rel="prefetch" href="/assets/index.html-1c24935a.js" as="script"><link rel="prefetch" href="/assets/index.html-99af66e2.js" as="script"><link rel="prefetch" href="/assets/index.html-ee02ddf0.js" as="script"><link rel="prefetch" href="/assets/index.html-20b834a5.js" as="script"><link rel="prefetch" href="/assets/index.html-3a4d6e36.js" as="script"><link rel="prefetch" href="/assets/index.html-139f2f06.js" as="script"><link rel="prefetch" href="/assets/index.html-a935f094.js" as="script"><link rel="prefetch" href="/assets/index.html-e92ce08c.js" as="script"><link rel="prefetch" href="/assets/index.html-63bc6b2b.js" as="script"><link rel="prefetch" href="/assets/index.html-94957f61.js" as="script"><link rel="prefetch" href="/assets/index.html-91bcd141.js" as="script"><link rel="prefetch" href="/assets/index.html-e5933818.js" as="script"><link rel="prefetch" href="/assets/index.html-abd11527.js" as="script"><link rel="prefetch" href="/assets/index.html-d6c5a433.js" as="script"><link rel="prefetch" href="/assets/index.html-ec18a7df.js" as="script"><link rel="prefetch" href="/assets/index.html-d3624e38.js" as="script"><link rel="prefetch" href="/assets/index.html-13f98761.js" as="script"><link rel="prefetch" href="/assets/index.html-0cce8e2d.js" as="script"><link rel="prefetch" href="/assets/index.html-7193a535.js" as="script"><link rel="prefetch" href="/assets/index.html-0e85c606.js" as="script"><link rel="prefetch" href="/assets/index.html-41fd6d63.js" as="script"><link rel="prefetch" href="/assets/index.html-faa3c911.js" as="script"><link rel="prefetch" href="/assets/index.html-bfb66f86.js" as="script"><link rel="prefetch" href="/assets/index.html-f5020150.js" as="script"><link rel="prefetch" href="/assets/index.html-5c2c76d5.js" as="script"><link rel="prefetch" href="/assets/index.html-a2feaac9.js" as="script"><link rel="prefetch" href="/assets/index.html-b7b8c4b6.js" as="script"><link rel="prefetch" href="/assets/index.html-ff6eb04f.js" as="script"><link rel="prefetch" href="/assets/index.html-a3550230.js" as="script"><link rel="prefetch" href="/assets/index.html-7a3254b0.js" as="script"><link rel="prefetch" href="/assets/index.html-c5715831.js" as="script"><link rel="prefetch" href="/assets/index.html-8af2a3d1.js" as="script"><link rel="prefetch" href="/assets/index.html-9d2fd3be.js" as="script"><link rel="prefetch" href="/assets/index.html-e9a4a4e1.js" as="script"><link rel="prefetch" href="/assets/index.html-cc614db6.js" as="script"><link rel="prefetch" href="/assets/index.html-b772e465.js" as="script"><link rel="prefetch" href="/assets/index.html-b1a752fe.js" as="script"><link rel="prefetch" href="/assets/index.html-4209efbb.js" as="script"><link rel="prefetch" href="/assets/index.html-4ff744ba.js" as="script"><link rel="prefetch" href="/assets/index.html-c424e42c.js" as="script"><link rel="prefetch" href="/assets/index.html-7f168d0f.js" as="script"><link rel="prefetch" href="/assets/index.html-56de2f95.js" as="script"><link rel="prefetch" href="/assets/index.html-f7cb97d3.js" as="script"><link rel="prefetch" href="/assets/index.html-c546e8a1.js" as="script"><link rel="prefetch" href="/assets/index.html-0009964a.js" as="script"><link rel="prefetch" href="/assets/index.html-00b637a2.js" as="script"><link rel="prefetch" href="/assets/index.html-fb5f6e90.js" as="script"><link rel="prefetch" href="/assets/index.html-ac4d56df.js" as="script"><link rel="prefetch" href="/assets/index.html-6aa2d78e.js" as="script"><link rel="prefetch" href="/assets/index.html-d462cdeb.js" as="script"><link rel="prefetch" href="/assets/index.html-6b698fb1.js" as="script"><link rel="prefetch" href="/assets/index.html-acbfbf53.js" as="script"><link rel="prefetch" href="/assets/index.html-905f1804.js" as="script"><link rel="prefetch" href="/assets/index.html-16d7d340.js" as="script"><link rel="prefetch" href="/assets/index.html-46271911.js" as="script"><link rel="prefetch" href="/assets/index.html-b604d4ee.js" as="script"><link rel="prefetch" href="/assets/index.html-14c05c19.js" as="script"><link rel="prefetch" href="/assets/index.html-f310c092.js" as="script"><link rel="prefetch" href="/assets/index.html-ccaf9ee9.js" as="script"><link rel="prefetch" href="/assets/index.html-e22bc441.js" as="script"><link rel="prefetch" href="/assets/index.html-1c66cf59.js" as="script"><link rel="prefetch" href="/assets/index.html-8208559f.js" as="script"><link rel="prefetch" href="/assets/index.html-2aea38ab.js" as="script"><link rel="prefetch" href="/assets/index.html-9c6eba41.js" as="script"><link rel="prefetch" href="/assets/index.html-38a7a2af.js" as="script"><link rel="prefetch" href="/assets/index.html-c8b179d7.js" as="script"><link rel="prefetch" href="/assets/index.html-7e1863fb.js" as="script"><link rel="prefetch" href="/assets/index.html-8968a188.js" as="script"><link rel="prefetch" href="/assets/index.html-64ee687b.js" as="script"><link rel="prefetch" href="/assets/index.html-80fe2383.js" as="script"><link rel="prefetch" href="/assets/index.html-fea946c3.js" as="script"><link rel="prefetch" href="/assets/index.html-f17f8ab5.js" as="script"><link rel="prefetch" href="/assets/index.html-1a5be529.js" as="script"><link rel="prefetch" href="/assets/index.html-0e767346.js" as="script"><link rel="prefetch" href="/assets/index.html-3ca31bd8.js" as="script"><link rel="prefetch" href="/assets/index.html-b133f8c8.js" as="script"><link rel="prefetch" href="/assets/index.html-7195b3a2.js" as="script"><link rel="prefetch" href="/assets/index.html-1beacc22.js" as="script"><link rel="prefetch" href="/assets/index.html-88e5e4ce.js" as="script"><link rel="prefetch" href="/assets/index.html-210be80e.js" as="script"><link rel="prefetch" href="/assets/index.html-f33d538b.js" as="script"><link rel="prefetch" href="/assets/index.html-4941c0fe.js" as="script"><link rel="prefetch" href="/assets/index.html-c736be09.js" as="script"><link rel="prefetch" href="/assets/index.html-03c9f91d.js" as="script"><link rel="prefetch" href="/assets/index.html-0b4b9ae3.js" as="script"><link rel="prefetch" href="/assets/index.html-229119d0.js" as="script"><link rel="prefetch" href="/assets/index.html-bc2fb4cf.js" as="script"><link rel="prefetch" href="/assets/index.html-1c4a3288.js" as="script"><link rel="prefetch" href="/assets/index.html-842d27e2.js" as="script"><link rel="prefetch" href="/assets/index.html-b4206ac4.js" as="script"><link rel="prefetch" href="/assets/index.html-73e0d1d2.js" as="script"><link rel="prefetch" href="/assets/index.html-72b69436.js" as="script"><link rel="prefetch" href="/assets/index.html-3477f208.js" as="script"><link rel="prefetch" href="/assets/index.html-7c416790.js" as="script"><link rel="prefetch" href="/assets/index.html-2fa8126d.js" as="script"><link rel="prefetch" href="/assets/index.html-c4278da5.js" as="script"><link rel="prefetch" href="/assets/index.html-97b358be.js" as="script"><link rel="prefetch" href="/assets/index.html-a3c429a2.js" as="script"><link rel="prefetch" href="/assets/index.html-e28d3b12.js" as="script"><link rel="prefetch" href="/assets/index.html-e18dcbc2.js" as="script"><link rel="prefetch" href="/assets/index.html-9cbad9b7.js" as="script"><link rel="prefetch" href="/assets/index.html-c02de52a.js" as="script"><link rel="prefetch" href="/assets/index.html-375eef32.js" as="script"><link rel="prefetch" href="/assets/index.html-3b8fb7db.js" as="script"><link rel="prefetch" href="/assets/index.html-2b8d0809.js" as="script"><link rel="prefetch" href="/assets/index.html-186dd8fe.js" as="script"><link rel="prefetch" href="/assets/index.html-62cabbed.js" as="script"><link rel="prefetch" href="/assets/index.html-991e5336.js" as="script"><link rel="prefetch" href="/assets/index.html-25c024ba.js" as="script"><link rel="prefetch" href="/assets/index.html-57cc6c33.js" as="script"><link rel="prefetch" href="/assets/Elasticsearch.html-0d7fc550.js" as="script"><link rel="prefetch" href="/assets/MongoDB.html-18e2230e.js" as="script"><link rel="prefetch" href="/assets/MySQL基础.html-738e4162.js" as="script"><link rel="prefetch" href="/assets/Redis.html-2426f726.js" as="script"><link rel="prefetch" href="/assets/IDEA、Eclipse快捷键.html-f736cf02.js" as="script"><link rel="prefetch" href="/assets/JDBC.html-b3f12b6c.js" as="script"><link rel="prefetch" href="/assets/JVM.html-ed716eb0.js" as="script"><link rel="prefetch" href="/assets/JVM入门.html-16317cb3.js" as="script"><link rel="prefetch" href="/assets/JWT.html-c4106f3d.js" as="script"><link rel="prefetch" href="/assets/JavaWeb基础.html-27d1b882.js" as="script"><link rel="prefetch" href="/assets/Maven基础.html-bcc1594c.js" as="script"><link rel="prefetch" href="/assets/MyBatis.html-fd974e69.js" as="script"><link rel="prefetch" href="/assets/MybatisPlus.html-49178a40.js" as="script"><link rel="prefetch" href="/assets/RabbitMQ.html-e5295d93.js" as="script"><link rel="prefetch" href="/assets/Shiro.html-499a24cf.js" as="script"><link rel="prefetch" href="/assets/SpringBoot.html-1ef90602.js" as="script"><link rel="prefetch" href="/assets/SpringBoot常用注解总结.html-53bc314c.js" as="script"><link rel="prefetch" href="/assets/SpringBoot自动装配原理.html-c522408d.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础.html-7171de6c.js" as="script"><link rel="prefetch" href="/assets/SpringCloud基础2024.html-f789b3a7.js" as="script"><link rel="prefetch" href="/assets/SpringMVC.html-569381a2.js" as="script"><link rel="prefetch" href="/assets/Spring基础.html-210cf7a4.js" as="script"><link rel="prefetch" href="/assets/index.html-34c332c9.js" as="script"><link rel="prefetch" href="/assets/Matplotlib.html-18136793.js" as="script"><link rel="prefetch" href="/assets/Numpy.html-0352e1f2.js" as="script"><link rel="prefetch" href="/assets/Pandas.html-b299707b.js" as="script"><link rel="prefetch" href="/assets/python 基础语法.html-61cae457.js" as="script"><link rel="prefetch" href="/assets/python 项目注意事项.html-972a85a9.js" as="script"><link rel="prefetch" href="/assets/Ajax.html-7745926e.js" as="script"><link rel="prefetch" href="/assets/Axios.html-856e9d62.js" as="script"><link rel="prefetch" href="/assets/CSS3.html-e4e44c8b.js" as="script"><link rel="prefetch" href="/assets/HTML.html-be292c86.js" as="script"><link rel="prefetch" href="/assets/Node.js笔记.html-536f7790.js" as="script"><link rel="prefetch" href="/assets/Promise.html-5beb2293.js" as="script"><link rel="prefetch" href="/assets/Git.html-abb14aab.js" as="script"><link rel="prefetch" href="/assets/Markdown语法基础.html-fcef6cd2.js" as="script"><link rel="prefetch" href="/assets/操作系统.html-5fae2790.js" as="script"><link rel="prefetch" href="/assets/数据结构.html-bcd279e3.js" as="script"><link rel="prefetch" href="/assets/正则表达式.html-7184303d.js" as="script"><link rel="prefetch" href="/assets/计算机组成原理.html-187f2e84.js" as="script"><link rel="prefetch" href="/assets/计算机网络.html-04b224a3.js" as="script"><link rel="prefetch" href="/assets/设计模式.html-1de3d2ac.js" as="script"><link rel="prefetch" href="/assets/面向对象设计基本原则.html-322ec365.js" as="script"><link rel="prefetch" href="/assets/Docker.html-a08a84b6.js" as="script"><link rel="prefetch" href="/assets/GitHub Actions.html-84e4b7ba.js" as="script"><link rel="prefetch" href="/assets/基于centos部署java项目.html-4222b066.js" as="script"><link rel="prefetch" href="/assets/一些插件.html-d3d9a12b.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-2a26df38.js" as="script"><link rel="prefetch" href="/assets/CSGO饰品图.html-d5e35aa1.js" as="script"><link rel="prefetch" href="/assets/基础.html-49030910.js" as="script"><link rel="prefetch" href="/assets/快捷键.html-ee03d585.js" as="script"><link rel="prefetch" href="/assets/Guitar.html-de2fc7df.js" as="script"><link rel="prefetch" href="/assets/hlae.html-4c73f7a3.js" as="script"><link rel="prefetch" href="/assets/settings.html-2520c5f6.js" as="script"><link rel="prefetch" href="/assets/Japanese.html-31f97b85.js" as="script"><link rel="prefetch" href="/assets/index.html-e5dce5b0.js" as="script"><link rel="prefetch" href="/assets/index.html-b3e00dd1.js" as="script"><link rel="prefetch" href="/assets/30天JavaScript挑战.html-a7bd1e9b.js" as="script"><link rel="prefetch" href="/assets/高频 SQL 50 题（基础版）.html-b2ac08c2.js" as="script"><link rel="prefetch" href="/assets/多线程.html-d55aba4f.js" as="script"><link rel="prefetch" href="/assets/noob-Rg-better.html-d6467376.js" as="script"><link rel="prefetch" href="/assets/noob-Rg.html-72a72445.js" as="script"><link rel="prefetch" href="/assets/1、JavaScript基础语法笔记.html-74deb03a.js" as="script"><link rel="prefetch" href="/assets/2、WebAPIs笔记.html-c07634c9.js" as="script"><link rel="prefetch" href="/assets/3、JavaScript进阶.html-76b4a8ed.js" as="script"><link rel="prefetch" href="/assets/leetcode228_汇总区间.html-f9912c58.js" as="script"><link rel="prefetch" href="/assets/leetcode_001_两数之和.html-b30d3b66.js" as="script"><link rel="prefetch" href="/assets/leetcode_002_两数相加.html-9bfac7ab.js" as="script"><link rel="prefetch" href="/assets/leetcode_003_无重复字符的最长子串.html-007076aa.js" as="script"><link rel="prefetch" href="/assets/leetcode_004_寻找两个正序数组的中位数.html-cb1b4b4e.js" as="script"><link rel="prefetch" href="/assets/leetcode_005_最长回文子串.html-a14fe196.js" as="script"><link rel="prefetch" href="/assets/leetcode_006_N 字形变换.html-c9e99ae1.js" as="script"><link rel="prefetch" href="/assets/leetcode_007_整数反转.html-c84a091f.js" as="script"><link rel="prefetch" href="/assets/leetcode_008_字符串转换整数 (atoi).html-f6ebc4c4.js" as="script"><link rel="prefetch" href="/assets/leetcode_009_回文数.html-ebcb729b.js" as="script"><link rel="prefetch" href="/assets/leetcode_010_正则表达式匹配.html-55517c4e.js" as="script"><link rel="prefetch" href="/assets/leetcode_011_盛最多水的容器.html-df7531d1.js" as="script"><link rel="prefetch" href="/assets/leetcode_012_整数转罗马数字.html-210607e5.js" as="script"><link rel="prefetch" href="/assets/leetcode_013_罗马数字转整数.html-26ea668f.js" as="script"><link rel="prefetch" href="/assets/leetcode_014_最长公共前缀.html-f2c288e7.js" as="script"><link rel="prefetch" href="/assets/leetcode_015_三数之和.html-b8328e1c.js" as="script"><link rel="prefetch" href="/assets/leetcode_016_最接近的三数之和.html-27592b5c.js" as="script"><link rel="prefetch" href="/assets/leetcode_017_电话号码的字母组合.html-1705bd4a.js" as="script"><link rel="prefetch" href="/assets/leetcode_018_四数之和.html-9c39a8bf.js" as="script"><link rel="prefetch" href="/assets/leetcode_019_删除链表的倒数第 N 个结点.html-aa6b9b12.js" as="script"><link rel="prefetch" href="/assets/leetcode_020_有效的括号.html-bd145592.js" as="script"><link rel="prefetch" href="/assets/leetcode_021_合并两个有序链表.html-e6332a8e.js" as="script"><link rel="prefetch" href="/assets/leetcode_022_括号生成.html-f2d40f8d.js" as="script"><link rel="prefetch" href="/assets/leetcode_023_合并 K 个升序链表.html-11b0e670.js" as="script"><link rel="prefetch" href="/assets/leetcode_024_两两交换链表中的节点.html-1e3758c7.js" as="script"><link rel="prefetch" href="/assets/leetcode_025_K 个一组翻转链表.html-1c101f8a.js" as="script"><link rel="prefetch" href="/assets/leetcode_026_删除有序数组中的重复项.html-738220c9.js" as="script"><link rel="prefetch" href="/assets/leetcode_027_移除元素.html-a85df841.js" as="script"><link rel="prefetch" href="/assets/leetcode_028_找出字符串中第一个匹配项的下标.html-6c6b555b.js" as="script"><link rel="prefetch" href="/assets/leetcode_029_两数相除.html-bf564475.js" as="script"><link rel="prefetch" href="/assets/leetcode_030_串联所有单词的子串.html-8fa5d1e7.js" as="script"><link rel="prefetch" href="/assets/leetcode_031_下一个排列.html-33e31919.js" as="script"><link rel="prefetch" href="/assets/leetcode_032_最长有效括号.html-b749c8be.js" as="script"><link rel="prefetch" href="/assets/leetcode_033_搜索旋转排序数组.html-0b05ed64.js" as="script"><link rel="prefetch" href="/assets/leetcode_034_在排序数组中查找元素的第一个和最后一个位置.html-7ef9fca9.js" as="script"><link rel="prefetch" href="/assets/leetcode_035_搜索插入位置.html-0612c188.js" as="script"><link rel="prefetch" href="/assets/leetcode_036_有效的数独.html-1a11f071.js" as="script"><link rel="prefetch" href="/assets/leetcode_038_外观数列.html-cf7dfb5f.js" as="script"><link rel="prefetch" href="/assets/leetcode_039_ 组合总和.html-49c183a6.js" as="script"><link rel="prefetch" href="/assets/leetcode_040_ 组合总和II.html-4d368bae.js" as="script"><link rel="prefetch" href="/assets/leetcode_041_ 缺失的第一个正数.html-fb7fd304.js" as="script"><link rel="prefetch" href="/assets/leetcode_042_接雨水.html-db67a81b.js" as="script"><link rel="prefetch" href="/assets/leetcode_043_字符串相乘.html-afe0ae3e.js" as="script"><link rel="prefetch" href="/assets/leetcode_045_跳跃游戏II.html-9cbc0467.js" as="script"><link rel="prefetch" href="/assets/leetcode_046_全排列.html-a31a9ae1.js" as="script"><link rel="prefetch" href="/assets/leetcode_047_全排列II.html-cb055914.js" as="script"><link rel="prefetch" href="/assets/leetcode_048_旋转图像.html-8bc5b16c.js" as="script"><link rel="prefetch" href="/assets/leetcode_049_字母异位词分组.html-60f8a6e2.js" as="script"><link rel="prefetch" href="/assets/leetcode_050_Pow(x_n).html-2c07a1f6.js" as="script"><link rel="prefetch" href="/assets/leetcode_051_N 皇后.html-c4e50f64.js" as="script"><link rel="prefetch" href="/assets/leetcode_052_N 皇后 II.html-ccbc2c21.js" as="script"><link rel="prefetch" href="/assets/leetcode_053_最大子数组和.html-a6cb397f.js" as="script"><link rel="prefetch" href="/assets/leetcode_054_螺旋矩阵.html-beafbc6b.js" as="script"><link rel="prefetch" href="/assets/leetcode_055_跳跃游戏.html-a10c4ff6.js" as="script"><link rel="prefetch" href="/assets/leetcode_056_合并区间.html-6dd1d13a.js" as="script"><link rel="prefetch" href="/assets/leetcode_058_最后一个单词的长度.html-58e7ab1d.js" as="script"><link rel="prefetch" href="/assets/leetcode_061_旋转链表.html-5940a607.js" as="script"><link rel="prefetch" href="/assets/leetcode_062_不同路径.html-8c2d2e2f.js" as="script"><link rel="prefetch" href="/assets/leetcode_063_不同路径II.html-0a132531.js" as="script"><link rel="prefetch" href="/assets/leetcode_064_最小路径和.html-ec992938.js" as="script"><link rel="prefetch" href="/assets/leetcode_066_加一.html-056b8c77.js" as="script"><link rel="prefetch" href="/assets/leetcode_067_二进制求和.html-5d437fcd.js" as="script"><link rel="prefetch" href="/assets/leetcode_068_文本左右对齐.html-2607aebb.js" as="script"><link rel="prefetch" href="/assets/leetcode_069_x的平方根.html-edf9ecdf.js" as="script"><link rel="prefetch" href="/assets/leetcode_070_爬楼梯.html-14d21099.js" as="script"><link rel="prefetch" href="/assets/leetcode_072_编辑距离.html-1bac988b.js" as="script"><link rel="prefetch" href="/assets/leetcode_073_矩阵置零.html-122f1f73.js" as="script"><link rel="prefetch" href="/assets/leetcode_075_颜色分类.html-f2895821.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串 copy.html-cc2a5fbf.js" as="script"><link rel="prefetch" href="/assets/leetcode_076_最小覆盖子串.html-b79b0ecc.js" as="script"><link rel="prefetch" href="/assets/leetcode_079_单词搜索.html-09500add.js" as="script"><link rel="prefetch" href="/assets/leetcode_080_删除有序数组中的重复项.html-e2afcbd8.js" as="script"><link rel="prefetch" href="/assets/leetcode_082_删除排序链表中的重复元素 II.html-37d65f99.js" as="script"><link rel="prefetch" href="/assets/leetcode_083_删除排序链表中的重复元素.html-3627048e.js" as="script"><link rel="prefetch" href="/assets/leetcode_086_分隔链表.html-27e5f9b1.js" as="script"><link rel="prefetch" href="/assets/leetcode_088_合并两个有序数组.html-72c3eb50.js" as="script"><link rel="prefetch" href="/assets/leetcode_092_反转链表 II.html-ff440f3a.js" as="script"><link rel="prefetch" href="/assets/leetcode_094_二叉树的中序遍历.html-767e8da7.js" as="script"><link rel="prefetch" href="/assets/leetcode_095_不同的二叉搜索树 II.html-af031ac1.js" as="script"><link rel="prefetch" href="/assets/leetcode_096_不同的二叉搜索树.html-47350676.js" as="script"><link rel="prefetch" href="/assets/leetcode_098_验证二叉搜索树.html-36411523.js" as="script"><link rel="prefetch" href="/assets/leetcode_1004_最大连续1的个数 III.html-087b9aaa.js" as="script"><link rel="prefetch" href="/assets/leetcode_100_相同的树.html-195a94dc.js" as="script"><link rel="prefetch" href="/assets/leetcode_101_对称二叉树.html-ff2092ec.js" as="script"><link rel="prefetch" href="/assets/leetcode_102_二叉树的层序遍历.html-346a5d17.js" as="script"><link rel="prefetch" href="/assets/leetcode_103_二叉树的锯齿形层序遍历.html-9c094b1f.js" as="script"><link rel="prefetch" href="/assets/leetcode_104_二叉树的最大深度.html-58a74030.js" as="script"><link rel="prefetch" href="/assets/leetcode_105_从前序与中序遍历序列构造二叉树.html-68391eb8.js" as="script"><link rel="prefetch" href="/assets/leetcode_106_从中序与后序遍历序列构造二叉树.html-0265430e.js" as="script"><link rel="prefetch" href="/assets/leetcode_1071_字符串的最大公因子.html-b28bf25a.js" as="script"><link rel="prefetch" href="/assets/leetcode_107_二叉树的层序遍历 II.html-130b2c60.js" as="script"><link rel="prefetch" href="/assets/leetcode_108_将有序数组转换为二叉搜索树.html-57076f6e.js" as="script"><link rel="prefetch" href="/assets/leetcode_112_路径总和.html-b1eb4144.js" as="script"><link rel="prefetch" href="/assets/leetcode_113_路径总和II.html-ccddd650.js" as="script"><link rel="prefetch" href="/assets/leetcode_1143_最长公共子序列.html-07a61c9e.js" as="script"><link rel="prefetch" href="/assets/leetcode_114_二叉树展开为链表.html-f9a3d8c7.js" as="script"><link rel="prefetch" href="/assets/leetcode_1161_最大层内元素和.html-e0410714.js" as="script"><link rel="prefetch" href="/assets/leetcode_117_填充每个节点的下一个右侧节点指针 II.html-964b85a3.js" as="script"><link rel="prefetch" href="/assets/leetcode_118_杨辉三角.html-6d480c4e.js" as="script"><link rel="prefetch" href="/assets/leetcode_119_杨辉三角 II.html-ec0457df.js" as="script"><link rel="prefetch" href="/assets/leetcode_1207_独一无二的出现次数.html-16cd924f.js" as="script"><link rel="prefetch" href="/assets/leetcode_120_三角形最小路径和.html-973da24f.js" as="script"><link rel="prefetch" href="/assets/leetcode_121_买卖股票的最佳时机 I.html-7868371f.js" as="script"><link rel="prefetch" href="/assets/leetcode_122_买卖股票的最佳时机 II.html-d0d57df2.js" as="script"><link rel="prefetch" href="/assets/leetcode_124_二叉树中的最大路径和.html-dbca1aa0.js" as="script"><link rel="prefetch" href="/assets/leetcode_125_验证回文串.html-d0bf9bf5.js" as="script"><link rel="prefetch" href="/assets/leetcode_128_最长连续序列.html-f50f392c.js" as="script"><link rel="prefetch" href="/assets/leetcode_129_求根节点到叶节点数字之和.html-2b818f76.js" as="script"><link rel="prefetch" href="/assets/leetcode_130_被围绕的区域.html-7e07dcaa.js" as="script"><link rel="prefetch" href="/assets/leetcode_1318_或运算的最小翻转次数.html-2973d39f.js" as="script"><link rel="prefetch" href="/assets/leetcode_134_加油站.html-cb195c4c.js" as="script"><link rel="prefetch" href="/assets/leetcode_135_分发糖果.html-014db911.js" as="script"><link rel="prefetch" href="/assets/leetcode_136_只出现一次的数字.html-a13743bf.js" as="script"><link rel="prefetch" href="/assets/leetcode_1372_二叉树中的最长交错路径.html-4a16cacc.js" as="script"><link rel="prefetch" href="/assets/leetcode_139_单词拆分.html-25f33277.js" as="script"><link rel="prefetch" href="/assets/leetcode_141_环形链表.html-c392cb3f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1431_拥有最多糖果的孩子.html-830ccb3f.js" as="script"><link rel="prefetch" href="/assets/leetcode_1448_统计二叉树中好节点的数目.html-a20e850a.js" as="script"><link rel="prefetch" href="/assets/leetcode_144_二叉树的前序遍历.html-ceb97bed.js" as="script"><link rel="prefetch" href="/assets/leetcode_1456_定长子串中元音的最大数目.html-ae291aee.js" as="script"><link rel="prefetch" href="/assets/leetcode_145_二叉树的后序遍历.html-0df00d86.js" as="script"><link rel="prefetch" href="/assets/leetcode_1466_重新规划路线.html-69d79ef7.js" as="script"><link rel="prefetch" href="/assets/leetcode_146_LRU 缓存.html-a84091db.js" as="script"><link rel="prefetch" href="/assets/leetcode_148_排序链表.html-cfb7c0c8.js" as="script"><link rel="prefetch" href="/assets/leetcode_1493_删掉一个元素以后全为 1 的最长子数组.html-999b513f.js" as="script"><link rel="prefetch" href="/assets/leetcode_150_逆波兰表达式求值.html-11f61c9b.js" as="script"><link rel="prefetch" href="/assets/leetcode_151_反转字符串中的单词.html-859a3aeb.js" as="script"><link rel="prefetch" href="/assets/leetcode_155_最小栈.html-ae0c0f6c.js" as="script"><link rel="prefetch" href="/assets/leetcode_160_相交链表.html-4fd6a5a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值 copy.html-3543f5a2.js" as="script"><link rel="prefetch" href="/assets/leetcode_162_寻找峰值.html-64c3e747.js" as="script"><link rel="prefetch" href="/assets/leetcode_1657_确定两个字符串是否接近.html-936b7425.js" as="script"><link rel="prefetch" href="/assets/leetcode_1679_K 和数对的最大数目.html-e33f8d5f.js" as="script"><link rel="prefetch" href="/assets/leetcode_169_多数元素.html-abb8641b.js" as="script"><link rel="prefetch" href="/assets/leetcode_1732_找到最高海拔.html-75a727cf.js" as="script"><link rel="prefetch" href="/assets/leetcode_173_二叉搜索树迭代器.html-562a79aa.js" as="script"><link rel="prefetch" href="/assets/leetcode_1768_交替合并字符串.html-26564d1a.js" as="script"><link rel="prefetch" href="/assets/leetcode_189_轮转数组.html-5302a751.js" as="script"><link rel="prefetch" href="/assets/leetcode_1926_迷宫中离入口最近的出口.html-3c209c3d.js" as="script"><link rel="prefetch" href="/assets/leetcode_198_打家劫舍.html-df4dbe92.js" as="script"><link rel="prefetch" href="/assets/leetcode_199. 二叉树的右视图.html-cb1ca647.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数 copy.html-e704d52c.js" as="script"><link rel="prefetch" href="/assets/leetcode_202_快乐数.html-a80a5bf8.js" as="script"><link rel="prefetch" href="/assets/leetcode_203_移除链表元素.html-7bd50157.js" as="script"><link rel="prefetch" href="/assets/leetcode_206_反转链表.html-03cb3252.js" as="script"><link rel="prefetch" href="/assets/leetcode_208_实现 Trie (前缀树).html-575324ff.js" as="script"><link rel="prefetch" href="/assets/leetcode_2095_删除链表的中间节点.html-5eacffc1.js" as="script"><link rel="prefetch" href="/assets/leetcode_209_长度最小的子数组.html-4bc77925.js" as="script"><link rel="prefetch" href="/assets/leetcode_2130_链表最大孪生和.html-c3d7c944.js" as="script"><link rel="prefetch" href="/assets/leetcode_215_数组中的第K个最大元素.html-0987630d.js" as="script"><link rel="prefetch" href="/assets/leetcode_216_组合总和 III.html-1c5cc65f.js" as="script"><link rel="prefetch" href="/assets/leetcode_219_存在重复元素 II.html-7cf17c03.js" as="script"><link rel="prefetch" href="/assets/leetcode_2215_找出两数组的不同.html-c69efeaf.js" as="script"><link rel="prefetch" href="/assets/leetcode_222_完全二叉树的节点个数.html-4b4f3668.js" as="script"><link rel="prefetch" href="/assets/leetcode_226_翻转二叉树.html-0cb3444f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2300. 咒语和药水的成功对数.html-8435e5b8.js" as="script"><link rel="prefetch" href="/assets/leetcode_230_二叉搜索树中第K小的元素.html-3e8305bc.js" as="script"><link rel="prefetch" href="/assets/leetcode_2336_无限集中的最小数字.html-dbb9e90f.js" as="script"><link rel="prefetch" href="/assets/leetcode_234_回文链表.html-0880fa15.js" as="script"><link rel="prefetch" href="/assets/leetcode_2352_相等行列对.html-910ad1bd.js" as="script"><link rel="prefetch" href="/assets/leetcode_236_二叉树的最近公共祖先.html-30acdc66.js" as="script"><link rel="prefetch" href="/assets/leetcode_238_除自身以外数组的乘积.html-1869b31f.js" as="script"><link rel="prefetch" href="/assets/leetcode_2390_从字符串中移除星号.html-1ba312f0.js" as="script"><link rel="prefetch" href="/assets/leetcode_242_有效的字母异位词.html-ac097342.js" as="script"><link rel="prefetch" href="/assets/leetcode_2542_最大序列的分数.html-921fbe4d.js" as="script"><link rel="prefetch" href="/assets/leetcode_274_H指数.html-06b0fb59.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy 2.html-287ed65d.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0 copy.html-878d1d33.js" as="script"><link rel="prefetch" href="/assets/leetcode_283_移动0.html-7d26c118.js" as="script"><link rel="prefetch" href="/assets/leetcode_300_最长递增子序列.html-014e199d.js" as="script"><link rel="prefetch" href="/assets/leetcode_322_零钱兑换.html-a210f6f2.js" as="script"><link rel="prefetch" href="/assets/leetcode_328_奇偶链表.html-2da74d0c.js" as="script"><link rel="prefetch" href="/assets/leetcode_334_递增的三元子序列.html-603d228f.js" as="script"><link rel="prefetch" href="/assets/leetcode_338_比特位计数.html-232c9f4d.js" as="script"><link rel="prefetch" href="/assets/leetcode_345_反转字符串中的元音字母.html-e7f68656.js" as="script"><link rel="prefetch" href="/assets/leetcode_374_猜数字大小.html-3ecb9cc0.js" as="script"><link rel="prefetch" href="/assets/leetcode_380_O(1) 时间插入、删除和获取随机元素.html-c59cd553.js" as="script"><link rel="prefetch" href="/assets/leetcode_383_赎金信.html-b84c7b85.js" as="script"><link rel="prefetch" href="/assets/leetcode_392_判断子序列.html-700d7d60.js" as="script"><link rel="prefetch" href="/assets/leetcode_394_字符串解码.html-a722ecf1.js" as="script"><link rel="prefetch" href="/assets/leetcode_435_无重叠区间.html-22869f9a.js" as="script"><link rel="prefetch" href="/assets/leetcode_437_路径总和 III.html-00cf9c86.js" as="script"><link rel="prefetch" href="/assets/leetcode_443_压缩字符串.html-10a3b932.js" as="script"><link rel="prefetch" href="/assets/leetcode_450_删除二叉搜索树中的节点.html-fd58fc79.js" as="script"><link rel="prefetch" href="/assets/leetcode_452_用最少数量的箭引爆气球.html-00ac0bb9.js" as="script"><link rel="prefetch" href="/assets/leetcode_530_二叉搜索树的最小绝对差.html-a5e67bf1.js" as="script"><link rel="prefetch" href="/assets/leetcode_547_省份数量.html-27aa5613.js" as="script"><link rel="prefetch" href="/assets/leetcode_605_种花问题.html-3ea5bf98.js" as="script"><link rel="prefetch" href="/assets/leetcode_637_二叉树的层平均值.html-f060e153.js" as="script"><link rel="prefetch" href="/assets/leetcode_643_子数组最大平均数 I.html-1dedb4e5.js" as="script"><link rel="prefetch" href="/assets/leetcode_649_Dota2 参议院.html-f0611bc9.js" as="script"><link rel="prefetch" href="/assets/leetcode_700_二叉搜索树中的搜索.html-d5e0cf8b.js" as="script"><link rel="prefetch" href="/assets/leetcode_714_买卖股票的最佳时机含手续费.html-3e3ada12.js" as="script"><link rel="prefetch" href="/assets/leetcode_724_寻找数组的中心下标.html-d9eb915f.js" as="script"><link rel="prefetch" href="/assets/leetcode_735_行星碰撞.html-6f26bd7a.js" as="script"><link rel="prefetch" href="/assets/leetcode_739_每日温度.html-c8b375ce.js" as="script"><link rel="prefetch" href="/assets/leetcode_746_使用最小花费爬楼梯.html-9c68dfe3.js" as="script"><link rel="prefetch" href="/assets/leetcode_790_多米诺和托米诺平铺.html-4fa37dc7.js" as="script"><link rel="prefetch" href="/assets/leetcode_841_钥匙和房间.html-3086a1e0.js" as="script"><link rel="prefetch" href="/assets/leetcode_872_叶子相似的树.html-f5d27804.js" as="script"><link rel="prefetch" href="/assets/leetcode_875_爱吃香蕉的珂珂.html-2a8dc5a5.js" as="script"><link rel="prefetch" href="/assets/leetcode_876_链表的中间结点.html-0ca411fc.js" as="script"><link rel="prefetch" href="/assets/leetcode_901_股票价格跨度.html-7639acde.js" as="script"><link rel="prefetch" href="/assets/leetcode_933_最近的请求次数.html-4819df74.js" as="script"><link rel="prefetch" href="/assets/leetcode_994_腐烂的橘子.html-8b9e2590.js" as="script"><link rel="prefetch" href="/assets/leetcode_LCP68_美丽的花束.html-21b7b43a.js" as="script"><link rel="prefetch" href="/assets/1、TypeScript语言简介.html-69bef8f2.js" as="script"><link rel="prefetch" href="/assets/2、基本用法.html-1d168ed8.js" as="script"><link rel="prefetch" href="/assets/3、any，unknown ，never 类型.html-fffb6247.js" as="script"><link rel="prefetch" href="/assets/4、系统类型.html-19d5b185.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-39535894.js" as="script"><link rel="prefetch" href="/assets/6、元祖.html-1b350b99.js" as="script"><link rel="prefetch" href="/assets/7、symbol 类型.html-d6ef8cc4.js" as="script"><link rel="prefetch" href="/assets/8、函数.html-d07ccfc6.js" as="script"><link rel="prefetch" href="/assets/index.html-c7ec8058.js" as="script"><link rel="prefetch" href="/assets/Arrays类.html-1c63ecc4.js" as="script"><link rel="prefetch" href="/assets/BigInteger和BigDecimal.html-0ae5e7a6.js" as="script"><link rel="prefetch" href="/assets/Collections类.html-4f253432.js" as="script"><link rel="prefetch" href="/assets/Java比较器.html-37dfbc7f.js" as="script"><link rel="prefetch" href="/assets/Math类.html-9a12a6b5.js" as="script"><link rel="prefetch" href="/assets/Object类.html-0c0f949d.js" as="script"><link rel="prefetch" href="/assets/Pattern 与 Matcher 类.html-ba2f8697.js" as="script"><link rel="prefetch" href="/assets/Stream API.html-72a050ac.js" as="script"><link rel="prefetch" href="/assets/String、Scanner相关类.html-a7be5e8f.js" as="script"><link rel="prefetch" href="/assets/System类.html-30592038.js" as="script"><link rel="prefetch" href="/assets/日期时间API.html-a9086afe.js" as="script"><link rel="prefetch" href="/assets/10、多线程.html-d2c66f5d.js" as="script"><link rel="prefetch" href="/assets/11、枚举类.html-cddfc33d.js" as="script"><link rel="prefetch" href="/assets/12、注解.html-6f4e8be4.js" as="script"><link rel="prefetch" href="/assets/13、集合.html-fec58135.js" as="script"><link rel="prefetch" href="/assets/14、泛型.html-b373376c.js" as="script"><link rel="prefetch" href="/assets/15、IO流.html-f29f26b5.js" as="script"><link rel="prefetch" href="/assets/16、网络编程.html-0cd1aae6.js" as="script"><link rel="prefetch" href="/assets/17、反射.html-82764281.js" as="script"><link rel="prefetch" href="/assets/18、新特性.html-dc541f5a.js" as="script"><link rel="prefetch" href="/assets/19、格式化输入输出.html-cd21d23e.js" as="script"><link rel="prefetch" href="/assets/1、基础概念.html-efb63d0e.js" as="script"><link rel="prefetch" href="/assets/2、数据类型.html-c9b97c1c.js" as="script"><link rel="prefetch" href="/assets/3、运算符.html-a914be3d.js" as="script"><link rel="prefetch" href="/assets/4、程序流程控制.html-060701c9.js" as="script"><link rel="prefetch" href="/assets/5、数组.html-799f1148.js" as="script"><link rel="prefetch" href="/assets/6、面向对象.html-5d0b38e6.js" as="script"><link rel="prefetch" href="/assets/7、单元测试Junit.html-92428073.js" as="script"><link rel="prefetch" href="/assets/8、包装类.html-c029ff7d.js" as="script"><link rel="prefetch" href="/assets/9、异常处理.html-cebe2093.js" as="script"><link rel="prefetch" href="/assets/index.html-35230eef.js" as="script"><link rel="prefetch" href="/assets/1、Pytorch 建模流程.html-204fd453.js" as="script"><link rel="prefetch" href="/assets/2、张量数据结构.html-1ad27c32.js" as="script"><link rel="prefetch" href="/assets/3、自动微分机制、优化器.html-93e2335b.js" as="script"><link rel="prefetch" href="/assets/4、动态计算图.html-0d4dfc40.js" as="script"><link rel="prefetch" href="/assets/5、Pytorch 低阶 API.html-2c7ecda8.js" as="script"><link rel="prefetch" href="/assets/6、Pytorch 中阶 API.html-320fbe4c.js" as="script"><link rel="prefetch" href="/assets/Pytorch-20.html-19e25315.js" as="script"><link rel="prefetch" href="/assets/Pytorch.html-5c7439ff.js" as="script"><link rel="prefetch" href="/assets/强化学习.html-baeb28a0.js" as="script"><link rel="prefetch" href="/assets/Vue笔记1-核心.html-478eb53b.js" as="script"><link rel="prefetch" href="/assets/Vue笔记2-组件.html-f49fd2dc.js" as="script"><link rel="prefetch" href="/assets/Vue笔记3-脚手架.html-e2586dc6.js" as="script"><link rel="prefetch" href="/assets/Vue笔记4-Vue中的ajax.html-4ed4ae90.js" as="script"><link rel="prefetch" href="/assets/Vue笔记5-插槽.html-89733d2a.js" as="script"><link rel="prefetch" href="/assets/Vue笔记6-vuex.html-4a41d3df.js" as="script"><link rel="prefetch" href="/assets/Vue笔记7-路由.html-267b1888.js" as="script"><link rel="prefetch" href="/assets/Vue笔记8-element-ui.html-7501e6a5.js" as="script"><link rel="prefetch" href="/assets/Vue3快速上手.html-235433b4.js" as="script"><link rel="prefetch" href="/assets/markdown扩展.html-366e7cf5.js" as="script"><link rel="prefetch" href="/assets/404.html-2c6d1860.js" as="script"><link rel="prefetch" href="/assets/index.html-19b91853.js" as="script"><link rel="prefetch" href="/assets/index.html-1adc1f61.js" as="script"><link rel="prefetch" href="/assets/index.html-64ed417e.js" as="script"><link rel="prefetch" href="/assets/index.html-46c9f9e0.js" as="script"><link rel="prefetch" href="/assets/index.html-ca3a871d.js" as="script"><link rel="prefetch" href="/assets/index.html-ca9a3aa4.js" as="script"><link rel="prefetch" href="/assets/index.html-9a647d67.js" as="script"><link rel="prefetch" href="/assets/index.html-738c95b3.js" as="script"><link rel="prefetch" href="/assets/index.html-80ef9a80.js" as="script"><link rel="prefetch" href="/assets/index.html-a7f5fcaa.js" as="script"><link rel="prefetch" href="/assets/index.html-50336445.js" as="script"><link rel="prefetch" href="/assets/index.html-06ea925d.js" as="script"><link rel="prefetch" href="/assets/index.html-32c6e433.js" as="script"><link rel="prefetch" href="/assets/index.html-cf746d71.js" as="script"><link rel="prefetch" href="/assets/index.html-d6aba97c.js" as="script"><link rel="prefetch" href="/assets/index.html-2ccd6a89.js" as="script"><link rel="prefetch" href="/assets/index.html-f471eca0.js" as="script"><link rel="prefetch" href="/assets/index.html-ad09016f.js" as="script"><link rel="prefetch" href="/assets/index.html-635218fb.js" as="script"><link rel="prefetch" href="/assets/index.html-9df1a602.js" as="script"><link rel="prefetch" href="/assets/index.html-a493ef55.js" as="script"><link rel="prefetch" href="/assets/index.html-9464c33f.js" as="script"><link rel="prefetch" href="/assets/index.html-298a7354.js" as="script"><link rel="prefetch" href="/assets/index.html-897f0710.js" as="script"><link rel="prefetch" href="/assets/index.html-88487998.js" as="script"><link rel="prefetch" href="/assets/index.html-79557cd2.js" as="script"><link rel="prefetch" href="/assets/index.html-290568b6.js" as="script"><link rel="prefetch" href="/assets/index.html-431c0528.js" as="script"><link rel="prefetch" href="/assets/index.html-f82cadcf.js" as="script"><link rel="prefetch" href="/assets/index.html-4e7944f1.js" as="script"><link rel="prefetch" href="/assets/index.html-3b8dbb81.js" as="script"><link rel="prefetch" href="/assets/index.html-9b7afb0c.js" as="script"><link rel="prefetch" href="/assets/index.html-02fa7965.js" as="script"><link rel="prefetch" href="/assets/index.html-a238ef9b.js" as="script"><link rel="prefetch" href="/assets/index.html-d03bb0b2.js" as="script"><link rel="prefetch" href="/assets/index.html-f25dadc2.js" as="script"><link rel="prefetch" href="/assets/index.html-5349c6f9.js" as="script"><link rel="prefetch" href="/assets/index.html-14f0fecb.js" as="script"><link rel="prefetch" href="/assets/index.html-29e27b56.js" as="script"><link rel="prefetch" href="/assets/index.html-c9d056d3.js" as="script"><link rel="prefetch" href="/assets/index.html-f1364e66.js" as="script"><link rel="prefetch" href="/assets/index.html-abc1ba62.js" as="script"><link rel="prefetch" href="/assets/index.html-0c93742f.js" as="script"><link rel="prefetch" href="/assets/index.html-2ed22cdf.js" as="script"><link rel="prefetch" href="/assets/index.html-28bbb272.js" as="script"><link rel="prefetch" href="/assets/index.html-dcb1bcf0.js" as="script"><link rel="prefetch" href="/assets/index.html-042ee5a8.js" as="script"><link rel="prefetch" href="/assets/index.html-2f97df81.js" as="script"><link rel="prefetch" href="/assets/index.html-b9a4cc88.js" as="script"><link rel="prefetch" href="/assets/index.html-2f608871.js" as="script"><link rel="prefetch" href="/assets/index.html-fd1db64d.js" as="script"><link rel="prefetch" href="/assets/index.html-db483f04.js" as="script"><link rel="prefetch" href="/assets/index.html-44ad29b2.js" as="script"><link rel="prefetch" href="/assets/index.html-3d14f69a.js" as="script"><link rel="prefetch" href="/assets/index.html-c9a1a3b7.js" as="script"><link rel="prefetch" href="/assets/index.html-21954207.js" as="script"><link rel="prefetch" href="/assets/index.html-c5c84fd8.js" as="script"><link rel="prefetch" href="/assets/index.html-c53d023c.js" as="script"><link rel="prefetch" href="/assets/index.html-c5bbc0b2.js" as="script"><link rel="prefetch" href="/assets/index.html-4aba9c1f.js" as="script"><link rel="prefetch" href="/assets/index.html-76941593.js" as="script"><link rel="prefetch" href="/assets/index.html-dbc52194.js" as="script"><link rel="prefetch" href="/assets/index.html-0c5c159e.js" as="script"><link rel="prefetch" href="/assets/index.html-23d4db40.js" as="script"><link rel="prefetch" href="/assets/index.html-d9c53f50.js" as="script"><link rel="prefetch" href="/assets/index.html-873c901b.js" as="script"><link rel="prefetch" href="/assets/index.html-d0a7a1e2.js" as="script"><link rel="prefetch" href="/assets/index.html-32628670.js" as="script"><link rel="prefetch" href="/assets/index.html-724e1b2c.js" as="script"><link rel="prefetch" href="/assets/index.html-f897b683.js" as="script"><link rel="prefetch" href="/assets/index.html-44f37b9d.js" as="script"><link rel="prefetch" href="/assets/index.html-e56824f7.js" as="script"><link rel="prefetch" href="/assets/index.html-fadc2a4f.js" as="script"><link rel="prefetch" href="/assets/index.html-2e709343.js" as="script"><link rel="prefetch" href="/assets/index.html-cece3b35.js" as="script"><link rel="prefetch" href="/assets/index.html-c6c6ffc5.js" as="script"><link rel="prefetch" href="/assets/index.html-74281bc5.js" as="script"><link rel="prefetch" href="/assets/index.html-29ae631b.js" as="script"><link rel="prefetch" href="/assets/index.html-b8affcfb.js" as="script"><link rel="prefetch" href="/assets/index.html-eedfead7.js" as="script"><link rel="prefetch" href="/assets/index.html-cf991ca3.js" as="script"><link rel="prefetch" href="/assets/index.html-054150ad.js" as="script"><link rel="prefetch" href="/assets/index.html-151cdeb4.js" as="script"><link rel="prefetch" href="/assets/index.html-80f00f31.js" as="script"><link rel="prefetch" href="/assets/index.html-329d792e.js" as="script"><link rel="prefetch" href="/assets/index.html-9bf84be1.js" as="script"><link rel="prefetch" href="/assets/index.html-d302331a.js" as="script"><link rel="prefetch" href="/assets/index.html-d7abbac6.js" as="script"><link rel="prefetch" href="/assets/index.html-9f669e26.js" as="script"><link rel="prefetch" href="/assets/index.html-36c5f321.js" as="script"><link rel="prefetch" href="/assets/index.html-8df4eb8e.js" as="script"><link rel="prefetch" href="/assets/index.html-30e08aaf.js" as="script"><link rel="prefetch" href="/assets/index.html-c23fee57.js" as="script"><link rel="prefetch" href="/assets/index.html-3e055de4.js" as="script"><link rel="prefetch" href="/assets/index.html-17952ba3.js" as="script"><link rel="prefetch" href="/assets/index.html-a848276c.js" as="script"><link rel="prefetch" href="/assets/index.html-ec819640.js" as="script"><link rel="prefetch" href="/assets/index.html-bfb7151f.js" as="script"><link rel="prefetch" href="/assets/index.html-31234fd0.js" as="script"><link rel="prefetch" href="/assets/index.html-22ef4e2d.js" as="script"><link rel="prefetch" href="/assets/index.html-df97fb99.js" as="script"><link rel="prefetch" href="/assets/index.html-a92eba60.js" as="script"><link rel="prefetch" href="/assets/index.html-f7fb75e2.js" as="script"><link rel="prefetch" href="/assets/index.html-a4115189.js" as="script"><link rel="prefetch" href="/assets/index.html-4b12622a.js" as="script"><link rel="prefetch" href="/assets/index.html-14160347.js" as="script"><link rel="prefetch" href="/assets/index.html-5c73683b.js" as="script"><link rel="prefetch" href="/assets/index.html-2ef92a92.js" as="script"><link rel="prefetch" href="/assets/index.html-ad743870.js" as="script"><link rel="prefetch" href="/assets/index.html-eb58b984.js" as="script"><link rel="prefetch" href="/assets/index.html-ca2c145e.js" as="script"><link rel="prefetch" href="/assets/index.html-a88afec6.js" as="script"><link rel="prefetch" href="/assets/index.html-46604b8b.js" as="script"><link rel="prefetch" href="/assets/index.html-f53ee25e.js" as="script"><link rel="prefetch" href="/assets/index.html-65b7f2bb.js" as="script"><link rel="prefetch" href="/assets/index.html-03638ad6.js" as="script"><link rel="prefetch" href="/assets/index.html-9331b36c.js" as="script"><link rel="prefetch" href="/assets/index.html-797a7dbf.js" as="script"><link rel="prefetch" href="/assets/index.html-ed8e4e8d.js" as="script"><link rel="prefetch" href="/assets/index.html-61ca122b.js" as="script"><link rel="prefetch" href="/assets/index.html-95d68eac.js" as="script"><link rel="prefetch" href="/assets/index.html-f2e30342.js" as="script"><link rel="prefetch" href="/assets/index.html-5a659a23.js" as="script"><link rel="prefetch" href="/assets/index.html-7328527f.js" as="script"><link rel="prefetch" href="/assets/index.html-73956c68.js" as="script"><link rel="prefetch" href="/assets/index.html-f090a021.js" as="script"><link rel="prefetch" href="/assets/index.html-30191c65.js" as="script"><link rel="prefetch" href="/assets/index.html-2028706b.js" as="script"><link rel="prefetch" href="/assets/index.html-ba20a7e0.js" as="script"><link rel="prefetch" href="/assets/index.html-8b4a337c.js" as="script"><link rel="prefetch" href="/assets/index.html-bdaa42ec.js" as="script"><link rel="prefetch" href="/assets/waline-meta-56fbc549.js" as="script"><link rel="prefetch" href="/assets/component-a5917a33.js" as="script"><link rel="prefetch" href="/assets/auto-fa8841cf.js" as="script"><link rel="prefetch" href="/assets/index-a7d1ee58.js" as="script"><link rel="prefetch" href="/assets/flowchart-c441f34d.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-28669b93.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-abe06b83.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-ec5549c1.js" as="script"><link rel="prefetch" href="/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-c26e15aa.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-5794cde2.js" as="script"><link rel="prefetch" href="/assets/pageview-83c5bc5d.js" as="script"><link rel="prefetch" href="/assets/style-e9220a04.js" as="script"><link rel="prefetch" href="/assets/docsearch-1d421ddb.js" as="script"><link rel="prefetch" href="/assets/index-5161ad19.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container no-sidebar has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand" href="/"><img class="vp-nav-logo" src="/favicon.ico" alt="T4mako"><!----><span class="vp-site-name hide-in-pad">T4mako</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a class="vp-link nav-link" href="/"><span class="font-icon icon iconfont icon-home" style=""></span>主页<!----></a></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="代码笔记"><span class="title"><span class="font-icon icon iconfont icon-code" style=""></span>代码笔记</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html"><!---->基础知识<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/java.html"><!---->Java<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91.html"><!---->前端开发<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/数据库.html"><!---->数据库<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/%E8%BF%90%E7%BB%B4%E4%B8%8E%E9%83%A8%E7%BD%B2.html"><!---->运维与部署<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link active" href="/code/python.html"><!---->Python<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/leetcode.html"><!---->Leetcode<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/project.html"><!---->项目笔记<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/code/其他.html"><!---->其他<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="兴趣使然"><span class="title"><span class="font-icon icon iconfont icon-view" style=""></span>兴趣使然</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/AE.html"><!---->AE<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/Blender.html"><!---->Blender<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/HLAE.html"><!---->HLAE<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/interests/cook.html"><!---->吃饭糊弄学<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="生活碎片"><span class="title"><span class="font-icon icon iconfont icon-note" style=""></span>生活碎片</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/life/随笔.html"><!---->随笔<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/life/%E8%A7%82%E5%BD%B1%E5%8C%BA.html"><!---->观影区<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><a class="vp-link nav-link" href="/friends.html"><span class="font-icon icon iconfont icon-group" style=""></span>友链<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/T4mako/T4mako.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->7、构建、训练模型</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/T4mako/T4mako.github.io" target="_blank" rel="noopener noreferrer">T4mako</a></span><span property="author" content="T4mako"></span></span><!----><!----><!----><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_7-1、构建模型">7.1、构建模型</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-1-1、继承-nn-module-基类构建自定义模型">7.1.1、继承 nn.Module 基类构建自定义模型</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-1-2、使用-nn-sequential-按层顺序构建模型">7.1.2、使用 nn.Sequential 按层顺序构建模型</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装">7.1.3、继承 nn.Module 基类构建模型并辅助应用模型容器进行封装</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_7-2、训练模型">7.2、训练模型</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-0、准备数据">7.2.0、准备数据</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-1、脚本风格">7.2.1、脚本风格</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-2、函数风格">7.2.2、函数风格</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-2-3、类风格">7.2.3、类风格</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/#_7-3、使用-gpu-训练模型">7.3、使用 GPU 训练模型</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-0、gpu-相关操作汇总">7.3.0、GPU 相关操作汇总</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-1、矩阵乘法案例">7.3.1、矩阵乘法案例</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-2、线性回归范例">7.3.2、线性回归范例</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-3、图片分类范例">7.3.3、图片分类范例</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/#_7-3-4、torchkeras-kerasmodel-中使用-gpu">7.3.4、torchkeras.KerasModel 中使用 GPU</a></li><!----><!--]--></ul></li><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="_7、构建、训练模型" tabindex="-1"><a class="header-anchor" href="#_7、构建、训练模型" aria-hidden="true">#</a> 7、构建、训练模型</h1><h2 id="_7-1、构建模型" tabindex="-1"><a class="header-anchor" href="#_7-1、构建模型" aria-hidden="true">#</a> 7.1、构建模型</h2><p>构建模型有三种方法：</p><ol><li>继承 nn.Module 基类构建自定义模型（最常见）</li><li>使用 nn.Sequential 按层顺序构建模型（最简单）</li><li>继承 nn.Module 基类构建模型并辅助应用模型容器进行封装（nn.Sequential,nn.ModuleList,nn.ModuleDict）（最为灵活也较为复杂）</li></ol><p>模型定义好后，会给参数（w，b）赋值</p><blockquote><p>pytorch hub 模块，调用他人的网络架构</p></blockquote><h3 id="_7-1-1、继承-nn-module-基类构建自定义模型" tabindex="-1"><a class="header-anchor" href="#_7-1-1、继承-nn-module-基类构建自定义模型" aria-hidden="true">#</a> 7.1.1、继承 nn.Module 基类构建自定义模型</h3><p>模型中：</p><ul><li><strong>用到的层</strong> 在 <strong><code>__init__</code></strong> 函数中定义</li><li>在 <strong><code>forward</code></strong> 方法中定义模型的正向传播逻辑</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pool2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>adaptive_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>adaptive_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y
        
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-1-2、使用-nn-sequential-按层顺序构建模型" tabindex="-1"><a class="header-anchor" href="#_7-1-2、使用-nn-sequential-按层顺序构建模型" aria-hidden="true">#</a> 7.1.2、使用 nn.Sequential 按层顺序构建模型</h3><p>使用 nn.Sequential 按层顺序构建模型 <strong>无需定义 forward 方法。仅仅适合于简单的模型</strong>。</p><p>以下是使用 nn.Sequential 搭建模型的一些等价方法</p><ol><li><p>利用 add_module 方法</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>利用变长参数</p><p>这种方式构建时不能给每个层指定名称</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (4): Dropout2d(p=0.1, inplace=False)
  (5): AdaptiveMaxPool2d(output_size=(1, 1))
  (6): Flatten(start_dim=1, end_dim=-1)
  (7): Linear(in_features=64, out_features=32, bias=True)
  (8): ReLU()
  (9): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>利用 OrderedDict</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict

net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span>
          <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=1, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装" tabindex="-1"><a class="header-anchor" href="#_7-1-3、继承-nn-module-基类构建模型并辅助应用模型容器进行封装" aria-hidden="true">#</a> 7.1.3、继承 nn.Module 基类构建模型并辅助应用模型容器进行封装</h3><p>当模型的结构比较复杂时，我们可以应用模型容器（nn.Sequential,nn.ModuleList,nn.ModuleDict）对模型的部分结构进行封装</p><p>这样做会让模型整体更加有层次感，有时候也能减少代码量。</p><blockquote><p>注意，在下面的范例中我们每次仅仅使用一种模型容器，但实际上这些模型容器的使用是非常灵活的，可以在一个模型中任意组合任意嵌套使用。</p></blockquote><ol><li><p>nn.Sequential 作为模型容器</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> y 
    
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (conv): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
  )
  (dense): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=64, out_features=32, bias=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>nn.ModuleList 作为模型容器</p><p>注意下面中的 ModuleList 不能用 Python 中的列表代替。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> summary 
summary<span class="token punctuation">(</span>net<span class="token punctuation">,</span>input_shape<span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
--------------------------------------------------------------------------
Layer (type)                            Output Shape              Param #
==========================================================================
Conv2d-1                            [-1, 32, 30, 30]                  896
MaxPool2d-2                         [-1, 32, 15, 15]                    0
Conv2d-3                            [-1, 64, 11, 11]               51,264
MaxPool2d-4                           [-1, 64, 5, 5]                    0
Dropout2d-5                           [-1, 64, 5, 5]                    0
AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0
Flatten-7                                   [-1, 64]                    0
Linear-8                                    [-1, 32]                2,080
ReLU-9                                      [-1, 32]                    0
Linear-10                                    [-1, 1]                   33
==========================================================================
Total params: 54,273
Trainable params: 54,273
Non-trainable params: 0
--------------------------------------------------------------------------
Input size (MB): 0.011719
Forward/backward pass size (MB): 0.359627
Params size (MB): 0.207035
Estimated Total Size (MB): 0.578381
--------------------------------------------------------------------------
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>nn.ModuleDict 作为模型容器</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers_dict <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;pool&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;conv2&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;dropout&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;adaptive&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;flatten&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;linear1&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;relu&quot;</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
               <span class="token string">&quot;linear2&quot;</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
              <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;pool&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;pool&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;adaptive&quot;</span><span class="token punctuation">,</span>
                  <span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;sigmoid&quot;</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>layers_dict<span class="token punctuation">[</span>layer<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers_dict): ModuleDict(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (adaptive): AdaptiveMaxPool2d(output_size=(1, 1))
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (linear1): Linear(in_features=64, out_features=32, bias=True)
    (relu): ReLU()
    (linear2): Linear(in_features=32, out_features=1, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h2 id="_7-2、训练模型" tabindex="-1"><a class="header-anchor" href="#_7-2、训练模型" aria-hidden="true">#</a> 7.2、训练模型</h2><p>Pytorch 通常需要用户编写自定义训练循环</p><p>有 3 类典型的训练循环代码风格：</p><ul><li>脚本形式训练循环</li><li>函数形式训练循环</li><li>类形式训练循环</li></ul><p><strong>训练模式</strong> 和 <strong>预测模式</strong> 的切换：</p><ul><li>一般在训练模型时加上 <strong>model.train()</strong>，这样会正常使用 Batch Normalization 和 Dropout</li><li>测试的时候选择 <strong>model.eval()</strong>，这样就不会使用 Batch Normalization 和 Dropout</li></ul><p>下面以 minist 数据集的多分类模型的训练为例，演示这 3 种训练模型的风格</p><p>其中类形式训练循环我们同时演示 torchkeras.KerasModel 和 torchkeras.LightModel 两种示范</p><h3 id="_7-2-0、准备数据" tabindex="-1"><a class="header-anchor" href="#_7-2-0、准备数据" aria-hidden="true">#</a> 7.2.0、准备数据</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">import</span> torchvision 
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

<span class="token comment"># 将图像数据转换为张量（tensor）</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

ds_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
ds_val <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;./data/mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>

dl_train <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
dl_val <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 60000</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_val<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 10000</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-1、脚本风格" tabindex="-1"><a class="header-anchor" href="#_7-2-1、脚本风格" aria-hidden="true">#</a> 7.2.1、脚本风格</h3><p>脚本风格的训练循环非常常见</p><p>构建模型：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 构建模型</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Sequential(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout2d(p=0.1, inplace=False)
  (adaptive_pool): AdaptiveMaxPool2d(output_size=(1, 1))
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear1): Linear(in_features=64, out_features=32, bias=True)
  (relu): ReLU()
  (linear2): Linear(in_features=32, out_features=10, bias=True)
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>训练模型</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm <span class="token comment"># 进度条库</span>

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

<span class="token comment"># 于打印带有时间戳的日志信息</span>
<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
    
<span class="token comment"># 交叉熵损失函数、Adam 优化器、准确率评估指标    </span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

<span class="token comment"># 训练的轮数、检查点路径、早停监控指标、容忍度和模式，以及历史记录的字典</span>
epochs <span class="token operator">=</span> <span class="token number">20</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>
<span class="token comment"># early_stopping 相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">5</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token comment"># 在每个 epoch 中，首先进行训练模式的前向和反向传播，然后进行验证模式的前向传播，并记录损失和指标。所有指标和损失在每个 epoch 结束时都会被存储在 history 字典中</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    <span class="token comment"># 训练模式</span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 初始化本轮训练的总损失和步数计数器</span>
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token comment"># 使用 tqdm 包装数据加载器 dl_train，以显示训练进度条。enumerate函数用于生成数据批次的索引和值</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 深拷贝 metrics_dict，用于记录本轮训练的评估指标</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    <span class="token comment"># 遍历训练数据集 dl_train，每个 batch 是一个批次的训练数据</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        <span class="token comment"># 解包批次数据，features 是输入特征，labels 是对应的标签。</span>
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        <span class="token comment"># forward</span>
        <span class="token comment"># 向前传播，生成预测值</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        <span class="token comment"># 计算损失（目标函数）</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment"># backward 反向传播计算梯度。</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 使用优化器更新模型参数。</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 清零优化器中的梯度，以便下一步计算。</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment"># metrics</span>
        <span class="token comment"># 计算当前批次的评估指标，train_metrics_dict 中包含了准确率等指标。</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
        <span class="token comment"># 将当前批次的损失和评估指标存入 step_log 字典。</span>
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 累加当前批次的损失到总损失中。</span>
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token comment"># 增加步数计数器。</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 如果不是最后一个批次，更新进度条的后缀为 step_log。如果是最后一个批次，计算整个 epoch 的平均损失和评估指标，更新进度条的后缀为epoch_log，并重置评估指标。            </span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    <span class="token comment"># 将模型设置为评估模式，禁用 dropout 等只在训练期间有效的层</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 初始化本轮验证的总损失和步数计数器</span>
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token comment"># 使用tqdm包装验证数据加载器dl_val，以显示验证进度条</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 深拷贝metrics_dict，用于记录本轮验证的评估指标</span>
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    <span class="token comment"># 禁用梯度计算，以节省内存并加快计算</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
		   <span class="token comment"># 解包批次数据，features是输入特征，labels是对应的标签</span>
            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment"># forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            <span class="token comment"># 计算当前批次的损失，使用预定义的损失函数 loss_fn</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment"># metrics</span>
            <span class="token comment"># 计算当前批次的评估指标，val_metrics_dict中包含了准确率等指标</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
		   <span class="token comment"># 将当前批次的损失和评估指标存入step_log字典</span>
            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
 		   <span class="token comment"># 累加当前批次的损失到总损失中。</span>
            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 增加步数计数器。</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token comment"># 如果不是最后一个批次，更新进度条的后缀为step_log。如果是最后一个批次，计算整个epoch的平均损失和评估指标，更新进度条的后缀为epoch_log，并重置评估指标。</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>
                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
    <span class="token comment"># 将本轮验证的损失和评估指标存入history字典中</span>
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    <span class="token comment"># 早停机制：根据验证集上的性能指标决定是否保存当前模型参数，并在指定的轮次内指标没有提升时停止训练</span>
    <span class="token comment"># 获取监控指标的历史记录</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    <span class="token comment"># 根据监控模式（最大化或最小化），找到最佳得分的索引</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token comment"># 如果当前轮次是最佳得分，保存模型参数，并打印提示信息。</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
    <span class="token comment"># 如果在指定的容忍度内（patience）没有取得进步，打印提示信息并停止训练。</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    <span class="token comment"># 加载保存的最佳模型参数。</span>
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 将历史记录转换为 DataFrame：</span>
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-2、函数风格" tabindex="-1"><a class="header-anchor" href="#_7-2-2、函数风格" aria-hidden="true">#</a> 7.2.2、函数风格</h3><p>该风格在脚本形式上做了进一步的函数封装</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=10, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">StepRunner</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> net<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span>
                 stage <span class="token operator">=</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span> metrics_dict <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> 
                 optimizer <span class="token operator">=</span> <span class="token boolean">None</span>
                 <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">,</span>self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">,</span>self<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">,</span>self<span class="token punctuation">.</span>stage <span class="token operator">=</span> net<span class="token punctuation">,</span>loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token punctuation">,</span>stage
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optimizer
            
    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#loss</span>
        preds <span class="token operator">=</span> self<span class="token punctuation">.</span>net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward()</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>optimizer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> self<span class="token punctuation">.</span>stage<span class="token operator">==</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span> 
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>step_metrics
    
    <span class="token keyword">def</span> <span class="token function">train_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#训练模式, dropout层发生作用</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
    
    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">eval_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#预测模式, dropout层不发生作用</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>stage<span class="token operator">==</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>train_step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span> 
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>eval_step<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
<span class="token keyword">class</span> <span class="token class-name">EpochRunner</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>steprunner<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>steprunner <span class="token operator">=</span> steprunner
        self<span class="token punctuation">.</span>stage <span class="token operator">=</span> steprunner<span class="token punctuation">.</span>stage
        
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
        loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
            loss<span class="token punctuation">,</span> step_metrics <span class="token operator">=</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span>
            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>
            total_loss <span class="token operator">+=</span> loss
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span>self<span class="token punctuation">.</span>stage<span class="token operator">+</span><span class="token string">&quot;_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> self<span class="token punctuation">.</span>steprunner<span class="token punctuation">.</span>metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> epoch_log


<span class="token keyword">def</span> <span class="token function">train_model</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metrics_dict<span class="token punctuation">,</span> 
                train_data<span class="token punctuation">,</span> val_data<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> 
                epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span><span class="token punctuation">,</span>
                patience<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> monitor<span class="token operator">=</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">&quot;min&quot;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 1，train -------------------------------------------------  </span>
        train_step_runner <span class="token operator">=</span> StepRunner<span class="token punctuation">(</span>net <span class="token operator">=</span> net<span class="token punctuation">,</span>stage<span class="token operator">=</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span>
                loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token operator">=</span>deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span><span class="token punctuation">,</span>
                optimizer <span class="token operator">=</span> optimizer<span class="token punctuation">)</span>
        train_epoch_runner <span class="token operator">=</span> EpochRunner<span class="token punctuation">(</span>train_step_runner<span class="token punctuation">)</span>
        train_metrics <span class="token operator">=</span> train_epoch_runner<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>

        <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> train_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

        <span class="token comment"># 2，validate -------------------------------------------------</span>
        <span class="token keyword">if</span> val_data<span class="token punctuation">:</span>
            val_step_runner <span class="token operator">=</span> StepRunner<span class="token punctuation">(</span>net <span class="token operator">=</span> net<span class="token punctuation">,</span>stage<span class="token operator">=</span><span class="token string">&quot;val&quot;</span><span class="token punctuation">,</span>
                loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">,</span>metrics_dict<span class="token operator">=</span>deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>
            val_epoch_runner <span class="token operator">=</span> EpochRunner<span class="token punctuation">(</span>val_step_runner<span class="token punctuation">)</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                val_metrics <span class="token operator">=</span> val_epoch_runner<span class="token punctuation">(</span>val_data<span class="token punctuation">)</span>
            val_metrics<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
            <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> val_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

        <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
        arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
        best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
        <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
                 arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stderr<span class="token punctuation">)</span>
            <span class="token keyword">break</span> 
        net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

dfhistory <span class="token operator">=</span> train_model<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
    optimizer<span class="token punctuation">,</span>
    loss_fn<span class="token punctuation">,</span>
    metrics_dict<span class="token punctuation">,</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-2-3、类风格" tabindex="-1"><a class="header-anchor" href="#_7-2-3、类风格" aria-hidden="true">#</a> 7.2.3、类风格</h3><p>此处使用torchkeras.KerasModel高层次API接口中的fit方法训练模型。</p><p>使用该形式训练模型非常简洁明了</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> KerasModel 

<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
    
net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&#39;&#39;&#39;
Net(
  (layers): ModuleList(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Dropout2d(p=0.1, inplace=False)
    (5): AdaptiveMaxPool2d(output_size=(1, 1))
    (6): Flatten(start_dim=1, end_dim=-1)
    (7): Linear(in_features=64, out_features=32, bias=True)
    (8): ReLU()
    (9): Linear(in_features=32, out_features=10, bias=True)
  )
)
&#39;&#39;&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

model <span class="token operator">=</span> KerasModel<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
                   loss_fn<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                   optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">,</span>
    plot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    cpu<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_7-3、使用-gpu-训练模型" tabindex="-1"><a class="header-anchor" href="#_7-3、使用-gpu-训练模型" aria-hidden="true">#</a> 7.3、使用 GPU 训练模型</h2><p>训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代</p><ol><li>当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据</li><li>当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用 GPU 来进行加速</li></ol><p>Pytorch 中使用 GPU 加速模型非常简单，只要将模型和数据移动到 GPU 上。核心代码只有以下几行：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 定义模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动模型到 cuda</span>

<span class="token comment"># 训练模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动数据到 cuda</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 或者  labels = labels.cuda() if torch.cuda.is_available() else labels</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果要使用多个 GPU 训练模型，也非常简单。只需要在将模型设置为数据并行风格模型。 则模型移动到 GPU 上之后，会在每一个 GPU 上拷贝一个副本，并把数据平分到各个 GPU 上进行训练。核心代码如下：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 定义模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> 
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>model<span class="token punctuation">)</span> <span class="token comment"># 包装为并行风格模型</span>

<span class="token comment"># 训练模型</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 移动数据到 cuda</span>
labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 或者 labels = labels.cuda() if torch.cuda.is_available() else labels</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-0、gpu-相关操作汇总" tabindex="-1"><a class="header-anchor" href="#_7-3-0、gpu-相关操作汇总" aria-hidden="true">#</a> 7.3.0、GPU 相关操作汇总</h3><ol><li><p>查看 GPU 信息</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 

<span class="token comment"># 1，查看 gpu 信息</span>
if_cuda <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;if_cuda=&quot;</span><span class="token punctuation">,</span>if_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>

gpu_count <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;gpu_count=&quot;</span><span class="token punctuation">,</span>gpu_count<span class="token punctuation">)</span> <span class="token comment"># 1</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>将张量在 GPU 和 CPU 间移动</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 2，将张量在gpu和cpu间移动</span>
tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor_gpu <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 或者 tensor_gpu = tensor.cuda()</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_gpu<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_gpu<span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>

tensor_cpu <span class="token operator">=</span> tensor_gpu<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 或者 tensor_cpu = tensor_gpu.cpu() </span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tensor_cpu<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cpu</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>将模型中的全部张量移动到 GPU 上</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 3，将模型中的全部张量移动到gpu上</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># False</span>
net<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span><span class="token punctuation">)</span> <span class="token comment"># 将模型中的全部参数张量依次到GPU上，注意，无需重新赋值为 net = net.to(&quot;cuda:0&quot;)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span> <span class="token comment"># True</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>创建支持多个 GPU 数据并行的模型</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 4，创建支持多个gpu数据并行的模型</span>
linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cpu</span>

model <span class="token operator">=</span> nn<span class="token punctuation">.</span>DataParallel<span class="token punctuation">(</span>linear<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>device_ids<span class="token punctuation">)</span> <span class="token comment"># [0]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token comment"># cuda:0</span>

<span class="token comment">#注意保存参数时要指定保存model.module的参数</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>module<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;model_parameter.pt&quot;</span><span class="token punctuation">)</span> 

linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
linear<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&quot;model_parameter.pt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ol><h3 id="_7-3-1、矩阵乘法案例" tabindex="-1"><a class="header-anchor" href="#_7-3-1、矩阵乘法案例" aria-hidden="true">#</a> 7.3.1、矩阵乘法案例</h3><p>下面分别使用 CPU 和 GPU 作一个矩阵乘法，并比较其计算效率。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> time
<span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn

<span class="token comment"># 使用 CPU</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># 使用 Gpu</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">,</span>device <span class="token operator">=</span> device<span class="token punctuation">)</span> <span class="token comment">#可以指定在GPU上创建张量</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#也可以在CPU上创建张量后移动到GPU上</span>
b <span class="token operator">=</span> b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment">#或者 b = b.cuda() if torch.cuda.is_available() else b </span>
tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-2、线性回归范例" tabindex="-1"><a class="header-anchor" href="#_7-3-2、线性回归范例" aria-hidden="true">#</a> 7.3.2、线性回归范例</h3><p>下面对比使用 CPU 和 GPU 训练一个线性回归模型的效率</p><p>使用 CPU：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 准备数据</span>
n <span class="token operator">=</span> <span class="token number">1000000</span> <span class="token comment">#样本数量</span>

X <span class="token operator">=</span> <span class="token number">10</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5.0</span>  <span class="token comment">#torch.rand是均匀分布 </span>
w0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> X@w0<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b0 <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># @表示矩阵乘法,增加正态扰动</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>w0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>b0<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#正向传播</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> x@self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        
linear <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 训练模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        Y_pred <span class="token operator">=</span> linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span> 
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>Y_pred<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> 
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch<span class="token operator">%</span><span class="token number">50</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">:</span>epoch<span class="token punctuation">,</span><span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;time used:&quot;</span><span class="token punctuation">,</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>

train<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 GPU：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 准备数据</span>
n <span class="token operator">=</span> <span class="token number">1000000</span> <span class="token comment"># 样本数量</span>

X <span class="token operator">=</span> <span class="token number">10</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">5.0</span>  <span class="token comment">#torch.rand 是均匀分布 </span>
w0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
b0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> X@w0<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b0 <span class="token operator">+</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span>size <span class="token operator">=</span> <span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># @表示矩阵乘法,增加正态扰动</span>

<span class="token comment"># 数据移动到 GPU 上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;torch.cuda.is_available() = &quot;</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> X<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> Y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;X.device:&quot;</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Y.device:&quot;</span><span class="token punctuation">,</span>Y<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>w0<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>b0<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 正向传播</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">return</span> x@self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        
linear <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 移动模型到GPU上</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
linear<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 查看模型是否已经移动到 GPU 上</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;if on cuda:&quot;</span><span class="token punctuation">,</span><span class="token builtin">next</span><span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>is_cuda<span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
    tic <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        Y_pred <span class="token operator">=</span> linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span> 
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>Y_pred<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> 
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> epoch<span class="token operator">%</span><span class="token number">50</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">:</span>epoch<span class="token punctuation">,</span><span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    toc <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;time used:&quot;</span><span class="token punctuation">,</span>toc<span class="token operator">-</span>tic<span class="token punctuation">)</span>
    
train<span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-3、图片分类范例" tabindex="-1"><a class="header-anchor" href="#_7-3-3、图片分类范例" aria-hidden="true">#</a> 7.3.3、图片分类范例</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">import</span> torchvision 
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

<span class="token comment"># 准备数据</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
ds_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
ds_val <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&quot;mnist/&quot;</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>
dl_train <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
dl_val <span class="token operator">=</span>  torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>ds_val<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">def</span> <span class="token function">create_net</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;conv2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;pool2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;dropout&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;adaptive_pool&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;flatten&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear1&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">&quot;linear2&quot;</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> net

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 CPU 训练：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
<span class="token comment">#注：多分类使用 torchmetrics 中的评估指标，二分类使用 torchkeras.metrics 中的评估指标</span>

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
    

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 

loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

epochs <span class="token operator">=</span> <span class="token number">3</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>

<span class="token comment">#early_stopping 相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">1</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        <span class="token comment">#forward</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 

            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment">#forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment">#metrics</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch           
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>使用 GPU 训练：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> os<span class="token punctuation">,</span>sys<span class="token punctuation">,</span>time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> datetime 
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm 

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn 
<span class="token keyword">from</span> copy <span class="token keyword">import</span> deepcopy
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy
<span class="token comment">#注：多分类使用torchmetrics中的评估指标，二分类使用torchkeras.metrics中的评估指标</span>

<span class="token keyword">def</span> <span class="token function">printlog</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">&#39;%Y-%m-%d %H:%M:%S&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n&quot;</span><span class="token operator">+</span><span class="token string">&quot;==========&quot;</span><span class="token operator">*</span><span class="token number">8</span> <span class="token operator">+</span> <span class="token string">&quot;%s&quot;</span><span class="token operator">%</span>nowtime<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span>
    
net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 


loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer<span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>   
metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span>


<span class="token comment"># =========================移动模型到GPU上==============================</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
loss_fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token keyword">for</span> name<span class="token punctuation">,</span>fn <span class="token keyword">in</span> metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
<span class="token comment"># ====================================================================</span>


epochs <span class="token operator">=</span> <span class="token number">5</span> 
ckpt_path<span class="token operator">=</span><span class="token string">&#39;checkpoint.pt&#39;</span>

<span class="token comment">#early_stopping相关设置</span>
monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span>
patience<span class="token operator">=</span><span class="token number">1</span>
mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span>

history <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    printlog<span class="token punctuation">(</span><span class="token string">&quot;Epoch {0} / {1}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 1，train -------------------------------------------------  </span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    train_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 
        
        features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
        
        <span class="token comment"># =========================移动数据到GPU上==============================</span>
        features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment"># ====================================================================</span>
        
        <span class="token comment">#forward</span>
        preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
        
        <span class="token comment">#backward</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        <span class="token comment">#metrics</span>
        step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                        <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        
        step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        step<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_train<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            epoch_loss <span class="token operator">=</span> total_loss<span class="token operator">/</span>step
            epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                             <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;train_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
            loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> train_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>
        

    <span class="token comment"># 2，validate -------------------------------------------------</span>
    net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    total_loss<span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    loop <span class="token operator">=</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span> total <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span>
    
    val_metrics_dict <span class="token operator">=</span> deepcopy<span class="token punctuation">(</span>metrics_dict<span class="token punctuation">)</span> 
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> batch <span class="token keyword">in</span> loop<span class="token punctuation">:</span> 

            features<span class="token punctuation">,</span>labels <span class="token operator">=</span> batch
            
            <span class="token comment"># =========================移动数据到GPU上==============================</span>
            features <span class="token operator">=</span> features<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            <span class="token comment"># ====================================================================</span>
            
            <span class="token comment">#forward</span>
            preds <span class="token operator">=</span> net<span class="token punctuation">(</span>features<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>

            <span class="token comment">#metrics</span>
            step_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                            <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

            step_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>step_metrics<span class="token punctuation">)</span>

            total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            step<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">if</span> i<span class="token operator">!=</span><span class="token builtin">len</span><span class="token punctuation">(</span>dl_val<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>step_log<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                epoch_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss<span class="token operator">/</span>step<span class="token punctuation">)</span>
                epoch_metrics <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;val_&quot;</span><span class="token operator">+</span>name<span class="token punctuation">:</span>metric_fn<span class="token punctuation">.</span>compute<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> 
                                 <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                epoch_log <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">&quot;val_loss&quot;</span><span class="token punctuation">:</span>epoch_loss<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token operator">**</span>epoch_metrics<span class="token punctuation">)</span>
                loop<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span><span class="token operator">**</span>epoch_log<span class="token punctuation">)</span>

                <span class="token keyword">for</span> name<span class="token punctuation">,</span>metric_fn <span class="token keyword">in</span> val_metrics_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    metric_fn<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
                    
    epoch_log<span class="token punctuation">[</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch           
    <span class="token keyword">for</span> name<span class="token punctuation">,</span> metric <span class="token keyword">in</span> epoch_log<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        history<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> history<span class="token punctuation">.</span>get<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>metric<span class="token punctuation">]</span>

    <span class="token comment"># 3，early-stopping -------------------------------------------------</span>
    arr_scores <span class="token operator">=</span> history<span class="token punctuation">[</span>monitor<span class="token punctuation">]</span>
    best_score_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span> <span class="token keyword">if</span> mode<span class="token operator">==</span><span class="token string">&quot;max&quot;</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_score_idx<span class="token operator">==</span><span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>ckpt_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best {0} : {1} &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>monitor<span class="token punctuation">,</span>
             arr_scores<span class="token punctuation">[</span>best_score_idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>arr_scores<span class="token punctuation">)</span><span class="token operator">-</span>best_score_idx<span class="token operator">&gt;</span>patience<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; {} without improvement in {} epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            monitor<span class="token punctuation">,</span>patience<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">break</span> 
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>history<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_7-3-4、torchkeras-kerasmodel-中使用-gpu" tabindex="-1"><a class="header-anchor" href="#_7-3-4、torchkeras-kerasmodel-中使用-gpu" aria-hidden="true">#</a> 7.3.4、torchkeras.KerasModel 中使用 GPU</h3><p>从上面的例子可以看到，在 pytorch 中使用 GPU 并不复杂，但对于经常炼丹的同学来说，模型和数据老是移来移去还是蛮麻烦的。</p><p>一不小心就会忘了移动某些数据或者某些 module，导致报错。</p><p>torchkeras.KerasModel 在设计的时候考虑到了这一点，如果环境当中存在可用的 GPU，会自动使用 GPU，反之则使用 CPU。</p><p>通过引入 accelerate 的一些基础功能，torchkeras.KerasModel 以非常优雅的方式在 GPU 和 CPU 之间切换。</p><p>详细实现可以参考 torchkeras.KerasModel 的源码。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span>  accelerate 
accelerator <span class="token operator">=</span> accelerate<span class="token punctuation">.</span>Accelerator<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>accelerator<span class="token punctuation">.</span>device<span class="token punctuation">)</span>  <span class="token comment"># cuda</span>

<span class="token keyword">from</span> torchkeras <span class="token keyword">import</span> KerasModel 
<span class="token keyword">from</span> torchmetrics <span class="token keyword">import</span> Accuracy

net <span class="token operator">=</span> create_net<span class="token punctuation">(</span><span class="token punctuation">)</span> 
model <span class="token operator">=</span> KerasModel<span class="token punctuation">(</span>net<span class="token punctuation">,</span>
                   loss_fn<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                   metrics_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;acc&quot;</span><span class="token punctuation">:</span>Accuracy<span class="token punctuation">(</span>task<span class="token operator">=</span><span class="token string">&#39;multiclass&#39;</span><span class="token punctuation">,</span>num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                   optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.01</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_data <span class="token operator">=</span> dl_train<span class="token punctuation">,</span>
    val_data<span class="token operator">=</span> dl_val<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    monitor<span class="token operator">=</span><span class="token string">&quot;val_acc&quot;</span><span class="token punctuation">,</span> 
    mode<span class="token operator">=</span><span class="token string">&quot;max&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/T4mako/T4mako.github.io/edit/main/src/code/python/Machine Learning/Pytorch/7、构建、训练模型.md" rel="noopener noreferrer" target="_blank" aria-label="在 GitHub 上编辑此页" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><!----><!----></div></footer><!----><div id="comment" class="waline-wrapper" darkmode="false" style="display:block;"><div data-waline provider="Waline" pageview="false"><!--v-if--><div class="wl-comment"><!--v-if--><div class="wl-panel"><div class="wl-header item3"><!--[--><div class="wl-header-item"><label for="wl-nick">昵称</label><input id="wl-nick" class="wl-input wl-nick" name="nick" type="text" value></div><div class="wl-header-item"><label for="wl-mail">邮箱</label><input id="wl-mail" class="wl-input wl-mail" name="mail" type="email" value></div><div class="wl-header-item"><label for="wl-link">网址</label><input id="wl-link" class="wl-input wl-link" name="link" type="text" value></div><!--]--></div><textarea id="wl-edit" class="wl-editor" placeholder="请留言。(填写邮箱可在被回复时收到邮件提醒)"></textarea><div class="wl-preview" style="display:none;"><hr><h4>预览:</h4><div class="wl-content"></div></div><div class="wl-footer"><div class="wl-actions"><a href="https://guides.github.com/features/mastering-markdown/" title="Markdown Guide" aria-label="Markdown is supported" class="wl-action" target="_blank" rel="noopener noreferrer"><svg width="16" height="16" ariaHidden="true"><path d="M14.85 3H1.15C.52 3 0 3.52 0 4.15v7.69C0 12.48.52 13 1.15 13h13.69c.64 0 1.15-.52 1.15-1.15v-7.7C16 3.52 15.48 3 14.85 3zM9 11H7V8L5.5 9.92 4 8v3H2V5h2l1.5 2L7 5h2v6zm2.99.5L9.5 8H11V5h2v3h1.5l-2.51 3.5z" fill="currentColor"></path></svg></a><button type="button" class="wl-action" title="表情" style="display:none;"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M563.2 463.3 677 540c1.7 1.2 3.7 1.8 5.8 1.8.7 0 1.4-.1 2-.2 2.7-.5 5.1-2.1 6.6-4.4l25.3-37.8c1.5-2.3 2.1-5.1 1.6-7.8s-2.1-5.1-4.4-6.6l-73.6-49.1 73.6-49.1c2.3-1.5 3.9-3.9 4.4-6.6.5-2.7 0-5.5-1.6-7.8l-25.3-37.8a10.1 10.1 0 0 0-6.6-4.4c-.7-.1-1.3-.2-2-.2-2.1 0-4.1.6-5.8 1.8l-113.8 76.6c-9.2 6.2-14.7 16.4-14.7 27.5.1 11 5.5 21.3 14.7 27.4zM387 348.8h-45.5c-5.7 0-10.4 4.7-10.4 10.4v153.3c0 5.7 4.7 10.4 10.4 10.4H387c5.7 0 10.4-4.7 10.4-10.4V359.2c0-5.7-4.7-10.4-10.4-10.4zm333.8 241.3-41-20a10.3 10.3 0 0 0-8.1-.5c-2.6.9-4.8 2.9-5.9 5.4-30.1 64.9-93.1 109.1-164.4 115.2-5.7.5-9.9 5.5-9.5 11.2l3.9 45.5c.5 5.3 5 9.5 10.3 9.5h.9c94.8-8 178.5-66.5 218.6-152.7 2.4-5 .3-11.2-4.8-13.6zm186-186.1c-11.9-42-30.5-81.4-55.2-117.1-24.1-34.9-53.5-65.6-87.5-91.2-33.9-25.6-71.5-45.5-111.6-59.2-41.2-14-84.1-21.1-127.8-21.1h-1.2c-75.4 0-148.8 21.4-212.5 61.7-63.7 40.3-114.3 97.6-146.5 165.8-32.2 68.1-44.3 143.6-35.1 218.4 9.3 74.8 39.4 145 87.3 203.3.1.2.3.3.4.5l36.2 38.4c1.1 1.2 2.5 2.1 3.9 2.6 73.3 66.7 168.2 103.5 267.5 103.5 73.3 0 145.2-20.3 207.7-58.7 37.3-22.9 70.3-51.5 98.1-85 27.1-32.7 48.7-69.5 64.2-109.1 15.5-39.7 24.4-81.3 26.6-123.8 2.4-43.6-2.5-87-14.5-129zm-60.5 181.1c-8.3 37-22.8 72-43 104-19.7 31.1-44.3 58.6-73.1 81.7-28.8 23.1-61 41-95.7 53.4-35.6 12.7-72.9 19.1-110.9 19.1-82.6 0-161.7-30.6-222.8-86.2l-34.1-35.8c-23.9-29.3-42.4-62.2-55.1-97.7-12.4-34.7-18.8-71-19.2-107.9-.4-36.9 5.4-73.3 17.1-108.2 12-35.8 30-69.2 53.4-99.1 31.7-40.4 71.1-72 117.2-94.1 44.5-21.3 94-32.6 143.4-32.6 49.3 0 97 10.8 141.8 32 34.3 16.3 65.3 38.1 92 64.8 26.1 26 47.5 56 63.6 89.2 16.2 33.2 26.6 68.5 31 105.1 4.6 37.5 2.7 75.3-5.6 112.3z" fill="currentColor"></path></svg></button><button type="button" class="wl-action" title="表情包"><svg width="24" height="24" fill="currentcolor" viewBox="0 0 24 24"><path style="transform: translateY(0.5px)" d="M18.968 10.5H15.968V11.484H17.984V12.984H15.968V15H14.468V9H18.968V10.5V10.5ZM8.984 9C9.26533 9 9.49967 9.09367 9.687 9.281C9.87433 9.46833 9.968 9.70267 9.968 9.984V10.5H6.499V13.5H8.468V12H9.968V14.016C9.968 14.2973 9.87433 14.5317 9.687 14.719C9.49967 14.9063 9.26533 15 8.984 15H5.984C5.70267 15 5.46833 14.9063 5.281 14.719C5.09367 14.5317 5 14.2973 5 14.016V9.985C5 9.70367 5.09367 9.46933 5.281 9.282C5.46833 9.09467 5.70267 9.001 5.984 9.001H8.984V9ZM11.468 9H12.968V15H11.468V9V9Z"></path><path d="M18.5 3H5.75C3.6875 3 2 4.6875 2 6.75V18C2 20.0625 3.6875 21.75 5.75 21.75H18.5C20.5625 21.75 22.25 20.0625 22.25 18V6.75C22.25 4.6875 20.5625 3 18.5 3ZM20.75 18C20.75 19.2375 19.7375 20.25 18.5 20.25H5.75C4.5125 20.25 3.5 19.2375 3.5 18V6.75C3.5 5.5125 4.5125 4.5 5.75 4.5H18.5C19.7375 4.5 20.75 5.5125 20.75 6.75V18Z"></path></svg></button><input id="wl-image-upload" class="upload" type="file" accept=".png,.jpg,.jpeg,.webp,.bmp,.gif"><label for="wl-image-upload" class="wl-action" title="上传图片"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M784 112H240c-88 0-160 72-160 160v480c0 88 72 160 160 160h544c88 0 160-72 160-160V272c0-88-72-160-160-160zm96 640c0 52.8-43.2 96-96 96H240c-52.8 0-96-43.2-96-96V272c0-52.8 43.2-96 96-96h544c52.8 0 96 43.2 96 96v480z" fill="currentColor"></path><path d="M352 480c52.8 0 96-43.2 96-96s-43.2-96-96-96-96 43.2-96 96 43.2 96 96 96zm0-128c17.6 0 32 14.4 32 32s-14.4 32-32 32-32-14.4-32-32 14.4-32 32-32zm462.4 379.2-3.2-3.2-177.6-177.6c-25.6-25.6-65.6-25.6-91.2 0l-80 80-36.8-36.8c-25.6-25.6-65.6-25.6-91.2 0L200 728c-4.8 6.4-8 14.4-8 24 0 17.6 14.4 32 32 32 9.6 0 16-3.2 22.4-9.6L380.8 640l134.4 134.4c6.4 6.4 14.4 9.6 24 9.6 17.6 0 32-14.4 32-32 0-9.6-4.8-17.6-9.6-24l-52.8-52.8 80-80L769.6 776c6.4 4.8 12.8 8 20.8 8 17.6 0 32-14.4 32-32 0-8-3.2-16-8-20.8z" fill="currentColor"></path></svg></label><button type="button" class="wl-action" title="预览"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M710.816 654.301c70.323-96.639 61.084-230.578-23.705-314.843-46.098-46.098-107.183-71.109-172.28-71.109-65.008 0-126.092 25.444-172.28 71.109-45.227 46.098-70.756 107.183-70.756 172.106 0 64.923 25.444 126.007 71.194 172.106 46.099 46.098 107.184 71.109 172.28 71.109 51.414 0 100.648-16.212 142.824-47.404l126.53 126.006c7.058 7.06 16.297 10.979 26.406 10.979 10.105 0 19.343-3.919 26.402-10.979 14.467-14.467 14.467-38.172 0-52.723L710.816 654.301zm-315.107-23.265c-65.88-65.88-65.88-172.54 0-238.42 32.069-32.07 74.245-49.149 119.471-49.149 45.227 0 87.407 17.603 119.472 49.149 65.88 65.879 65.88 172.539 0 238.42-63.612 63.178-175.242 63.178-238.943 0zm0 0" fill="currentColor"></path><path d="M703.319 121.603H321.03c-109.8 0-199.469 89.146-199.469 199.38v382.034c0 109.796 89.236 199.38 199.469 199.38h207.397c20.653 0 37.384-16.645 37.384-37.299 0-20.649-16.731-37.296-37.384-37.296H321.03c-68.582 0-124.352-55.77-124.352-124.267V321.421c0-68.496 55.77-124.267 124.352-124.267h382.289c68.582 0 124.352 55.771 124.352 124.267V524.72c0 20.654 16.736 37.299 37.385 37.299 20.654 0 37.384-16.645 37.384-37.299V320.549c-.085-109.8-89.321-198.946-199.121-198.946zm0 0" fill="currentColor"></path></svg></button></div><div class="wl-info"><div class="wl-captcha-container"></div><div class="wl-text-number">0 <!--v-if-->  字</div><button type="button" class="wl-btn">登录</button><button type="submit" class="primary wl-btn" title="Cmd|Ctrl + Enter"><!--[-->提交<!--]--></button></div><div class="wl-gif-popup"><input type="text" placeholder="搜索表情包"><!--v-if--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div></div><div class="wl-emoji-popup"><!--[--><!--]--><!--v-if--></div></div></div><!--v-if--></div><div class="wl-meta-head"><div class="wl-count"><!--v-if--> 评论</div><ul class="wl-sort"><!--[--><li class="active">按正序</li><li class="">按倒序</li><li class="">按热度</li><!--]--></ul></div><div class="wl-cards"><!--[--><!--]--></div><!--[--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div><!--]--><div class="wl-power"> Powered by <a href="https://github.com/walinejs/waline" target="_blank" rel="noopener noreferrer"> Waline </a> v2.15.5</div></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">T4mako's blog</div><div class="vp-copyright">Copyright © 2024 T4mako</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-6225af5c.js" defer></script>
  </body>
</html>
